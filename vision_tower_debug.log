/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
preprocessor_config.json: 100%
 977/977 [00:00<00:00, 99.3kB/s]
processor_config.json: 100%
 79.0/79.0 [00:00<00:00, 8.62kB/s]
config.json: 
 2.33k/? [00:00<00:00, 193kB/s]
`torch_dtype` is deprecated! Use `dtype` instead!
model.safetensors: 100%
 902M/902M [00:07<00:00, 182MB/s]
Some weights of Lfm2VlModel were not initialized from the model checkpoint at LiquidAI/LFM2-VL-450M and are newly initialized: ['language_model.embed_tokens.weight', 'language_model.embedding_norm.weight', 'language_model.layers.0.conv.conv.weight', 'language_model.layers.0.conv.in_proj.weight', 'language_model.layers.0.conv.out_proj.weight', 'language_model.layers.0.feed_forward.w1.weight', 'language_model.layers.0.feed_forward.w2.weight', 'language_model.layers.0.feed_forward.w3.weight', 'language_model.layers.0.ffn_norm.weight', 'language_model.layers.0.operator_norm.weight', 'language_model.layers.1.conv.conv.weight', 'language_model.layers.1.conv.in_proj.weight', 'language_model.layers.1.conv.out_proj.weight', 'language_model.layers.1.feed_forward.w1.weight', 'language_model.layers.1.feed_forward.w2.weight', 'language_model.layers.1.feed_forward.w3.weight', 'language_model.layers.1.ffn_norm.weight', 'language_model.layers.1.operator_norm.weight', 'language_model.layers.10.feed_forward.w1.weight', 'language_model.layers.10.feed_forward.w2.weight', 'language_model.layers.10.feed_forward.w3.weight', 'language_model.layers.10.ffn_norm.weight', 'language_model.layers.10.operator_norm.weight', 'language_model.layers.10.self_attn.k_layernorm.weight', 'language_model.layers.10.self_attn.k_proj.weight', 'language_model.layers.10.self_attn.out_proj.weight', 'language_model.layers.10.self_attn.q_layernorm.weight', 'language_model.layers.10.self_attn.q_proj.weight', 'language_model.layers.10.self_attn.v_proj.weight', 'language_model.layers.11.conv.conv.weight', 'language_model.layers.11.conv.in_proj.weight', 'language_model.layers.11.conv.out_proj.weight', 'language_model.layers.11.feed_forward.w1.weight', 'language_model.layers.11.feed_forward.w2.weight', 'language_model.layers.11.feed_forward.w3.weight', 'language_model.layers.11.ffn_norm.weight', 'language_model.layers.11.operator_norm.weight', 'language_model.layers.12.feed_forward.w1.weight', 'language_model.layers.12.feed_forward.w2.weight', 'language_model.layers.12.feed_forward.w3.weight', 'language_model.layers.12.ffn_norm.weight', 'language_model.layers.12.operator_norm.weight', 'language_model.layers.12.self_attn.k_layernorm.weight', 'language_model.layers.12.self_attn.k_proj.weight', 'language_model.layers.12.self_attn.out_proj.weight', 'language_model.layers.12.self_attn.q_layernorm.weight', 'language_model.layers.12.self_attn.q_proj.weight', 'language_model.layers.12.self_attn.v_proj.weight', 'language_model.layers.13.conv.conv.weight', 'language_model.layers.13.conv.in_proj.weight', 'language_model.layers.13.conv.out_proj.weight', 'language_model.layers.13.feed_forward.w1.weight', 'language_model.layers.13.feed_forward.w2.weight', 'language_model.layers.13.feed_forward.w3.weight', 'language_model.layers.13.ffn_norm.weight', 'language_model.layers.13.operator_norm.weight', 'language_model.layers.14.feed_forward.w1.weight', 'language_model.layers.14.feed_forward.w2.weight', 'language_model.layers.14.feed_forward.w3.weight', 'language_model.layers.14.ffn_norm.weight', 'language_model.layers.14.operator_norm.weight', 'language_model.layers.14.self_attn.k_layernorm.weight', 'language_model.layers.14.self_attn.k_proj.weight', 'language_model.layers.14.self_attn.out_proj.weight', 'language_model.layers.14.self_attn.q_layernorm.weight', 'language_model.layers.14.self_attn.q_proj.weight', 'language_model.layers.14.self_attn.v_proj.weight', 'language_model.layers.15.conv.conv.weight', 'language_model.layers.15.conv.in_proj.weight', 'language_model.layers.15.conv.out_proj.weight', 'language_model.layers.15.feed_forward.w1.weight', 'language_model.layers.15.feed_forward.w2.weight', 'language_model.layers.15.feed_forward.w3.weight', 'language_model.layers.15.ffn_norm.weight', 'language_model.layers.15.operator_norm.weight', 'language_model.layers.2.feed_forward.w1.weight', 'language_model.layers.2.feed_forward.w2.weight', 'language_model.layers.2.feed_forward.w3.weight', 'language_model.layers.2.ffn_norm.weight', 'language_model.layers.2.operator_norm.weight', 'language_model.layers.2.self_attn.k_layernorm.weight', 'language_model.layers.2.self_attn.k_proj.weight', 'language_model.layers.2.self_attn.out_proj.weight', 'language_model.layers.2.self_attn.q_layernorm.weight', 'language_model.layers.2.self_attn.q_proj.weight', 'language_model.layers.2.self_attn.v_proj.weight', 'language_model.layers.3.conv.conv.weight', 'language_model.layers.3.conv.in_proj.weight', 'language_model.layers.3.conv.out_proj.weight', 'language_model.layers.3.feed_forward.w1.weight', 'language_model.layers.3.feed_forward.w2.weight', 'language_model.layers.3.feed_forward.w3.weight', 'language_model.layers.3.ffn_norm.weight', 'language_model.layers.3.operator_norm.weight', 'language_model.layers.4.conv.conv.weight', 'language_model.layers.4.conv.in_proj.weight', 'language_model.layers.4.conv.out_proj.weight', 'language_model.layers.4.feed_forward.w1.weight', 'language_model.layers.4.feed_forward.w2.weight', 'language_model.layers.4.feed_forward.w3.weight', 'language_model.layers.4.ffn_norm.weight', 'language_model.layers.4.operator_norm.weight', 'language_model.layers.5.feed_forward.w1.weight', 'language_model.layers.5.feed_forward.w2.weight', 'language_model.layers.5.feed_forward.w3.weight', 'language_model.layers.5.ffn_norm.weight', 'language_model.layers.5.operator_norm.weight', 'language_model.layers.5.self_attn.k_layernorm.weight', 'language_model.layers.5.self_attn.k_proj.weight', 'language_model.layers.5.self_attn.out_proj.weight', 'language_model.layers.5.self_attn.q_layernorm.weight', 'language_model.layers.5.self_attn.q_proj.weight', 'language_model.layers.5.self_attn.v_proj.weight', 'language_model.layers.6.conv.conv.weight', 'language_model.layers.6.conv.in_proj.weight', 'language_model.layers.6.conv.out_proj.weight', 'language_model.layers.6.feed_forward.w1.weight', 'language_model.layers.6.feed_forward.w2.weight', 'language_model.layers.6.feed_forward.w3.weight', 'language_model.layers.6.ffn_norm.weight', 'language_model.layers.6.operator_norm.weight', 'language_model.layers.7.conv.conv.weight', 'language_model.layers.7.conv.in_proj.weight', 'language_model.layers.7.conv.out_proj.weight', 'language_model.layers.7.feed_forward.w1.weight', 'language_model.layers.7.feed_forward.w2.weight', 'language_model.layers.7.feed_forward.w3.weight', 'language_model.layers.7.ffn_norm.weight', 'language_model.layers.7.operator_norm.weight', 'language_model.layers.8.feed_forward.w1.weight', 'language_model.layers.8.feed_forward.w2.weight', 'language_model.layers.8.feed_forward.w3.weight', 'language_model.layers.8.ffn_norm.weight', 'language_model.layers.8.operator_norm.weight', 'language_model.layers.8.self_attn.k_layernorm.weight', 'language_model.layers.8.self_attn.k_proj.weight', 'language_model.layers.8.self_attn.out_proj.weight', 'language_model.layers.8.self_attn.q_layernorm.weight', 'language_model.layers.8.self_attn.q_proj.weight', 'language_model.layers.8.self_attn.v_proj.weight', 'language_model.layers.9.conv.conv.weight', 'language_model.layers.9.conv.in_proj.weight', 'language_model.layers.9.conv.out_proj.weight', 'language_model.layers.9.feed_forward.w1.weight', 'language_model.layers.9.feed_forward.w2.weight', 'language_model.layers.9.feed_forward.w3.weight', 'language_model.layers.9.ffn_norm.weight', 'language_model.layers.9.operator_norm.weight', 'multi_modal_projector.layer_norm.bias', 'multi_modal_projector.layer_norm.weight', 'multi_modal_projector.linear_1.bias', 'multi_modal_projector.linear_1.weight', 'multi_modal_projector.linear_2.bias', 'multi_modal_projector.linear_2.weight', 'vision_tower.vision_model.embeddings.patch_embedding.bias', 'vision_tower.vision_model.embeddings.patch_embedding.weight', 'vision_tower.vision_model.embeddings.position_embedding.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_tower.vision_model.post_layernorm.bias', 'vision_tower.vision_model.post_layernorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[PROC] pixel_values shape=(1, 1024, 768)  min=-1 max=1 mean=-1.5522e-10 std=0.57961 sum1e6=-0.00012207
[PROC] pixel_attention_mask shape=(1, 1024)  ones=1024
[PROC] spatial_shapes=(32, 32)  tokens=1024
[PROC] pixel_values head: -1, -1, -1, -1, -0.992157, -0.992157, -1, -0.984314, -0.984314, -1, -0.976471, -0.976471, -1, -0.968627, -0.968627, -1, -0.960784, -0.960784, -1, -0.952941, -0.952941, -1, -0.945098, -0.945098, -1, -0.937255, -0.937255, -1, -0.929412, -0.929412, -1, -0.921569 ...
[VT][input.pixel_values]   shape=(1, 1024, 768)  min=-1 max=1 mean=6.20882e-10 std=0.580246 sum1e6=0.000488281
[VT][input.attn_mask]      shape=(1, 1024)  ones=1024
[VT][input.spatial_shapes] shape=(1, 2)  first=(32, 32)
[VT][hooks.targeted] attaching to 98 modules
  - vision_model.embeddings.patch_embedding (patch_embedding, Linear)
  - vision_model.encoder.layers.0.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.0.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.0.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.0.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.0.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.0.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.0.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.0.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.1.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.1.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.1.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.1.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.1.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.1.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.1.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.1.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.2.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.2.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.2.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.2.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.2.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.2.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.2.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.2.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.3.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.3.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.3.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.3.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.3.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.3.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.3.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.3.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.4.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.4.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.4.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.4.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.4.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.4.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.4.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.4.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.5.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.5.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.5.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.5.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.5.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.5.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.5.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.5.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.6.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.6.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.6.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.6.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.6.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.6.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.6.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.6.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.7.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.7.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.7.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.7.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.7.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.7.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.7.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.7.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.8.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.8.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.8.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.8.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.8.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.8.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.8.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.8.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.9.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.9.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.9.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.9.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.9.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.9.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.9.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.9.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.10.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.10.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.10.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.10.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.10.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.10.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.10.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.10.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.encoder.layers.11.layer_norm1 (ln1, LayerNorm)
  - vision_model.encoder.layers.11.self_attn.k_proj (attn_k, Linear)
  - vision_model.encoder.layers.11.self_attn.v_proj (attn_v, Linear)
  - vision_model.encoder.layers.11.self_attn.q_proj (attn_q, Linear)
  - vision_model.encoder.layers.11.self_attn.out_proj (attn_out, Linear)
  - vision_model.encoder.layers.11.layer_norm2 (ln2, LayerNorm)
  - vision_model.encoder.layers.11.mlp.fc1 (mlp_fc1, Linear)
  - vision_model.encoder.layers.11.mlp.fc2 (mlp_fc2, Linear)
  - vision_model.post_layernorm (post_layernorm, LayerNorm)
[VT][hooks.leaf_sweep] attaching to 0 extra leaves
[VT][vision_model.embeddings.patch_embedding/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-1 max=1 mean=6.20882e-10 std=0.580246 sum1e6=0.000488281
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_0] shape=[768] showing 24/768: -1, -1, -1, -1, -0.992188, -0.992188, -1, -0.984375, -0.984375, -1, -0.976562, -0.976562, -1, -0.96875, -0.96875, -1, -0.960938, -0.960938, -1, -0.953125, -0.953125, -1, -0.945312, -0.945312 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_64] shape=[768] showing 24/768: -0.75, -1, -0.75, -0.75, -0.992188, -0.742188, -0.75, -0.984375, -0.734375, -0.75, -0.976562, -0.726562, -0.75, -0.96875, -0.71875, -0.75, -0.960938, -0.710938, -0.75, -0.953125, -0.703125, -0.75, -0.945312, -0.695312 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_128] shape=[768] showing 24/768: -0.498047, -1, -0.498047, -0.498047, -0.992188, -0.490234, -0.498047, -0.984375, -0.482422, -0.498047, -0.976562, -0.474609, -0.498047, -0.96875, -0.466797, -0.498047, -0.960938, -0.458984, -0.498047, -0.953125, -0.451172, -0.498047, -0.945312, -0.443359 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_192] shape=[768] showing 24/768: -0.24707, -1, -0.24707, -0.24707, -0.992188, -0.239258, -0.24707, -0.984375, -0.231445, -0.24707, -0.976562, -0.223633, -0.24707, -0.96875, -0.21582, -0.24707, -0.960938, -0.208008, -0.24707, -0.953125, -0.200195, -0.24707, -0.945312, -0.192383 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_256] shape=[768] showing 24/768: 0.00393677, -1, 0.00393677, 0.00393677, -0.992188, 0.0117798, 0.00393677, -0.984375, 0.0196533, 0.00393677, -0.976562, 0.0274658, 0.00393677, -0.96875, 0.0354004, 0.00393677, -0.960938, 0.0432129, 0.00393677, -0.953125, 0.0510254, 0.00393677, -0.945312, 0.0588379 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_320] shape=[768] showing 24/768: 0.255859, -1, 0.255859, 0.255859, -0.992188, 0.263672, 0.255859, -0.984375, 0.271484, 0.255859, -0.976562, 0.279297, 0.255859, -0.96875, 0.287109, 0.255859, -0.960938, 0.294922, 0.255859, -0.953125, 0.302734, 0.255859, -0.945312, 0.310547 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_384] shape=[768] showing 24/768: 0.507812, -1, 0.507812, 0.507812, -0.992188, 0.515625, 0.507812, -0.984375, 0.523438, 0.507812, -0.976562, 0.53125, 0.507812, -0.96875, 0.539062, 0.507812, -0.960938, 0.546875, 0.507812, -0.953125, 0.554688, 0.507812, -0.945312, 0.5625 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_448] shape=[768] showing 24/768: 0.757812, -1, 0.757812, 0.757812, -0.992188, 0.765625, 0.757812, -0.984375, 0.773438, 0.757812, -0.976562, 0.78125, 0.757812, -0.96875, 0.789062, 0.757812, -0.960938, 0.796875, 0.757812, -0.953125, 0.804688, 0.757812, -0.945312, 0.8125 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_512] shape=[768] showing 24/768: -1, -1, -1, -1, -0.992188, -0.992188, -1, -0.984375, -0.984375, -1, -0.976562, -0.976562, -1, -0.96875, -0.96875, -1, -0.960938, -0.960938, -1, -0.953125, -0.953125, -1, -0.945312, -0.945312 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_576] shape=[768] showing 24/768: -0.75, -1, -0.75, -0.75, -0.992188, -0.742188, -0.75, -0.984375, -0.734375, -0.75, -0.976562, -0.726562, -0.75, -0.96875, -0.71875, -0.75, -0.960938, -0.710938, -0.75, -0.953125, -0.703125, -0.75, -0.945312, -0.695312 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_640] shape=[768] showing 24/768: -0.498047, -1, -0.498047, -0.498047, -0.992188, -0.490234, -0.498047, -0.984375, -0.482422, -0.498047, -0.976562, -0.474609, -0.498047, -0.96875, -0.466797, -0.498047, -0.960938, -0.458984, -0.498047, -0.953125, -0.451172, -0.498047, -0.945312, -0.443359 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_704] shape=[768] showing 24/768: -0.24707, -1, -0.24707, -0.24707, -0.992188, -0.239258, -0.24707, -0.984375, -0.231445, -0.24707, -0.976562, -0.223633, -0.24707, -0.96875, -0.21582, -0.24707, -0.960938, -0.208008, -0.24707, -0.953125, -0.200195, -0.24707, -0.945312, -0.192383 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_768] shape=[768] showing 24/768: 0.00393677, -1, 0.00393677, 0.00393677, -0.992188, 0.0117798, 0.00393677, -0.984375, 0.0196533, 0.00393677, -0.976562, 0.0274658, 0.00393677, -0.96875, 0.0354004, 0.00393677, -0.960938, 0.0432129, 0.00393677, -0.953125, 0.0510254, 0.00393677, -0.945312, 0.0588379 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_832] shape=[768] showing 24/768: 0.255859, -1, 0.255859, 0.255859, -0.992188, 0.263672, 0.255859, -0.984375, 0.271484, 0.255859, -0.976562, 0.279297, 0.255859, -0.96875, 0.287109, 0.255859, -0.960938, 0.294922, 0.255859, -0.953125, 0.302734, 0.255859, -0.945312, 0.310547 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_896] shape=[768] showing 24/768: 0.507812, -1, 0.507812, 0.507812, -0.992188, 0.515625, 0.507812, -0.984375, 0.523438, 0.507812, -0.976562, 0.53125, 0.507812, -0.96875, 0.539062, 0.507812, -0.960938, 0.546875, 0.507812, -0.953125, 0.554688, 0.507812, -0.945312, 0.5625 ...
[VT][vision_model.embeddings.patch_embedding/pre[NLH]/item_960] shape=[768] showing 24/768: 0.757812, -1, 0.757812, 0.757812, -0.992188, 0.765625, 0.757812, -0.984375, 0.773438, 0.757812, -0.976562, 0.78125, 0.757812, -0.96875, 0.789062, 0.757812, -0.960938, 0.796875, 0.757812, -0.953125, 0.804688, 0.757812, -0.945312, 0.8125 ...
[VT][vision_model.embeddings.patch_embedding] OUT shape=(1, 1024, 768) layout=NLH  min=-3.78125 max=3.79688 mean=-0.00117569 std=0.58697 sum1e6=-924.6
[VT][vision_model.embeddings.patch_embedding[NLH]/item_0] shape=[768] showing 24/768: 0.275391, -0.341797, 0.949219, 0.824219, 1.49219, -0.25, 0.0280762, -0.546875, -0.223633, 1.60938, 1.10156, -0.902344, -0.882812, -0.441406, -0.251953, -0.392578, 2.79688, -1.27344, -1.13281, 0.292969, 0.980469, 0.0688477, 1.17969, 0.589844 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_64] shape=[768] showing 24/768: 0.0668945, -0.384766, 0.921875, 0.585938, 1.25781, -0.224609, -0.0429688, -0.652344, -0.0561523, 1.16406, 0.875, -0.609375, -0.753906, -0.178711, -0.345703, -0.417969, 2.35938, -1.21875, -0.941406, 0.204102, 0.863281, 0.181641, 1.00781, 0.601562 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_128] shape=[768] showing 24/768: -0.142578, -0.427734, 0.890625, 0.341797, 1.02344, -0.198242, -0.114258, -0.753906, 0.112793, 0.71875, 0.644531, -0.3125, -0.621094, 0.0864258, -0.439453, -0.443359, 1.92969, -1.16406, -0.742188, 0.115234, 0.746094, 0.294922, 0.839844, 0.617188 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_192] shape=[768] showing 24/768: -0.351562, -0.470703, 0.863281, 0.0991211, 0.785156, -0.171875, -0.185547, -0.859375, 0.28125, 0.269531, 0.416016, -0.0179443, -0.488281, 0.349609, -0.535156, -0.46875, 1.5, -1.11719, -0.542969, 0.0267334, 0.625, 0.410156, 0.667969, 0.628906 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_256] shape=[768] showing 24/768: -0.558594, -0.511719, 0.835938, -0.143555, 0.546875, -0.146484, -0.257812, -0.964844, 0.449219, -0.176758, 0.186523, 0.277344, -0.357422, 0.613281, -0.628906, -0.494141, 1.0625, -1.0625, -0.347656, -0.0622559, 0.507812, 0.523438, 0.496094, 0.640625 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_320] shape=[768] showing 24/768: -0.769531, -0.554688, 0.808594, -0.386719, 0.308594, -0.119629, -0.328125, -1.07031, 0.617188, -0.625, -0.043457, 0.570312, -0.224609, 0.878906, -0.722656, -0.519531, 0.632812, -1.00781, -0.149414, -0.151367, 0.390625, 0.636719, 0.324219, 0.652344 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.597656, 0.78125, -0.628906, 0.0703125, -0.09375, -0.400391, -1.17188, 0.785156, -1.07031, -0.273438, 0.867188, -0.0927734, 1.14062, -0.816406, -0.546875, 0.197266, -0.957031, 0.0480957, -0.240234, 0.271484, 0.75, 0.15332, 0.667969 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_448] shape=[768] showing 24/768: -1.1875, -0.640625, 0.75, -0.871094, -0.166016, -0.0673828, -0.470703, -1.27344, 0.953125, -1.51562, -0.503906, 1.16406, 0.0383301, 1.40625, -0.910156, -0.570312, -0.234375, -0.90625, 0.244141, -0.328125, 0.15332, 0.863281, -0.0166016, 0.679688 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_512] shape=[768] showing 24/768: 0.275391, -0.341797, 0.949219, 0.824219, 1.49219, -0.25, 0.0280762, -0.546875, -0.223633, 1.60938, 1.10156, -0.902344, -0.882812, -0.441406, -0.251953, -0.392578, 2.79688, -1.27344, -1.13281, 0.292969, 0.980469, 0.0688477, 1.17969, 0.589844 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_576] shape=[768] showing 24/768: 0.0668945, -0.384766, 0.921875, 0.585938, 1.25781, -0.224609, -0.0429688, -0.652344, -0.0561523, 1.16406, 0.875, -0.609375, -0.753906, -0.178711, -0.345703, -0.417969, 2.35938, -1.21875, -0.941406, 0.204102, 0.863281, 0.181641, 1.00781, 0.601562 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_640] shape=[768] showing 24/768: -0.142578, -0.427734, 0.890625, 0.341797, 1.02344, -0.198242, -0.114258, -0.753906, 0.112793, 0.71875, 0.644531, -0.3125, -0.621094, 0.0864258, -0.439453, -0.443359, 1.92969, -1.16406, -0.742188, 0.115234, 0.746094, 0.294922, 0.839844, 0.617188 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_704] shape=[768] showing 24/768: -0.351562, -0.470703, 0.863281, 0.0991211, 0.785156, -0.171875, -0.185547, -0.859375, 0.28125, 0.269531, 0.416016, -0.0179443, -0.488281, 0.349609, -0.535156, -0.46875, 1.5, -1.11719, -0.542969, 0.0267334, 0.625, 0.410156, 0.667969, 0.628906 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_768] shape=[768] showing 24/768: -0.558594, -0.511719, 0.835938, -0.143555, 0.546875, -0.146484, -0.257812, -0.964844, 0.449219, -0.176758, 0.186523, 0.277344, -0.357422, 0.613281, -0.628906, -0.494141, 1.0625, -1.0625, -0.347656, -0.0622559, 0.507812, 0.523438, 0.496094, 0.640625 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_832] shape=[768] showing 24/768: -0.769531, -0.554688, 0.808594, -0.386719, 0.308594, -0.119629, -0.328125, -1.07031, 0.617188, -0.625, -0.043457, 0.570312, -0.224609, 0.878906, -0.722656, -0.519531, 0.632812, -1.00781, -0.149414, -0.151367, 0.390625, 0.636719, 0.324219, 0.652344 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_896] shape=[768] showing 24/768: -0.976562, -0.597656, 0.78125, -0.628906, 0.0703125, -0.09375, -0.400391, -1.17188, 0.785156, -1.07031, -0.273438, 0.867188, -0.0927734, 1.14062, -0.816406, -0.546875, 0.197266, -0.957031, 0.0480957, -0.240234, 0.271484, 0.75, 0.15332, 0.667969 ...
[VT][vision_model.embeddings.patch_embedding[NLH]/item_960] shape=[768] showing 24/768: -1.1875, -0.640625, 0.75, -0.871094, -0.166016, -0.0673828, -0.470703, -1.27344, 0.953125, -1.51562, -0.503906, 1.16406, 0.0383301, 1.40625, -0.910156, -0.570312, -0.234375, -0.90625, 0.244141, -0.328125, 0.15332, 0.863281, -0.0166016, 0.679688 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.79688 max=3.8125 mean=-0.00124243 std=0.587507 sum1e6=-977.09
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_0] shape=[768] showing 24/768: 0.285156, -0.333984, 0.933594, 0.832031, 1.48438, -0.240234, 0.0996094, -0.535156, -0.225586, 1.625, 1.17969, -0.910156, -0.9375, -0.466797, -0.28125, -0.392578, 2.75, -1.28125, -1.10938, 0.324219, 0.988281, 0.0649414, 1.25, 0.554688 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_64] shape=[768] showing 24/768: 0.0649414, -0.398438, 0.917969, 0.644531, 1.32031, -0.227539, -0.0522461, -0.691406, -0.0458984, 1.16406, 0.890625, -0.574219, -0.765625, -0.202148, -0.365234, -0.425781, 2.35938, -1.23438, -0.914062, 0.210938, 0.832031, 0.232422, 1.02344, 0.613281 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_128] shape=[768] showing 24/768: -0.124023, -0.460938, 0.882812, 0.382812, 1.00781, -0.248047, -0.140625, -0.730469, 0.135742, 0.773438, 0.652344, -0.306641, -0.648438, 0.074707, -0.439453, -0.451172, 1.88281, -1.19531, -0.691406, 0.11084, 0.707031, 0.251953, 0.84375, 0.605469 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_192] shape=[768] showing 24/768: -0.376953, -0.482422, 0.875, 0.0644531, 0.835938, -0.189453, -0.183594, -0.851562, 0.330078, 0.287109, 0.410156, -0.0546875, -0.433594, 0.373047, -0.550781, -0.453125, 1.49219, -1.07812, -0.574219, 0.0498047, 0.621094, 0.431641, 0.644531, 0.605469 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_256] shape=[768] showing 24/768: -0.550781, -0.542969, 0.773438, -0.138672, 0.613281, -0.097168, -0.287109, -1.02344, 0.470703, -0.158203, 0.181641, 0.287109, -0.355469, 0.625, -0.601562, -0.511719, 1.03125, -1.07031, -0.373047, -0.0324707, 0.492188, 0.566406, 0.490234, 0.617188 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_320] shape=[768] showing 24/768: -0.777344, -0.585938, 0.78125, -0.4375, 0.330078, -0.121582, -0.359375, -1.09375, 0.570312, -0.6875, -0.0307617, 0.59375, -0.217773, 0.886719, -0.6875, -0.480469, 0.585938, -1.04688, -0.191406, -0.147461, 0.412109, 0.644531, 0.392578, 0.664062 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.601562, 0.773438, -0.625, 0.123535, -0.11084, -0.427734, -1.13281, 0.828125, -1.02344, -0.259766, 0.859375, -0.163086, 1.125, -0.804688, -0.527344, 0.175781, -1.04688, 0.00244141, -0.253906, 0.300781, 0.753906, 0.168945, 0.664062 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_448] shape=[768] showing 24/768: -1.14844, -0.628906, 0.789062, -0.867188, -0.168945, -0.0913086, -0.482422, -1.24219, 0.925781, -1.49219, -0.511719, 1.14844, 0.0266113, 1.39844, -0.898438, -0.523438, -0.209961, -0.949219, 0.208008, -0.322266, 0.15918, 0.878906, -0.050293, 0.703125 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_512] shape=[768] showing 24/768: 0.291016, -0.316406, 0.972656, 0.84375, 1.44531, -0.265625, 0.0229492, -0.5625, -0.236328, 1.60156, 1.14062, -0.875, -0.851562, -0.453125, -0.197266, -0.380859, 2.82812, -1.26562, -1.09375, 0.302734, 0.976562, 0.0598145, 1.17969, 0.605469 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_576] shape=[768] showing 24/768: 0.09375, -0.363281, 0.964844, 0.652344, 1.27344, -0.207031, -0.0878906, -0.636719, -0.0864258, 1.1875, 0.910156, -0.605469, -0.769531, -0.21875, -0.347656, -0.40625, 2.375, -1.21094, -0.925781, 0.22168, 0.929688, 0.170898, 0.996094, 0.660156 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_640] shape=[768] showing 24/768: -0.144531, -0.425781, 0.886719, 0.361328, 1.03125, -0.220703, -0.148438, -0.699219, 0.101562, 0.730469, 0.675781, -0.335938, -0.625, 0.0578613, -0.433594, -0.462891, 1.9375, -1.15625, -0.753906, 0.101562, 0.785156, 0.271484, 0.832031, 0.597656 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_704] shape=[768] showing 24/768: -0.40625, -0.527344, 0.839844, 0.125977, 0.800781, -0.208008, -0.206055, -0.878906, 0.318359, 0.273438, 0.439453, -0.00842285, -0.507812, 0.306641, -0.535156, -0.5, 1.49219, -1.1875, -0.5625, 0.0358887, 0.699219, 0.388672, 0.691406, 0.605469 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_768] shape=[768] showing 24/768: -0.59375, -0.519531, 0.8125, -0.141602, 0.589844, -0.147461, -0.248047, -0.980469, 0.482422, -0.166016, 0.152344, 0.294922, -0.396484, 0.605469, -0.617188, -0.503906, 1.07812, -1.04688, -0.375, -0.043457, 0.511719, 0.519531, 0.511719, 0.609375 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_832] shape=[768] showing 24/768: -0.761719, -0.589844, 0.832031, -0.398438, 0.361328, -0.105957, -0.353516, -1.03906, 0.664062, -0.644531, -0.0898438, 0.582031, -0.253906, 0.875, -0.71875, -0.464844, 0.636719, -1.00781, -0.15625, -0.148438, 0.398438, 0.636719, 0.333984, 0.640625 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_896] shape=[768] showing 24/768: -0.9375, -0.628906, 0.804688, -0.636719, 0.0639648, -0.0358887, -0.392578, -1.17969, 0.773438, -1.0625, -0.253906, 0.910156, -0.0581055, 1.125, -0.867188, -0.5, 0.160156, -0.949219, 0.0395508, -0.289062, 0.263672, 0.683594, 0.149414, 0.652344 ...
[VT][vision_model.encoder.layers.0.layer_norm1/pre[NLH]/item_960] shape=[768] showing 24/768: -1.17188, -0.613281, 0.78125, -0.847656, -0.168945, -0.0288086, -0.476562, -1.26562, 0.9375, -1.52344, -0.488281, 1.1875, -0.00195312, 1.42188, -0.921875, -0.519531, -0.242188, -0.921875, 0.227539, -0.306641, 0.202148, 0.878906, 0.029541, 0.679688 ...
[VT][vision_model.encoder.layers.0.layer_norm1] OUT shape=(1, 1024, 768) layout=NLH  min=-3.96875 max=4.21875 mean=-7.23172e-07 std=0.999993 sum1e6=-0.568726
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_0] shape=[768] showing 24/768: 0.0471191, -0.632812, 0.761719, 0.648438, 1.36719, -0.53125, -0.157227, -0.855469, -0.515625, 1.52344, 1.03125, -1.26562, -1.29688, -0.78125, -0.574219, -0.699219, 2.76562, -1.67188, -1.48438, 0.090332, 0.820312, -0.195312, 1.10938, 0.34375 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_64] shape=[768] showing 24/768: -0.182617, -0.792969, 0.9375, 0.578125, 1.46875, -0.566406, -0.335938, -1.17969, -0.328125, 1.26562, 0.902344, -1.02344, -1.27344, -0.535156, -0.746094, -0.828125, 2.82812, -1.89062, -1.46875, 0.00927734, 0.824219, 0.0375977, 1.07812, 0.539062 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_128] shape=[768] showing 24/768: -0.455078, -0.980469, 1.11719, 0.335938, 1.3125, -0.648438, -0.480469, -1.39844, -0.0490723, 0.945312, 0.757812, -0.738281, -1.27344, -0.144531, -0.945312, -0.964844, 2.67188, -2.125, -1.33594, -0.0878906, 0.84375, 0.131836, 1.05469, 0.683594 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_192] shape=[768] showing 24/768: -0.890625, -1.07031, 1.3125, -0.114258, 1.24219, -0.558594, -0.550781, -1.71875, 0.351562, 0.277344, 0.492188, -0.324219, -0.988281, 0.427734, -1.19531, -1.02344, 2.39062, -2.125, -1.23438, -0.139648, 0.863281, 0.53125, 0.902344, 0.835938 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_256] shape=[768] showing 24/768: -1.14062, -1.125, 1.20312, -0.410156, 0.921875, -0.335938, -0.671875, -1.97656, 0.667969, -0.445312, 0.157227, 0.34375, -0.792969, 0.941406, -1.22656, -1.07031, 1.66406, -2.0625, -0.824219, -0.22168, 0.707031, 0.839844, 0.703125, 0.929688 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_320] shape=[768] showing 24/768: -1.32812, -1.02344, 1.15625, -0.785156, 0.435547, -0.283203, -0.664062, -1.83594, 0.820312, -1.1875, -0.138672, 0.855469, -0.4375, 1.32031, -1.1875, -0.855469, 0.84375, -1.75781, -0.394531, -0.324219, 0.566406, 0.9375, 0.535156, 0.96875 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_384] shape=[768] showing 24/768: -1.34375, -0.835938, 1.02344, -0.867188, 0.142578, -0.173828, -0.601562, -1.55469, 1.09375, -1.40625, -0.375, 1.14062, -0.244141, 1.5, -1.10938, -0.738281, 0.213867, -1.4375, -0.0206299, -0.367188, 0.382812, 0.996094, 0.204102, 0.875 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_448] shape=[768] showing 24/768: -1.28125, -0.691406, 0.914062, -0.960938, -0.171875, -0.0834961, -0.527344, -1.39062, 1.07031, -1.67188, -0.558594, 1.32031, 0.0500488, 1.60156, -0.996094, -0.574219, -0.217773, -1.05469, 0.255859, -0.345703, 0.200195, 1.01562, -0.0368652, 0.816406 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_512] shape=[768] showing 24/768: 0.0556641, -0.613281, 0.808594, 0.664062, 1.32812, -0.558594, -0.240234, -0.886719, -0.527344, 1.5, 0.992188, -1.22656, -1.20312, -0.765625, -0.482422, -0.683594, 2.85938, -1.66406, -1.46875, 0.0683594, 0.8125, -0.199219, 1.03906, 0.402344 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_576] shape=[768] showing 24/768: -0.147461, -0.75, 1, 0.589844, 1.40625, -0.542969, -0.386719, -1.10938, -0.384766, 1.29688, 0.929688, -1.07031, -1.28125, -0.558594, -0.726562, -0.804688, 2.85938, -1.86719, -1.49219, 0.0213623, 0.953125, -0.0456543, 1.03906, 0.597656 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_640] shape=[768] showing 24/768: -0.486328, -0.925781, 1.125, 0.302734, 1.35156, -0.605469, -0.492188, -1.35156, -0.102539, 0.878906, 0.792969, -0.785156, -1.23438, -0.170898, -0.9375, -0.984375, 2.76562, -2.0625, -1.4375, -0.102539, 0.964844, 0.163086, 1.03906, 0.671875 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_704] shape=[768] showing 24/768: -0.941406, -1.15625, 1.25, -0.00610352, 1.17969, -0.59375, -0.589844, -1.77344, 0.332031, 0.251953, 0.542969, -0.242188, -1.11719, 0.310547, -1.16406, -1.10156, 2.39062, -2.3125, -1.21094, -0.164062, 1, 0.455078, 0.988281, 0.835938 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_768] shape=[768] showing 24/768: -1.21875, -1.08594, 1.27344, -0.417969, 0.878906, -0.427734, -0.605469, -1.90625, 0.691406, -0.460938, 0.104004, 0.357422, -0.871094, 0.910156, -1.25781, -1.0625, 1.75, -2.03125, -0.832031, -0.243164, 0.742188, 0.753906, 0.742188, 0.914062 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_832] shape=[768] showing 24/768: -1.3125, -1.03125, 1.24219, -0.730469, 0.488281, -0.259766, -0.65625, -1.75781, 0.972656, -1.125, -0.234375, 0.839844, -0.498047, 1.3125, -1.24219, -0.835938, 0.929688, -1.70312, -0.339844, -0.328125, 0.546875, 0.929688, 0.443359, 0.933594 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_896] shape=[768] showing 24/768: -1.29688, -0.878906, 1.0625, -0.890625, 0.0595703, -0.0756836, -0.558594, -1.625, 1.02344, -1.46875, -0.371094, 1.20312, -0.105957, 1.49219, -1.20312, -0.703125, 0.189453, -1.3125, 0.0264893, -0.417969, 0.330078, 0.898438, 0.174805, 0.855469 ...
[VT][vision_model.encoder.layers.0.layer_norm1[NLH]/item_960] shape=[768] showing 24/768: -1.3125, -0.675781, 0.90625, -0.941406, -0.172852, -0.013916, -0.523438, -1.41406, 1.08594, -1.71094, -0.535156, 1.36719, 0.0166016, 1.63281, -1.02344, -0.570312, -0.255859, -1.02344, 0.277344, -0.330078, 0.248047, 1.01562, 0.0522461, 0.789062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.96875 max=4.21875 mean=-7.23172e-07 std=0.999993 sum1e6=-0.568726
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.0471191, -0.632812, 0.761719, 0.648438, 1.36719, -0.53125, -0.157227, -0.855469, -0.515625, 1.52344, 1.03125, -1.26562, -1.29688, -0.78125, -0.574219, -0.699219, 2.76562, -1.67188, -1.48438, 0.090332, 0.820312, -0.195312, 1.10938, 0.34375 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_64] shape=[768] showing 24/768: -0.182617, -0.792969, 0.9375, 0.578125, 1.46875, -0.566406, -0.335938, -1.17969, -0.328125, 1.26562, 0.902344, -1.02344, -1.27344, -0.535156, -0.746094, -0.828125, 2.82812, -1.89062, -1.46875, 0.00927734, 0.824219, 0.0375977, 1.07812, 0.539062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_128] shape=[768] showing 24/768: -0.455078, -0.980469, 1.11719, 0.335938, 1.3125, -0.648438, -0.480469, -1.39844, -0.0490723, 0.945312, 0.757812, -0.738281, -1.27344, -0.144531, -0.945312, -0.964844, 2.67188, -2.125, -1.33594, -0.0878906, 0.84375, 0.131836, 1.05469, 0.683594 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.890625, -1.07031, 1.3125, -0.114258, 1.24219, -0.558594, -0.550781, -1.71875, 0.351562, 0.277344, 0.492188, -0.324219, -0.988281, 0.427734, -1.19531, -1.02344, 2.39062, -2.125, -1.23438, -0.139648, 0.863281, 0.53125, 0.902344, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -1.14062, -1.125, 1.20312, -0.410156, 0.921875, -0.335938, -0.671875, -1.97656, 0.667969, -0.445312, 0.157227, 0.34375, -0.792969, 0.941406, -1.22656, -1.07031, 1.66406, -2.0625, -0.824219, -0.22168, 0.707031, 0.839844, 0.703125, 0.929688 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -1.32812, -1.02344, 1.15625, -0.785156, 0.435547, -0.283203, -0.664062, -1.83594, 0.820312, -1.1875, -0.138672, 0.855469, -0.4375, 1.32031, -1.1875, -0.855469, 0.84375, -1.75781, -0.394531, -0.324219, 0.566406, 0.9375, 0.535156, 0.96875 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.34375, -0.835938, 1.02344, -0.867188, 0.142578, -0.173828, -0.601562, -1.55469, 1.09375, -1.40625, -0.375, 1.14062, -0.244141, 1.5, -1.10938, -0.738281, 0.213867, -1.4375, -0.0206299, -0.367188, 0.382812, 0.996094, 0.204102, 0.875 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.28125, -0.691406, 0.914062, -0.960938, -0.171875, -0.0834961, -0.527344, -1.39062, 1.07031, -1.67188, -0.558594, 1.32031, 0.0500488, 1.60156, -0.996094, -0.574219, -0.217773, -1.05469, 0.255859, -0.345703, 0.200195, 1.01562, -0.0368652, 0.816406 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.0556641, -0.613281, 0.808594, 0.664062, 1.32812, -0.558594, -0.240234, -0.886719, -0.527344, 1.5, 0.992188, -1.22656, -1.20312, -0.765625, -0.482422, -0.683594, 2.85938, -1.66406, -1.46875, 0.0683594, 0.8125, -0.199219, 1.03906, 0.402344 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_576] shape=[768] showing 24/768: -0.147461, -0.75, 1, 0.589844, 1.40625, -0.542969, -0.386719, -1.10938, -0.384766, 1.29688, 0.929688, -1.07031, -1.28125, -0.558594, -0.726562, -0.804688, 2.85938, -1.86719, -1.49219, 0.0213623, 0.953125, -0.0456543, 1.03906, 0.597656 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_640] shape=[768] showing 24/768: -0.486328, -0.925781, 1.125, 0.302734, 1.35156, -0.605469, -0.492188, -1.35156, -0.102539, 0.878906, 0.792969, -0.785156, -1.23438, -0.170898, -0.9375, -0.984375, 2.76562, -2.0625, -1.4375, -0.102539, 0.964844, 0.163086, 1.03906, 0.671875 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.941406, -1.15625, 1.25, -0.00610352, 1.17969, -0.59375, -0.589844, -1.77344, 0.332031, 0.251953, 0.542969, -0.242188, -1.11719, 0.310547, -1.16406, -1.10156, 2.39062, -2.3125, -1.21094, -0.164062, 1, 0.455078, 0.988281, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -1.21875, -1.08594, 1.27344, -0.417969, 0.878906, -0.427734, -0.605469, -1.90625, 0.691406, -0.460938, 0.104004, 0.357422, -0.871094, 0.910156, -1.25781, -1.0625, 1.75, -2.03125, -0.832031, -0.243164, 0.742188, 0.753906, 0.742188, 0.914062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -1.3125, -1.03125, 1.24219, -0.730469, 0.488281, -0.259766, -0.65625, -1.75781, 0.972656, -1.125, -0.234375, 0.839844, -0.498047, 1.3125, -1.24219, -0.835938, 0.929688, -1.70312, -0.339844, -0.328125, 0.546875, 0.929688, 0.443359, 0.933594 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.29688, -0.878906, 1.0625, -0.890625, 0.0595703, -0.0756836, -0.558594, -1.625, 1.02344, -1.46875, -0.371094, 1.20312, -0.105957, 1.49219, -1.20312, -0.703125, 0.189453, -1.3125, 0.0264893, -0.417969, 0.330078, 0.898438, 0.174805, 0.855469 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.3125, -0.675781, 0.90625, -0.941406, -0.172852, -0.013916, -0.523438, -1.41406, 1.08594, -1.71094, -0.535156, 1.36719, 0.0166016, 1.63281, -1.02344, -0.570312, -0.255859, -1.02344, 0.277344, -0.330078, 0.248047, 1.01562, 0.0522461, 0.789062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.03125 max=3.79688 mean=-0.00243278 std=0.996111 sum1e6=-1913.22
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_0] shape=[768] showing 24/768: -0.0668945, 0.992188, 0.408203, 0.0515137, 0.882812, 0.738281, -0.675781, 0.396484, -0.789062, 0.0267334, 2.46875, 1.01562, -1.02344, -0.917969, -0.0629883, -0.714844, -0.972656, -0.976562, -0.0339355, 0.910156, -1.10156, 0.182617, 0.0991211, 0.414062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_64] shape=[768] showing 24/768: -0.081543, 1.125, -0.0454102, 0.188477, 0.90625, 0.589844, -0.464844, 0.347656, -0.59375, -0.124512, 2.5, 0.871094, -0.753906, -1.07031, -0.00306702, -0.734375, -0.875, -1, -0.328125, 0.644531, -0.859375, 0.269531, 0.167969, 0.558594 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_128] shape=[768] showing 24/768: 0.0186768, 1.08594, -0.585938, 0.245117, 0.890625, 0.310547, -0.0698242, 0.345703, -0.371094, -0.314453, 2.42188, 0.609375, -0.416016, -1.1875, 0.0432129, -0.640625, -0.746094, -0.867188, -0.644531, 0.195312, -0.503906, 0.332031, 0.294922, 0.785156 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_192] shape=[768] showing 24/768: 0.120117, 1.0625, -1.41406, 0.324219, 0.839844, -0.0629883, 0.455078, 0.316406, 0.136719, -0.386719, 2.1875, 0.168945, 0.0498047, -1.32812, 0.181641, -0.435547, -0.445312, -0.445312, -1.05469, -0.417969, 0.195312, 0.240234, 0.408203, 1.05469 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_256] shape=[768] showing 24/768: 0.217773, 0.851562, -2, 0.433594, 0.691406, -0.400391, 0.953125, 0.155273, 0.498047, -0.570312, 1.59375, -0.253906, 0.734375, -1.22656, 0.191406, -0.240234, -0.11377, -0.168945, -1.33594, -0.953125, 0.800781, 0.296875, 0.486328, 1.21094 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_320] shape=[768] showing 24/768: 0.168945, 0.621094, -2.40625, 0.494141, 0.574219, -0.746094, 1.21875, 0.0262451, 0.914062, -0.648438, 0.984375, -0.707031, 1.1875, -1.03125, 0.191406, 0.00723267, 0.292969, 0.0917969, -1.50781, -1.48438, 1.17969, 0.251953, 0.5625, 1.14062 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_384] shape=[768] showing 24/768: 0.123047, 0.421875, -2.5, 0.476562, 0.332031, -0.917969, 1.36719, -0.0771484, 1.0625, -0.667969, 0.417969, -0.984375, 1.50781, -0.78125, 0.208008, 0.181641, 0.492188, 0.373047, -1.47656, -1.75, 1.48438, 0.25, 0.597656, 1.07031 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_448] shape=[768] showing 24/768: 0.134766, 0.232422, -2.54688, 0.435547, 0.158203, -1.02344, 1.46875, -0.121094, 1.19531, -0.636719, 0.000595093, -1.04688, 1.65625, -0.605469, 0.171875, 0.25, 0.613281, 0.632812, -1.46094, -1.85156, 1.64844, 0.233398, 0.539062, 1 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_512] shape=[768] showing 24/768: -0.0732422, 0.976562, 0.367188, 0.0397949, 0.871094, 0.769531, -0.632812, 0.398438, -0.730469, 0.000427246, 2.45312, 1.03125, -1.00781, -0.902344, -0.0568848, -0.78125, -0.980469, -0.953125, -0.177734, 0.90625, -1.07812, 0.241211, 0.0756836, 0.382812 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_576] shape=[768] showing 24/768: 0.00622559, 1, 0.0015564, 0.117676, 0.894531, 0.585938, -0.367188, 0.347656, -0.636719, -0.103027, 2.5, 0.871094, -0.777344, -1.07031, -0.0045166, -0.753906, -0.84375, -0.902344, -0.341797, 0.621094, -0.828125, 0.285156, 0.178711, 0.59375 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_640] shape=[768] showing 24/768: 0.0200195, 1.08594, -0.582031, 0.229492, 0.921875, 0.25, 0.0544434, 0.3125, -0.269531, -0.238281, 2.48438, 0.621094, -0.449219, -1.15625, -0.00558472, -0.613281, -0.671875, -0.792969, -0.6875, 0.200195, -0.447266, 0.351562, 0.335938, 0.753906 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_704] shape=[768] showing 24/768: 0.0183105, 0.9375, -1.24219, 0.339844, 0.894531, 0.0332031, 0.396484, 0.208008, 0.161133, -0.404297, 2.17188, 0.302734, 0.125, -1.27344, 0.0932617, -0.46875, -0.416016, -0.515625, -1.10156, -0.367188, 0.145508, 0.355469, 0.425781, 0.992188 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_768] shape=[768] showing 24/768: 0.0214844, 0.800781, -2, 0.519531, 0.757812, -0.345703, 0.832031, 0.125977, 0.65625, -0.542969, 1.60156, -0.212891, 0.664062, -1.25, 0.1875, -0.15918, -0.100098, -0.165039, -1.375, -0.972656, 0.777344, 0.417969, 0.445312, 1.13281 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_832] shape=[768] showing 24/768: 0.177734, 0.535156, -2.42188, 0.542969, 0.523438, -0.6875, 1.22656, -0.0634766, 0.898438, -0.632812, 0.957031, -0.691406, 1.125, -1.00781, 0.367188, 0.00588989, 0.229492, 0.152344, -1.46875, -1.53125, 1.21875, 0.382812, 0.523438, 1.17969 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_896] shape=[768] showing 24/768: 0.121582, 0.423828, -2.5, 0.490234, 0.349609, -0.867188, 1.41406, -0.124512, 1.13281, -0.675781, 0.433594, -0.847656, 1.46094, -0.933594, 0.234375, 0.207031, 0.515625, 0.423828, -1.50781, -1.72656, 1.47656, 0.306641, 0.535156, 1.0625 ...
[VT][vision_model.encoder.layers.0.self_attn.q_proj[NLH]/item_960] shape=[768] showing 24/768: 0.0932617, 0.285156, -2.48438, 0.445312, 0.222656, -1.02344, 1.48438, -0.168945, 1.27344, -0.636719, -0.0217285, -0.992188, 1.61719, -0.710938, 0.208008, 0.308594, 0.59375, 0.582031, -1.375, -1.77344, 1.65625, 0.210938, 0.486328, 1.01562 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.96875 max=4.21875 mean=-7.23172e-07 std=0.999993 sum1e6=-0.568726
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.0471191, -0.632812, 0.761719, 0.648438, 1.36719, -0.53125, -0.157227, -0.855469, -0.515625, 1.52344, 1.03125, -1.26562, -1.29688, -0.78125, -0.574219, -0.699219, 2.76562, -1.67188, -1.48438, 0.090332, 0.820312, -0.195312, 1.10938, 0.34375 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_64] shape=[768] showing 24/768: -0.182617, -0.792969, 0.9375, 0.578125, 1.46875, -0.566406, -0.335938, -1.17969, -0.328125, 1.26562, 0.902344, -1.02344, -1.27344, -0.535156, -0.746094, -0.828125, 2.82812, -1.89062, -1.46875, 0.00927734, 0.824219, 0.0375977, 1.07812, 0.539062 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_128] shape=[768] showing 24/768: -0.455078, -0.980469, 1.11719, 0.335938, 1.3125, -0.648438, -0.480469, -1.39844, -0.0490723, 0.945312, 0.757812, -0.738281, -1.27344, -0.144531, -0.945312, -0.964844, 2.67188, -2.125, -1.33594, -0.0878906, 0.84375, 0.131836, 1.05469, 0.683594 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.890625, -1.07031, 1.3125, -0.114258, 1.24219, -0.558594, -0.550781, -1.71875, 0.351562, 0.277344, 0.492188, -0.324219, -0.988281, 0.427734, -1.19531, -1.02344, 2.39062, -2.125, -1.23438, -0.139648, 0.863281, 0.53125, 0.902344, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -1.14062, -1.125, 1.20312, -0.410156, 0.921875, -0.335938, -0.671875, -1.97656, 0.667969, -0.445312, 0.157227, 0.34375, -0.792969, 0.941406, -1.22656, -1.07031, 1.66406, -2.0625, -0.824219, -0.22168, 0.707031, 0.839844, 0.703125, 0.929688 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -1.32812, -1.02344, 1.15625, -0.785156, 0.435547, -0.283203, -0.664062, -1.83594, 0.820312, -1.1875, -0.138672, 0.855469, -0.4375, 1.32031, -1.1875, -0.855469, 0.84375, -1.75781, -0.394531, -0.324219, 0.566406, 0.9375, 0.535156, 0.96875 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.34375, -0.835938, 1.02344, -0.867188, 0.142578, -0.173828, -0.601562, -1.55469, 1.09375, -1.40625, -0.375, 1.14062, -0.244141, 1.5, -1.10938, -0.738281, 0.213867, -1.4375, -0.0206299, -0.367188, 0.382812, 0.996094, 0.204102, 0.875 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.28125, -0.691406, 0.914062, -0.960938, -0.171875, -0.0834961, -0.527344, -1.39062, 1.07031, -1.67188, -0.558594, 1.32031, 0.0500488, 1.60156, -0.996094, -0.574219, -0.217773, -1.05469, 0.255859, -0.345703, 0.200195, 1.01562, -0.0368652, 0.816406 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.0556641, -0.613281, 0.808594, 0.664062, 1.32812, -0.558594, -0.240234, -0.886719, -0.527344, 1.5, 0.992188, -1.22656, -1.20312, -0.765625, -0.482422, -0.683594, 2.85938, -1.66406, -1.46875, 0.0683594, 0.8125, -0.199219, 1.03906, 0.402344 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_576] shape=[768] showing 24/768: -0.147461, -0.75, 1, 0.589844, 1.40625, -0.542969, -0.386719, -1.10938, -0.384766, 1.29688, 0.929688, -1.07031, -1.28125, -0.558594, -0.726562, -0.804688, 2.85938, -1.86719, -1.49219, 0.0213623, 0.953125, -0.0456543, 1.03906, 0.597656 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_640] shape=[768] showing 24/768: -0.486328, -0.925781, 1.125, 0.302734, 1.35156, -0.605469, -0.492188, -1.35156, -0.102539, 0.878906, 0.792969, -0.785156, -1.23438, -0.170898, -0.9375, -0.984375, 2.76562, -2.0625, -1.4375, -0.102539, 0.964844, 0.163086, 1.03906, 0.671875 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.941406, -1.15625, 1.25, -0.00610352, 1.17969, -0.59375, -0.589844, -1.77344, 0.332031, 0.251953, 0.542969, -0.242188, -1.11719, 0.310547, -1.16406, -1.10156, 2.39062, -2.3125, -1.21094, -0.164062, 1, 0.455078, 0.988281, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -1.21875, -1.08594, 1.27344, -0.417969, 0.878906, -0.427734, -0.605469, -1.90625, 0.691406, -0.460938, 0.104004, 0.357422, -0.871094, 0.910156, -1.25781, -1.0625, 1.75, -2.03125, -0.832031, -0.243164, 0.742188, 0.753906, 0.742188, 0.914062 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -1.3125, -1.03125, 1.24219, -0.730469, 0.488281, -0.259766, -0.65625, -1.75781, 0.972656, -1.125, -0.234375, 0.839844, -0.498047, 1.3125, -1.24219, -0.835938, 0.929688, -1.70312, -0.339844, -0.328125, 0.546875, 0.929688, 0.443359, 0.933594 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.29688, -0.878906, 1.0625, -0.890625, 0.0595703, -0.0756836, -0.558594, -1.625, 1.02344, -1.46875, -0.371094, 1.20312, -0.105957, 1.49219, -1.20312, -0.703125, 0.189453, -1.3125, 0.0264893, -0.417969, 0.330078, 0.898438, 0.174805, 0.855469 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.3125, -0.675781, 0.90625, -0.941406, -0.172852, -0.013916, -0.523438, -1.41406, 1.08594, -1.71094, -0.535156, 1.36719, 0.0166016, 1.63281, -1.02344, -0.570312, -0.255859, -1.02344, 0.277344, -0.330078, 0.248047, 1.01562, 0.0522461, 0.789062 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.21875 max=4.21875 mean=-0.00172296 std=0.994334 sum1e6=-1354.99
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_0] shape=[768] showing 24/768: -0.496094, -0.429688, -0.259766, -1.5625, -1.14844, -0.53125, 1.83594, 0.0400391, 1.3125, 0.757812, 0.816406, -0.535156, -0.369141, -0.0317383, 1.91406, -1.61719, 1.66406, -1.75, 0.235352, -1.35938, 2.20312, -0.135742, -0.208984, -1.02344 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_64] shape=[768] showing 24/768: -0.503906, -0.707031, -0.170898, -1.47656, -1.02344, -0.707031, 1.67969, 0.102539, 1.20312, 0.570312, 0.820312, -0.71875, -0.480469, 0.12793, 1.94531, -1.50781, 1.82812, -1.67188, -0.0454102, -1.375, 2.17188, 0.0410156, -0.333984, -0.640625 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_128] shape=[768] showing 24/768: -0.492188, -1.03906, -0.0834961, -1.21094, -0.769531, -0.914062, 1.39062, 0.11377, 0.90625, 0.419922, 0.65625, -0.933594, -0.5, 0.302734, 1.94531, -1.17188, 2.0625, -1.46094, -0.400391, -1.34375, 2.01562, 0.199219, -0.484375, -0.142578 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_192] shape=[768] showing 24/768: -0.429688, -1.29688, 0.168945, -0.941406, -0.328125, -1.07812, 0.882812, 0.104004, 0.396484, 0.117676, 0.478516, -1.07031, -0.589844, 0.539062, 1.65625, -0.855469, 2.03125, -1.10938, -0.796875, -1.07812, 1.57812, 0.376953, -0.570312, 0.5 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_256] shape=[768] showing 24/768: -0.275391, -1.44531, 0.283203, -0.498047, 0.105957, -1.07031, 0.196289, 0.12793, -0.0415039, -0.333984, 0.120117, -1.14844, -0.609375, 0.671875, 1.26562, -0.291016, 1.89062, -0.542969, -1.19531, -0.773438, 0.984375, 0.492188, -0.539062, 1.23438 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_320] shape=[768] showing 24/768: -0.155273, -1.36719, 0.330078, -0.0800781, 0.414062, -1.09375, -0.451172, 0.125977, -0.472656, -0.625, -0.171875, -1.07812, -0.535156, 0.835938, 0.703125, 0.246094, 1.50781, 0.0795898, -1.4375, -0.458984, 0.40625, 0.574219, -0.558594, 1.8125 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_384] shape=[768] showing 24/768: -0.0179443, -1.375, 0.365234, 0.289062, 0.683594, -1.03125, -0.9375, 0.129883, -0.808594, -0.855469, -0.351562, -1.01562, -0.523438, 0.886719, 0.201172, 0.671875, 1.19531, 0.4375, -1.42969, -0.0177002, -0.178711, 0.664062, -0.582031, 2.01562 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_448] shape=[768] showing 24/768: 0.0917969, -1.25, 0.417969, 0.566406, 0.851562, -0.929688, -1.21094, 0.0805664, -1.02344, -0.96875, -0.425781, -0.890625, -0.494141, 0.832031, -0.0908203, 0.882812, 0.910156, 0.707031, -1.46875, 0.235352, -0.550781, 0.71875, -0.425781, 2.125 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_512] shape=[768] showing 24/768: -0.523438, -0.46875, -0.173828, -1.55469, -1.11719, -0.546875, 1.875, -0.00338745, 1.27344, 0.730469, 0.847656, -0.566406, -0.371094, -0.0568848, 1.95312, -1.57812, 1.58594, -1.75, 0.209961, -1.42969, 2.23438, -0.118652, -0.234375, -1.10156 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_576] shape=[768] showing 24/768: -0.539062, -0.648438, -0.216797, -1.42969, -1, -0.742188, 1.78125, 0.0407715, 1.14062, 0.636719, 0.742188, -0.691406, -0.478516, 0.081543, 1.97656, -1.50781, 1.79688, -1.67188, -0.0393066, -1.42969, 2.25, -0.0859375, -0.371094, -0.703125 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_640] shape=[768] showing 24/768: -0.492188, -1.02344, -0.134766, -1.25, -0.800781, -0.925781, 1.45312, 0.152344, 0.945312, 0.400391, 0.550781, -0.875, -0.484375, 0.269531, 1.91406, -1.21875, 2.01562, -1.53906, -0.34375, -1.29688, 2.10938, 0.219727, -0.457031, -0.157227 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_704] shape=[768] showing 24/768: -0.341797, -1.28906, -0.0170898, -1.03906, -0.447266, -1.07812, 0.933594, 0.120605, 0.503906, 0.0727539, 0.369141, -1.05469, -0.613281, 0.503906, 1.67969, -0.875, 2.15625, -1.14062, -0.726562, -1.10156, 1.52344, 0.318359, -0.554688, 0.605469 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_768] shape=[768] showing 24/768: -0.285156, -1.4375, 0.273438, -0.458984, 0.115234, -1.14844, 0.257812, 0.155273, -0.0693359, -0.291016, 0.161133, -1.10156, -0.566406, 0.628906, 1.28125, -0.314453, 1.94531, -0.5625, -1.15625, -0.738281, 0.925781, 0.503906, -0.546875, 1.35938 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_832] shape=[768] showing 24/768: -0.170898, -1.45312, 0.414062, -0.0118408, 0.535156, -1.15625, -0.492188, 0.104004, -0.419922, -0.558594, -0.0673828, -1.10938, -0.527344, 0.722656, 0.71875, 0.320312, 1.54688, 0.00205994, -1.42969, -0.219727, 0.367188, 0.582031, -0.535156, 1.77344 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_896] shape=[768] showing 24/768: -0.0544434, -1.35938, 0.462891, 0.298828, 0.71875, -1.02344, -0.894531, 0.0976562, -0.816406, -0.824219, -0.326172, -0.984375, -0.503906, 0.863281, 0.277344, 0.699219, 1.20312, 0.435547, -1.51562, 0.0471191, -0.201172, 0.632812, -0.486328, 2.07812 ...
[VT][vision_model.encoder.layers.0.self_attn.k_proj[NLH]/item_960] shape=[768] showing 24/768: 0.0213623, -1.23438, 0.4375, 0.546875, 0.851562, -0.9375, -1.1875, 0.111328, -1.05469, -0.960938, -0.464844, -0.832031, -0.457031, 0.75, -0.103516, 0.929688, 0.964844, 0.753906, -1.50781, 0.196289, -0.601562, 0.648438, -0.431641, 2.28125 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.96875 max=4.21875 mean=-7.23172e-07 std=0.999993 sum1e6=-0.568726
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.0471191, -0.632812, 0.761719, 0.648438, 1.36719, -0.53125, -0.157227, -0.855469, -0.515625, 1.52344, 1.03125, -1.26562, -1.29688, -0.78125, -0.574219, -0.699219, 2.76562, -1.67188, -1.48438, 0.090332, 0.820312, -0.195312, 1.10938, 0.34375 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_64] shape=[768] showing 24/768: -0.182617, -0.792969, 0.9375, 0.578125, 1.46875, -0.566406, -0.335938, -1.17969, -0.328125, 1.26562, 0.902344, -1.02344, -1.27344, -0.535156, -0.746094, -0.828125, 2.82812, -1.89062, -1.46875, 0.00927734, 0.824219, 0.0375977, 1.07812, 0.539062 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_128] shape=[768] showing 24/768: -0.455078, -0.980469, 1.11719, 0.335938, 1.3125, -0.648438, -0.480469, -1.39844, -0.0490723, 0.945312, 0.757812, -0.738281, -1.27344, -0.144531, -0.945312, -0.964844, 2.67188, -2.125, -1.33594, -0.0878906, 0.84375, 0.131836, 1.05469, 0.683594 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.890625, -1.07031, 1.3125, -0.114258, 1.24219, -0.558594, -0.550781, -1.71875, 0.351562, 0.277344, 0.492188, -0.324219, -0.988281, 0.427734, -1.19531, -1.02344, 2.39062, -2.125, -1.23438, -0.139648, 0.863281, 0.53125, 0.902344, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -1.14062, -1.125, 1.20312, -0.410156, 0.921875, -0.335938, -0.671875, -1.97656, 0.667969, -0.445312, 0.157227, 0.34375, -0.792969, 0.941406, -1.22656, -1.07031, 1.66406, -2.0625, -0.824219, -0.22168, 0.707031, 0.839844, 0.703125, 0.929688 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -1.32812, -1.02344, 1.15625, -0.785156, 0.435547, -0.283203, -0.664062, -1.83594, 0.820312, -1.1875, -0.138672, 0.855469, -0.4375, 1.32031, -1.1875, -0.855469, 0.84375, -1.75781, -0.394531, -0.324219, 0.566406, 0.9375, 0.535156, 0.96875 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.34375, -0.835938, 1.02344, -0.867188, 0.142578, -0.173828, -0.601562, -1.55469, 1.09375, -1.40625, -0.375, 1.14062, -0.244141, 1.5, -1.10938, -0.738281, 0.213867, -1.4375, -0.0206299, -0.367188, 0.382812, 0.996094, 0.204102, 0.875 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.28125, -0.691406, 0.914062, -0.960938, -0.171875, -0.0834961, -0.527344, -1.39062, 1.07031, -1.67188, -0.558594, 1.32031, 0.0500488, 1.60156, -0.996094, -0.574219, -0.217773, -1.05469, 0.255859, -0.345703, 0.200195, 1.01562, -0.0368652, 0.816406 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.0556641, -0.613281, 0.808594, 0.664062, 1.32812, -0.558594, -0.240234, -0.886719, -0.527344, 1.5, 0.992188, -1.22656, -1.20312, -0.765625, -0.482422, -0.683594, 2.85938, -1.66406, -1.46875, 0.0683594, 0.8125, -0.199219, 1.03906, 0.402344 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_576] shape=[768] showing 24/768: -0.147461, -0.75, 1, 0.589844, 1.40625, -0.542969, -0.386719, -1.10938, -0.384766, 1.29688, 0.929688, -1.07031, -1.28125, -0.558594, -0.726562, -0.804688, 2.85938, -1.86719, -1.49219, 0.0213623, 0.953125, -0.0456543, 1.03906, 0.597656 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_640] shape=[768] showing 24/768: -0.486328, -0.925781, 1.125, 0.302734, 1.35156, -0.605469, -0.492188, -1.35156, -0.102539, 0.878906, 0.792969, -0.785156, -1.23438, -0.170898, -0.9375, -0.984375, 2.76562, -2.0625, -1.4375, -0.102539, 0.964844, 0.163086, 1.03906, 0.671875 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.941406, -1.15625, 1.25, -0.00610352, 1.17969, -0.59375, -0.589844, -1.77344, 0.332031, 0.251953, 0.542969, -0.242188, -1.11719, 0.310547, -1.16406, -1.10156, 2.39062, -2.3125, -1.21094, -0.164062, 1, 0.455078, 0.988281, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -1.21875, -1.08594, 1.27344, -0.417969, 0.878906, -0.427734, -0.605469, -1.90625, 0.691406, -0.460938, 0.104004, 0.357422, -0.871094, 0.910156, -1.25781, -1.0625, 1.75, -2.03125, -0.832031, -0.243164, 0.742188, 0.753906, 0.742188, 0.914062 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -1.3125, -1.03125, 1.24219, -0.730469, 0.488281, -0.259766, -0.65625, -1.75781, 0.972656, -1.125, -0.234375, 0.839844, -0.498047, 1.3125, -1.24219, -0.835938, 0.929688, -1.70312, -0.339844, -0.328125, 0.546875, 0.929688, 0.443359, 0.933594 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.29688, -0.878906, 1.0625, -0.890625, 0.0595703, -0.0756836, -0.558594, -1.625, 1.02344, -1.46875, -0.371094, 1.20312, -0.105957, 1.49219, -1.20312, -0.703125, 0.189453, -1.3125, 0.0264893, -0.417969, 0.330078, 0.898438, 0.174805, 0.855469 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.3125, -0.675781, 0.90625, -0.941406, -0.172852, -0.013916, -0.523438, -1.41406, 1.08594, -1.71094, -0.535156, 1.36719, 0.0166016, 1.63281, -1.02344, -0.570312, -0.255859, -1.02344, 0.277344, -0.330078, 0.248047, 1.01562, 0.0522461, 0.789062 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.84375 max=4.8125 mean=5.39338e-05 std=0.97758 sum1e6=42.4153
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_0] shape=[768] showing 24/768: -0.785156, -0.155273, -0.140625, -0.910156, 2.0625, -1.57812, 0.882812, 0.929688, -0.660156, -0.0634766, -1.13281, 0.628906, -1.09375, 0.0703125, 0.546875, -1.77344, 0.0893555, 1.36719, 0.34375, 0.359375, 0.291016, -0.0654297, -0.302734, -0.419922 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_64] shape=[768] showing 24/768: -0.828125, -0.417969, 0.143555, -0.710938, 1.89844, -1.42188, 0.59375, 0.738281, -0.660156, -0.074707, -0.878906, 0.570312, -0.980469, 0.201172, 0.722656, -1.32812, 0.125977, 1.13281, 0.330078, 0.390625, 0.239258, -0.195312, -0.145508, -0.429688 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_128] shape=[768] showing 24/768: -0.882812, -0.710938, 0.519531, -0.351562, 1.5, -1.10938, 0.275391, 0.474609, -0.589844, -0.179688, -0.5, 0.443359, -0.804688, 0.410156, 0.914062, -0.535156, 0.263672, 0.796875, 0.131836, 0.558594, 0.165039, -0.435547, 0.0272217, -0.398438 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_192] shape=[768] showing 24/768: -0.972656, -1.11719, 0.992188, 0.103516, 0.960938, -0.683594, -0.275391, 0.074707, -0.470703, -0.245117, -0.0712891, 0.226562, -0.535156, 0.679688, 1.09375, 0.482422, 0.462891, 0.351562, -0.0742188, 0.8125, 0.101562, -0.597656, 0.289062, -0.351562 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_256] shape=[768] showing 24/768: -0.90625, -1.35156, 1.28906, 0.664062, 0.314453, -0.0771484, -0.84375, -0.219727, -0.279297, -0.318359, 0.4375, -0.0625, -0.204102, 0.898438, 1.20312, 1.69531, 0.632812, -0.304688, -0.326172, 0.839844, 0.0664062, -0.6875, 0.578125, -0.21875 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_320] shape=[768] showing 24/768: -0.734375, -1.54688, 1.55469, 1.05469, -0.423828, 0.503906, -1.32812, -0.648438, -0.00111389, -0.460938, 0.914062, -0.231445, 0.169922, 1.07812, 1.10156, 2.51562, 0.640625, -0.863281, -0.566406, 0.882812, -0.0177002, -0.839844, 0.824219, -0.090332 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_384] shape=[768] showing 24/768: -0.431641, -1.5625, 1.61719, 1.36719, -0.886719, 0.917969, -1.54688, -0.875, 0.146484, -0.404297, 1.22656, -0.390625, 0.466797, 1.07812, 1.05469, 3.01562, 0.550781, -1.25, -0.621094, 0.859375, -0.167969, -0.796875, 0.839844, 0.00271606 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_448] shape=[768] showing 24/768: -0.310547, -1.45312, 1.59375, 1.42188, -1.1875, 1.22656, -1.65625, -0.960938, 0.220703, -0.359375, 1.46094, -0.443359, 0.648438, 0.96875, 0.953125, 3.25, 0.53125, -1.40625, -0.625, 0.738281, -0.1875, -0.730469, 0.898438, 0.102051 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_512] shape=[768] showing 24/768: -0.777344, -0.180664, -0.137695, -1, 2.03125, -1.65625, 0.847656, 0.964844, -0.636719, 0.00387573, -1.05469, 0.605469, -1.04688, 0.0683594, 0.542969, -1.79688, 0.0612793, 1.38281, 0.400391, 0.3125, 0.28125, -0.103027, -0.267578, -0.382812 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_576] shape=[768] showing 24/768: -0.847656, -0.433594, 0.166992, -0.746094, 1.85938, -1.51562, 0.652344, 0.796875, -0.582031, -0.0480957, -0.890625, 0.515625, -1.02344, 0.217773, 0.703125, -1.29688, 0.160156, 1.19531, 0.271484, 0.410156, 0.261719, -0.216797, -0.143555, -0.460938 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_640] shape=[768] showing 24/768: -0.925781, -0.722656, 0.605469, -0.421875, 1.54688, -1.14844, 0.199219, 0.53125, -0.527344, -0.200195, -0.546875, 0.433594, -0.890625, 0.486328, 0.988281, -0.486328, 0.28125, 0.867188, 0.0996094, 0.570312, 0.134766, -0.373047, 0.0874023, -0.40625 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_704] shape=[768] showing 24/768: -0.882812, -1.10156, 0.992188, 0.0722656, 1.03125, -0.71875, -0.306641, 0.228516, -0.382812, -0.251953, -0.0927734, 0.224609, -0.6875, 0.824219, 1.13281, 0.613281, 0.398438, 0.3125, -0.0634766, 0.769531, 0.0776367, -0.511719, 0.308594, -0.371094 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_768] shape=[768] showing 24/768: -0.882812, -1.45312, 1.35938, 0.589844, 0.255859, -0.0361328, -0.925781, -0.222656, -0.251953, -0.367188, 0.447266, -0.0441895, -0.208984, 1.04688, 1.25781, 1.6875, 0.613281, -0.337891, -0.271484, 0.929688, 0.0678711, -0.738281, 0.503906, -0.277344 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_832] shape=[768] showing 24/768: -0.6875, -1.60938, 1.60938, 1.00781, -0.375, 0.625, -1.28125, -0.644531, -0.057373, -0.492188, 0.921875, -0.306641, 0.117676, 1.05469, 1.19531, 2.5, 0.589844, -0.851562, -0.443359, 0.871094, 0.0349121, -0.753906, 0.707031, -0.116211 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_896] shape=[768] showing 24/768: -0.515625, -1.49219, 1.6875, 1.28125, -0.835938, 0.960938, -1.53125, -0.921875, 0.10498, -0.425781, 1.28125, -0.488281, 0.443359, 1.11719, 1.0625, 3.04688, 0.539062, -1.29688, -0.53125, 0.804688, -0.0722656, -0.71875, 0.828125, 0.0108032 ...
[VT][vision_model.encoder.layers.0.self_attn.v_proj[NLH]/item_960] shape=[768] showing 24/768: -0.388672, -1.48438, 1.60938, 1.45312, -1.1875, 1.26562, -1.67969, -1.00781, 0.185547, -0.373047, 1.44531, -0.480469, 0.683594, 1.04688, 0.949219, 3.20312, 0.523438, -1.47656, -0.578125, 0.699219, -0.142578, -0.675781, 0.878906, 0.0559082 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-2.20312 max=2.125 mean=0.000935732 std=0.418866 sum1e6=735.889
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_0] shape=[768] showing 24/768: -0.373047, -0.326172, -0.490234, -0.376953, 0.202148, 0.171875, 0.710938, -0.158203, -1.01562, -0.296875, 0.503906, -0.00842285, -0.574219, -0.378906, -0.480469, 0.671875, -0.345703, 0.65625, 0.00952148, -0.746094, -0.337891, 0.115234, -0.134766, 0.222656 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_64] shape=[768] showing 24/768: -0.412109, -0.386719, -0.408203, -0.328125, 0.226562, 0.142578, 0.660156, -0.160156, -1, -0.3125, 0.478516, -0.0130615, -0.574219, -0.324219, -0.408203, 0.714844, -0.318359, 0.636719, 0.00482178, -0.660156, -0.316406, 0.0756836, -0.113281, 0.183594 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_128] shape=[768] showing 24/768: -0.490234, -0.511719, -0.265625, -0.19043, 0.229492, 0.113281, 0.585938, -0.193359, -1.00781, -0.363281, 0.419922, -0.050293, -0.546875, -0.242188, -0.310547, 0.847656, -0.287109, 0.578125, 0.00136566, -0.5, -0.279297, 0.00271606, -0.0849609, 0.09375 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.550781, -0.621094, -0.0593262, -0.0483398, 0.257812, 0.048584, 0.431641, -0.195312, -0.898438, -0.371094, 0.332031, -0.0668945, -0.492188, -0.101562, -0.124512, 0.898438, -0.210938, 0.464844, -0.012146, -0.259766, -0.208008, -0.0927734, -0.0272217, -0.00488281 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.558594, -0.671875, 0.111816, 0.0820312, 0.251953, 0.0027771, 0.279297, -0.191406, -0.730469, -0.345703, 0.234375, -0.0854492, -0.402344, 0.0142212, 0.0349121, 0.878906, -0.145508, 0.314453, -0.0244141, -0.0334473, -0.130859, -0.166992, 0.0220947, -0.0854492 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.470703, -0.617188, 0.289062, 0.143555, 0.242188, -0.0354004, 0.0424805, -0.138672, -0.382812, -0.21875, 0.169922, -0.059082, -0.259766, 0.163086, 0.255859, 0.695312, -0.0283203, 0.0795898, -0.0634766, 0.192383, -0.0349121, -0.226562, 0.108398, -0.102539 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -0.304688, -0.466797, 0.382812, 0.161133, 0.171875, -0.0222168, -0.171875, -0.0854492, 0.0270996, -0.0466309, 0.132812, -0.0324707, -0.0791016, 0.253906, 0.404297, 0.433594, 0.060791, -0.186523, -0.104492, 0.347656, 0.0490723, -0.240234, 0.178711, -0.0673828 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -0.126953, -0.314453, 0.460938, 0.179688, 0.0673828, 0.0285645, -0.384766, -0.0517578, 0.423828, 0.121582, 0.134766, -0.0144653, 0.105957, 0.332031, 0.527344, 0.216797, 0.141602, -0.458984, -0.15332, 0.466797, 0.117188, -0.245117, 0.25, -0.0129395 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_512] shape=[768] showing 24/768: -0.376953, -0.339844, -0.464844, -0.367188, 0.199219, 0.176758, 0.6875, -0.162109, -1, -0.294922, 0.515625, -0.00811768, -0.570312, -0.361328, -0.458984, 0.695312, -0.333984, 0.640625, 0.00186157, -0.730469, -0.335938, 0.105469, -0.122559, 0.223633 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_576] shape=[768] showing 24/768: -0.412109, -0.404297, -0.380859, -0.302734, 0.200195, 0.166992, 0.628906, -0.176758, -0.988281, -0.314453, 0.503906, -0.0214844, -0.554688, -0.306641, -0.392578, 0.765625, -0.306641, 0.601562, -0.00714111, -0.648438, -0.318359, 0.0649414, -0.0976562, 0.186523 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_640] shape=[768] showing 24/768: -0.486328, -0.480469, -0.316406, -0.228516, 0.251953, 0.0942383, 0.636719, -0.176758, -1.03125, -0.361328, 0.400391, -0.0412598, -0.570312, -0.275391, -0.345703, 0.792969, -0.308594, 0.621094, 0.0159912, -0.535156, -0.285156, 0.0233154, -0.108398, 0.0991211 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.539062, -0.605469, -0.0961914, -0.065918, 0.243164, 0.0688477, 0.458984, -0.202148, -0.925781, -0.375, 0.351562, -0.0693359, -0.5, -0.128906, -0.163086, 0.90625, -0.227539, 0.480469, -0.0106812, -0.304688, -0.223633, -0.0761719, -0.0378418, 0.0122681 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.515625, -0.652344, 0.15625, 0.0844727, 0.21875, 0.0354004, 0.193359, -0.19043, -0.632812, -0.302734, 0.28125, -0.074707, -0.357422, 0.0576172, 0.0883789, 0.871094, -0.104004, 0.235352, -0.0524902, -0.0152588, -0.123535, -0.176758, 0.0617676, -0.0544434 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.458984, -0.613281, 0.294922, 0.15332, 0.219727, -0.0169678, 0.0255127, -0.146484, -0.363281, -0.212891, 0.183594, -0.0639648, -0.243164, 0.166016, 0.255859, 0.707031, -0.0251465, 0.0556641, -0.0698242, 0.193359, -0.0354004, -0.226562, 0.114746, -0.0957031 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -0.294922, -0.433594, 0.345703, 0.133789, 0.193359, -0.0466309, -0.134766, -0.065918, 0.0280762, -0.0368652, 0.0976562, -0.0253906, -0.0878906, 0.227539, 0.380859, 0.361328, 0.0439453, -0.161133, -0.090332, 0.335938, 0.0539551, -0.223633, 0.157227, -0.0693359 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -0.11377, -0.267578, 0.414062, 0.133789, 0.106445, -0.0106812, -0.337891, -0.0183105, 0.431641, 0.139648, 0.0893555, 0.0018158, 0.090332, 0.302734, 0.507812, 0.107422, 0.125, -0.423828, -0.135742, 0.453125, 0.125, -0.224609, 0.225586, -0.0130005 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-1.76562 max=1.82812 mean=0.000763973 std=0.411253 sum1e6=600.813
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_0] shape=[768] showing 24/768: 0.683594, -0.15625, -0.667969, -0.126953, -0.392578, -0.0302734, 0.445312, -0.167969, 0.53125, -0.445312, -0.917969, 0.208984, 0.4375, 0.0454102, 0.255859, -0.236328, -0.0539551, 0.404297, 0.209961, 0.283203, 0.65625, 0.878906, -0.511719, 0.9375 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_64] shape=[768] showing 24/768: 0.511719, -0.219727, -0.527344, -0.15332, -0.394531, -0.00787354, 0.394531, -0.0917969, 0.511719, -0.605469, -0.976562, 0.185547, 0.435547, -0.0480957, 0.245117, -0.298828, -0.139648, 0.443359, 0.140625, 0.195312, 0.597656, 0.972656, -0.566406, 0.921875 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_128] shape=[768] showing 24/768: 0.275391, -0.322266, -0.304688, -0.210938, -0.392578, 0.0419922, 0.240234, -0.0463867, 0.455078, -0.742188, -1, 0.117188, 0.386719, -0.196289, 0.253906, -0.40625, -0.253906, 0.507812, -0.00622559, 0.0698242, 0.511719, 1.00781, -0.617188, 0.917969 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_192] shape=[768] showing 24/768: -0.00982666, -0.443359, -0.0593262, -0.322266, -0.300781, 0.106445, 0.00540161, 0.041748, 0.353516, -0.894531, -0.964844, 0.114258, 0.363281, -0.345703, 0.314453, -0.435547, -0.40625, 0.585938, -0.208008, -0.0522461, 0.386719, 1.03125, -0.65625, 0.835938 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_256] shape=[768] showing 24/768: -0.292969, -0.466797, 0.24707, -0.398438, -0.182617, 0.181641, -0.228516, 0.129883, 0.222656, -0.933594, -0.816406, 0.0795898, 0.263672, -0.464844, 0.347656, -0.443359, -0.503906, 0.640625, -0.398438, -0.200195, 0.283203, 0.964844, -0.59375, 0.691406 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_320] shape=[768] showing 24/768: -0.5625, -0.421875, 0.492188, -0.447266, -0.0402832, 0.154297, -0.5, 0.21582, 0.12207, -0.878906, -0.632812, 0.00982666, 0.208008, -0.511719, 0.365234, -0.357422, -0.527344, 0.652344, -0.5, -0.34375, 0.104004, 0.816406, -0.451172, 0.511719 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_384] shape=[768] showing 24/768: -0.75, -0.416016, 0.632812, -0.503906, 0.090332, 0.203125, -0.625, 0.263672, -0.00726318, -0.730469, -0.396484, -0.124023, 0.168945, -0.492188, 0.361328, -0.285156, -0.5, 0.566406, -0.574219, -0.417969, -0.00732422, 0.617188, -0.34375, 0.345703 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_448] shape=[768] showing 24/768: -0.910156, -0.367188, 0.714844, -0.511719, 0.169922, 0.234375, -0.699219, 0.265625, -0.106445, -0.640625, -0.242188, -0.211914, 0.0874023, -0.462891, 0.330078, -0.164062, -0.535156, 0.443359, -0.59375, -0.455078, -0.15332, 0.466797, -0.209961, 0.112305 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_512] shape=[768] showing 24/768: 0.664062, -0.15625, -0.644531, -0.114746, -0.394531, -0.0317383, 0.445312, -0.173828, 0.5625, -0.441406, -0.957031, 0.209961, 0.425781, 0.0544434, 0.222656, -0.237305, -0.0507812, 0.380859, 0.228516, 0.279297, 0.664062, 0.882812, -0.496094, 0.917969 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_576] shape=[768] showing 24/768: 0.53125, -0.220703, -0.484375, -0.145508, -0.427734, -0.0419922, 0.353516, -0.117188, 0.53125, -0.574219, -0.996094, 0.18457, 0.398438, -0.065918, 0.231445, -0.322266, -0.121582, 0.439453, 0.140625, 0.19043, 0.605469, 0.945312, -0.550781, 0.929688 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_640] shape=[768] showing 24/768: 0.328125, -0.316406, -0.314453, -0.214844, -0.384766, 0.0238037, 0.271484, -0.017334, 0.443359, -0.761719, -0.96875, 0.125, 0.421875, -0.175781, 0.255859, -0.394531, -0.212891, 0.498047, 0.00613403, 0.0456543, 0.53125, 0.996094, -0.617188, 0.945312 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_704] shape=[768] showing 24/768: 0.000652313, -0.402344, -0.104492, -0.289062, -0.3125, 0.0859375, 0.0566406, 0.0820312, 0.357422, -0.882812, -0.933594, 0.0791016, 0.398438, -0.328125, 0.302734, -0.457031, -0.384766, 0.558594, -0.15625, -0.0649414, 0.441406, 1.02344, -0.640625, 0.910156 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_768] shape=[768] showing 24/768: -0.333984, -0.419922, 0.249023, -0.367188, -0.15625, 0.104004, -0.265625, 0.198242, 0.251953, -0.898438, -0.804688, 0.0373535, 0.3125, -0.482422, 0.330078, -0.455078, -0.466797, 0.683594, -0.353516, -0.241211, 0.257812, 0.902344, -0.550781, 0.71875 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_832] shape=[768] showing 24/768: -0.566406, -0.404297, 0.515625, -0.433594, -0.0412598, 0.19043, -0.46875, 0.213867, 0.0917969, -0.855469, -0.648438, 0.00634766, 0.217773, -0.53125, 0.335938, -0.359375, -0.558594, 0.679688, -0.492188, -0.339844, 0.0893555, 0.820312, -0.447266, 0.523438 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_896] shape=[768] showing 24/768: -0.742188, -0.410156, 0.628906, -0.511719, 0.0776367, 0.22168, -0.601562, 0.239258, -0.0137329, -0.746094, -0.404297, -0.125977, 0.139648, -0.46875, 0.328125, -0.263672, -0.523438, 0.558594, -0.5625, -0.423828, -0.048584, 0.628906, -0.324219, 0.287109 ...
[VT][vision_model.encoder.layers.0.self_attn.out_proj[NLH]/item_960] shape=[768] showing 24/768: -0.914062, -0.367188, 0.753906, -0.492188, 0.169922, 0.212891, -0.699219, 0.246094, -0.112305, -0.636719, -0.241211, -0.21875, 0.0844727, -0.431641, 0.318359, -0.147461, -0.498047, 0.447266, -0.570312, -0.460938, -0.177734, 0.457031, -0.21582, 0.112305 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.71875 max=4.53125 mean=-0.000478117 std=0.716838 sum1e6=-376.007
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_0] shape=[768] showing 24/768: 0.96875, -0.490234, 0.265625, 0.703125, 1.09375, -0.269531, 0.546875, -0.703125, 0.304688, 1.17969, 0.261719, -0.703125, -0.5, -0.421875, -0.0253906, -0.628906, 2.70312, -0.875, -0.898438, 0.609375, 1.64062, 0.945312, 0.738281, 1.49219 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_64] shape=[768] showing 24/768: 0.578125, -0.617188, 0.390625, 0.492188, 0.925781, -0.235352, 0.341797, -0.78125, 0.464844, 0.558594, -0.0859375, -0.388672, -0.330078, -0.25, -0.120117, -0.726562, 2.21875, -0.789062, -0.773438, 0.40625, 1.42969, 1.20312, 0.457031, 1.53125 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_128] shape=[768] showing 24/768: 0.151367, -0.78125, 0.578125, 0.171875, 0.617188, -0.206055, 0.0996094, -0.777344, 0.589844, 0.03125, -0.347656, -0.189453, -0.261719, -0.121582, -0.185547, -0.859375, 1.625, -0.6875, -0.699219, 0.180664, 1.21875, 1.25781, 0.226562, 1.52344 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_192] shape=[768] showing 24/768: -0.386719, -0.925781, 0.816406, -0.257812, 0.535156, -0.0830078, -0.177734, -0.808594, 0.683594, -0.609375, -0.554688, 0.0595703, -0.0703125, 0.0273438, -0.236328, -0.890625, 1.08594, -0.492188, -0.78125, -0.00244141, 1.00781, 1.46094, -0.0117188, 1.4375 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_256] shape=[768] showing 24/768: -0.84375, -1.00781, 1.02344, -0.539062, 0.429688, 0.0844727, -0.515625, -0.894531, 0.695312, -1.09375, -0.632812, 0.367188, -0.0917969, 0.160156, -0.253906, -0.953125, 0.527344, -0.429688, -0.773438, -0.232422, 0.773438, 1.53125, -0.103516, 1.3125 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_320] shape=[768] showing 24/768: -1.34375, -1.00781, 1.27344, -0.882812, 0.289062, 0.0327148, -0.859375, -0.878906, 0.691406, -1.5625, -0.664062, 0.605469, -0.00976562, 0.375, -0.322266, -0.835938, 0.0585938, -0.394531, -0.691406, -0.492188, 0.515625, 1.46094, -0.0585938, 1.17188 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_384] shape=[768] showing 24/768: -1.72656, -1.01562, 1.40625, -1.125, 0.213867, 0.0922852, -1.05469, -0.867188, 0.820312, -1.75, -0.65625, 0.734375, 0.00585938, 0.632812, -0.443359, -0.8125, -0.324219, -0.480469, -0.570312, -0.671875, 0.292969, 1.375, -0.174805, 1.00781 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_448] shape=[768] showing 24/768: -2.0625, -0.996094, 1.5, -1.375, 0.000976562, 0.142578, -1.17969, -0.976562, 0.820312, -2.125, -0.753906, 0.9375, 0.114258, 0.9375, -0.570312, -0.6875, -0.746094, -0.507812, -0.386719, -0.777344, 0.00585938, 1.34375, -0.259766, 0.816406 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_512] shape=[768] showing 24/768: 0.953125, -0.472656, 0.328125, 0.730469, 1.04688, -0.296875, 0.46875, -0.734375, 0.326172, 1.15625, 0.183594, -0.664062, -0.425781, -0.398438, 0.0253906, -0.617188, 2.78125, -0.882812, -0.867188, 0.582031, 1.64062, 0.941406, 0.683594, 1.52344 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_576] shape=[768] showing 24/768: 0.625, -0.585938, 0.480469, 0.507812, 0.84375, -0.249023, 0.265625, -0.753906, 0.445312, 0.613281, -0.0859375, -0.421875, -0.371094, -0.285156, -0.116211, -0.726562, 2.25, -0.773438, -0.785156, 0.412109, 1.53125, 1.11719, 0.445312, 1.59375 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_640] shape=[768] showing 24/768: 0.183594, -0.742188, 0.570312, 0.146484, 0.648438, -0.197266, 0.123047, -0.714844, 0.546875, -0.03125, -0.292969, -0.210938, -0.203125, -0.118164, -0.177734, -0.859375, 1.72656, -0.65625, -0.746094, 0.147461, 1.3125, 1.26562, 0.214844, 1.54688 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_704] shape=[768] showing 24/768: -0.40625, -0.929688, 0.734375, -0.163086, 0.488281, -0.12207, -0.149414, -0.796875, 0.675781, -0.609375, -0.494141, 0.0708008, -0.109375, -0.0214844, -0.232422, -0.957031, 1.10938, -0.628906, -0.71875, -0.0290527, 1.14062, 1.41406, 0.0507812, 1.51562 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_768] shape=[768] showing 24/768: -0.929688, -0.9375, 1.0625, -0.507812, 0.433594, -0.043457, -0.515625, -0.78125, 0.734375, -1.0625, -0.652344, 0.332031, -0.0839844, 0.123047, -0.287109, -0.960938, 0.609375, -0.363281, -0.726562, -0.285156, 0.769531, 1.42188, -0.0390625, 1.32812 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_832] shape=[768] showing 24/768: -1.32812, -0.992188, 1.34375, -0.832031, 0.320312, 0.0844727, -0.820312, -0.824219, 0.757812, -1.5, -0.738281, 0.589844, -0.0361328, 0.34375, -0.382812, -0.824219, 0.078125, -0.328125, -0.648438, -0.488281, 0.488281, 1.45312, -0.113281, 1.16406 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_896] shape=[768] showing 24/768: -1.67969, -1.03906, 1.4375, -1.14844, 0.141602, 0.185547, -0.992188, -0.941406, 0.757812, -1.8125, -0.65625, 0.785156, 0.081543, 0.65625, -0.539062, -0.765625, -0.363281, -0.390625, -0.523438, -0.710938, 0.214844, 1.3125, -0.174805, 0.9375 ...
[VT][vision_model.encoder.layers.0.layer_norm2/pre[NLH]/item_960] shape=[768] showing 24/768: -2.09375, -0.980469, 1.53125, -1.34375, 0.000976562, 0.183594, -1.17188, -1.01562, 0.824219, -2.15625, -0.730469, 0.96875, 0.0825195, 0.992188, -0.601562, -0.667969, -0.742188, -0.474609, -0.34375, -0.765625, 0.0244141, 1.33594, -0.186523, 0.792969 ...
[VT][vision_model.encoder.layers.0.layer_norm2] OUT shape=(1, 1024, 768) layout=NLH  min=-4.46875 max=4.28125 mean=-7.27363e-07 std=0.999996 sum1e6=-0.572021
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_0] shape=[768] showing 24/768: 0.746094, -0.703125, 0.0483398, 0.482422, 0.871094, -0.482422, 0.328125, -0.914062, 0.0869141, 0.957031, 0.0444336, -0.914062, -0.710938, -0.632812, -0.240234, -0.839844, 2.46875, -1.08594, -1.10938, 0.388672, 1.41406, 0.722656, 0.515625, 1.26562 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_64] shape=[768] showing 24/768: 0.453125, -0.902344, 0.241211, 0.357422, 0.847656, -0.46875, 0.186523, -1.08594, 0.326172, 0.431641, -0.298828, -0.640625, -0.574219, -0.484375, -0.337891, -1.02344, 2.3125, -1.09375, -1.07812, 0.259766, 1.42188, 1.16406, 0.316406, 1.53125 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_128] shape=[768] showing 24/768: 0.0124512, -1.17969, 0.558594, 0.0385742, 0.605469, -0.443359, -0.0537109, -1.17188, 0.574219, -0.140625, -0.625, -0.421875, -0.515625, -0.335938, -0.417969, -1.28125, 1.89062, -1.05469, -1.07031, 0.0498047, 1.375, 1.42188, 0.108398, 1.76562 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_192] shape=[768] showing 24/768: -0.671875, -1.40625, 0.972656, -0.496094, 0.589844, -0.255859, -0.386719, -1.25, 0.792969, -0.976562, -0.902344, -0.0617676, -0.239258, -0.105957, -0.466797, -1.35938, 1.34375, -0.816406, -1.21094, -0.146484, 1.23438, 1.85938, -0.15918, 1.82031 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_256] shape=[768] showing 24/768: -1.25, -1.47656, 1.30469, -0.835938, 0.490234, 0.0183105, -0.804688, -1.32031, 0.855469, -1.59375, -0.964844, 0.40625, -0.222656, 0.12207, -0.445312, -1.39844, 0.625, -0.683594, -1.15625, -0.416016, 0.960938, 2, -0.239258, 1.70312 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_320] shape=[768] showing 24/768: -1.78906, -1.35156, 1.60156, -1.1875, 0.326172, -0.00634766, -1.16406, -1.1875, 0.847656, -2.07812, -0.90625, 0.734375, -0.0612793, 0.4375, -0.464844, -1.13281, 0.0270996, -0.558594, -0.945312, -0.6875, 0.617188, 1.84375, -0.124512, 1.46875 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_384] shape=[768] showing 24/768: -2.03125, -1.19531, 1.64062, -1.32031, 0.243164, 0.101074, -1.24219, -1.02344, 0.953125, -2.04688, -0.773438, 0.851562, -0.000125885, 0.734375, -0.527344, -0.957031, -0.386719, -0.570312, -0.675781, -0.792969, 0.335938, 1.60156, -0.210938, 1.17188 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_448] shape=[768] showing 24/768: -2.09375, -0.996094, 1.57031, -1.38281, 0.0273438, 0.172852, -1.1875, -0.976562, 0.867188, -2.15625, -0.746094, 0.988281, 0.143555, 0.988281, -0.558594, -0.679688, -0.738281, -0.494141, -0.371094, -0.773438, 0.0324707, 1.40625, -0.240234, 0.863281 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_512] shape=[768] showing 24/768: 0.734375, -0.683594, 0.112305, 0.511719, 0.824219, -0.507812, 0.251953, -0.941406, 0.110352, 0.933594, -0.0311279, -0.871094, -0.636719, -0.609375, -0.188477, -0.824219, 2.54688, -1.08594, -1.07031, 0.365234, 1.41406, 0.722656, 0.464844, 1.29688 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_576] shape=[768] showing 24/768: 0.507812, -0.871094, 0.34375, 0.373047, 0.757812, -0.486328, 0.0986328, -1.0625, 0.302734, 0.494141, -0.300781, -0.683594, -0.625, -0.527344, -0.335938, -1.03125, 2.35938, -1.08594, -1.09375, 0.265625, 1.53906, 1.07031, 0.302734, 1.60938 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_640] shape=[768] showing 24/768: 0.0546875, -1.13281, 0.550781, 0.00726318, 0.648438, -0.431641, -0.0227051, -1.09375, 0.519531, -0.219727, -0.554688, -0.449219, -0.439453, -0.332031, -0.408203, -1.28125, 2.03125, -1.01562, -1.13281, 0.00848389, 1.5, 1.4375, 0.0947266, 1.79688 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_704] shape=[768] showing 24/768: -0.699219, -1.41406, 0.863281, -0.365234, 0.523438, -0.310547, -0.347656, -1.23438, 0.78125, -0.976562, -0.820312, -0.0461426, -0.292969, -0.172852, -0.460938, -1.45312, 1.375, -1, -1.125, -0.182617, 1.42188, 1.78906, -0.0737305, 1.92969 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_768] shape=[768] showing 24/768: -1.375, -1.39062, 1.35938, -0.796875, 0.498047, -0.158203, -0.808594, -1.17188, 0.910156, -1.5625, -0.996094, 0.357422, -0.213867, 0.0708008, -0.494141, -1.42188, 0.738281, -0.597656, -1.10156, -0.490234, 0.960938, 1.85938, -0.152344, 1.72656 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_832] shape=[768] showing 24/768: -1.77344, -1.33594, 1.69531, -1.13281, 0.365234, 0.0595703, -1.11719, -1.11719, 0.933594, -2, -1.00781, 0.714844, -0.097168, 0.396484, -0.546875, -1.11719, 0.0512695, -0.476562, -0.890625, -0.683594, 0.585938, 1.83594, -0.197266, 1.46094 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_896] shape=[768] showing 24/768: -1.97656, -1.22656, 1.67969, -1.35938, 0.158203, 0.208984, -1.17188, -1.11719, 0.882812, -2.14062, -0.777344, 0.914062, 0.0874023, 0.761719, -0.640625, -0.90625, -0.435547, -0.466797, -0.621094, -0.84375, 0.244141, 1.53125, -0.213867, 1.09375 ...
[VT][vision_model.encoder.layers.0.layer_norm2[NLH]/item_960] shape=[768] showing 24/768: -2.125, -0.984375, 1.60156, -1.35938, 0.0256348, 0.213867, -1.17969, -1.02344, 0.871094, -2.1875, -0.726562, 1.02344, 0.109375, 1.04688, -0.59375, -0.664062, -0.738281, -0.462891, -0.328125, -0.761719, 0.0498047, 1.39844, -0.166992, 0.839844 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.46875 max=4.28125 mean=-7.27363e-07 std=0.999996 sum1e6=-0.572021
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_0] shape=[768] showing 24/768: 0.746094, -0.703125, 0.0483398, 0.482422, 0.871094, -0.482422, 0.328125, -0.914062, 0.0869141, 0.957031, 0.0444336, -0.914062, -0.710938, -0.632812, -0.240234, -0.839844, 2.46875, -1.08594, -1.10938, 0.388672, 1.41406, 0.722656, 0.515625, 1.26562 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_64] shape=[768] showing 24/768: 0.453125, -0.902344, 0.241211, 0.357422, 0.847656, -0.46875, 0.186523, -1.08594, 0.326172, 0.431641, -0.298828, -0.640625, -0.574219, -0.484375, -0.337891, -1.02344, 2.3125, -1.09375, -1.07812, 0.259766, 1.42188, 1.16406, 0.316406, 1.53125 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_128] shape=[768] showing 24/768: 0.0124512, -1.17969, 0.558594, 0.0385742, 0.605469, -0.443359, -0.0537109, -1.17188, 0.574219, -0.140625, -0.625, -0.421875, -0.515625, -0.335938, -0.417969, -1.28125, 1.89062, -1.05469, -1.07031, 0.0498047, 1.375, 1.42188, 0.108398, 1.76562 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_192] shape=[768] showing 24/768: -0.671875, -1.40625, 0.972656, -0.496094, 0.589844, -0.255859, -0.386719, -1.25, 0.792969, -0.976562, -0.902344, -0.0617676, -0.239258, -0.105957, -0.466797, -1.35938, 1.34375, -0.816406, -1.21094, -0.146484, 1.23438, 1.85938, -0.15918, 1.82031 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_256] shape=[768] showing 24/768: -1.25, -1.47656, 1.30469, -0.835938, 0.490234, 0.0183105, -0.804688, -1.32031, 0.855469, -1.59375, -0.964844, 0.40625, -0.222656, 0.12207, -0.445312, -1.39844, 0.625, -0.683594, -1.15625, -0.416016, 0.960938, 2, -0.239258, 1.70312 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_320] shape=[768] showing 24/768: -1.78906, -1.35156, 1.60156, -1.1875, 0.326172, -0.00634766, -1.16406, -1.1875, 0.847656, -2.07812, -0.90625, 0.734375, -0.0612793, 0.4375, -0.464844, -1.13281, 0.0270996, -0.558594, -0.945312, -0.6875, 0.617188, 1.84375, -0.124512, 1.46875 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_384] shape=[768] showing 24/768: -2.03125, -1.19531, 1.64062, -1.32031, 0.243164, 0.101074, -1.24219, -1.02344, 0.953125, -2.04688, -0.773438, 0.851562, -0.000125885, 0.734375, -0.527344, -0.957031, -0.386719, -0.570312, -0.675781, -0.792969, 0.335938, 1.60156, -0.210938, 1.17188 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_448] shape=[768] showing 24/768: -2.09375, -0.996094, 1.57031, -1.38281, 0.0273438, 0.172852, -1.1875, -0.976562, 0.867188, -2.15625, -0.746094, 0.988281, 0.143555, 0.988281, -0.558594, -0.679688, -0.738281, -0.494141, -0.371094, -0.773438, 0.0324707, 1.40625, -0.240234, 0.863281 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_512] shape=[768] showing 24/768: 0.734375, -0.683594, 0.112305, 0.511719, 0.824219, -0.507812, 0.251953, -0.941406, 0.110352, 0.933594, -0.0311279, -0.871094, -0.636719, -0.609375, -0.188477, -0.824219, 2.54688, -1.08594, -1.07031, 0.365234, 1.41406, 0.722656, 0.464844, 1.29688 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_576] shape=[768] showing 24/768: 0.507812, -0.871094, 0.34375, 0.373047, 0.757812, -0.486328, 0.0986328, -1.0625, 0.302734, 0.494141, -0.300781, -0.683594, -0.625, -0.527344, -0.335938, -1.03125, 2.35938, -1.08594, -1.09375, 0.265625, 1.53906, 1.07031, 0.302734, 1.60938 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_640] shape=[768] showing 24/768: 0.0546875, -1.13281, 0.550781, 0.00726318, 0.648438, -0.431641, -0.0227051, -1.09375, 0.519531, -0.219727, -0.554688, -0.449219, -0.439453, -0.332031, -0.408203, -1.28125, 2.03125, -1.01562, -1.13281, 0.00848389, 1.5, 1.4375, 0.0947266, 1.79688 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_704] shape=[768] showing 24/768: -0.699219, -1.41406, 0.863281, -0.365234, 0.523438, -0.310547, -0.347656, -1.23438, 0.78125, -0.976562, -0.820312, -0.0461426, -0.292969, -0.172852, -0.460938, -1.45312, 1.375, -1, -1.125, -0.182617, 1.42188, 1.78906, -0.0737305, 1.92969 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_768] shape=[768] showing 24/768: -1.375, -1.39062, 1.35938, -0.796875, 0.498047, -0.158203, -0.808594, -1.17188, 0.910156, -1.5625, -0.996094, 0.357422, -0.213867, 0.0708008, -0.494141, -1.42188, 0.738281, -0.597656, -1.10156, -0.490234, 0.960938, 1.85938, -0.152344, 1.72656 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_832] shape=[768] showing 24/768: -1.77344, -1.33594, 1.69531, -1.13281, 0.365234, 0.0595703, -1.11719, -1.11719, 0.933594, -2, -1.00781, 0.714844, -0.097168, 0.396484, -0.546875, -1.11719, 0.0512695, -0.476562, -0.890625, -0.683594, 0.585938, 1.83594, -0.197266, 1.46094 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_896] shape=[768] showing 24/768: -1.97656, -1.22656, 1.67969, -1.35938, 0.158203, 0.208984, -1.17188, -1.11719, 0.882812, -2.14062, -0.777344, 0.914062, 0.0874023, 0.761719, -0.640625, -0.90625, -0.435547, -0.466797, -0.621094, -0.84375, 0.244141, 1.53125, -0.213867, 1.09375 ...
[VT][vision_model.encoder.layers.0.mlp.fc1/pre[NLH]/item_960] shape=[768] showing 24/768: -2.125, -0.984375, 1.60156, -1.35938, 0.0256348, 0.213867, -1.17969, -1.02344, 0.871094, -2.1875, -0.726562, 1.02344, 0.109375, 1.04688, -0.59375, -0.664062, -0.738281, -0.462891, -0.328125, -0.761719, 0.0498047, 1.39844, -0.166992, 0.839844 ...
[VT][vision_model.encoder.layers.0.mlp.fc1] OUT shape=(1, 1024, 3072) layout=NLH  min=-2.65625 max=2.75 mean=0.000181178 std=0.631458 sum1e6=-8582.56
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_0] shape=[3072] showing 24/3072: -0.582031, -0.925781, 0.00704956, -0.126953, -0.133789, 0.773438, -0.613281, -0.894531, 0.10498, -0.408203, 0.125, -0.287109, -0.507812, -0.152344, -0.332031, -0.478516, 0.738281, 0.617188, -0.176758, -0.753906, -0.400391, 0.855469, 0.554688, -0.644531 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_64] shape=[3072] showing 24/3072: -0.484375, -0.824219, 0.140625, -0.0366211, -0.166016, 0.804688, -0.890625, -0.683594, 0.0200195, -0.494141, 0.210938, -0.371094, -0.527344, -0.235352, -0.310547, -0.613281, 0.820312, 0.519531, -0.226562, -0.742188, -0.574219, 0.953125, 0.566406, -0.578125 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_128] shape=[3072] showing 24/3072: -0.386719, -0.683594, 0.220703, 0.00411987, -0.248047, 0.742188, -1.125, -0.361328, -0.166016, -0.574219, 0.244141, -0.441406, -0.496094, -0.396484, -0.208984, -0.742188, 0.839844, 0.375, -0.251953, -0.695312, -0.785156, 1.04688, 0.519531, -0.482422 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_192] shape=[3072] showing 24/3072: -0.121582, -0.507812, 0.349609, 0.142578, -0.240234, 0.582031, -1.39062, -0.0332031, -0.365234, -0.554688, 0.265625, -0.46875, -0.451172, -0.660156, -0.0761719, -0.765625, 0.765625, 0.206055, -0.236328, -0.667969, -0.941406, 1.14062, 0.427734, -0.349609 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_256] shape=[3072] showing 24/3072: 0.168945, -0.28125, 0.404297, 0.149414, -0.240234, 0.355469, -1.53125, 0.306641, -0.585938, -0.5625, 0.143555, -0.398438, -0.244141, -0.835938, -0.0037384, -0.75, 0.609375, -0.0388184, -0.287109, -0.597656, -1.04688, 1.09375, 0.283203, -0.225586 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_320] shape=[3072] showing 24/3072: 0.394531, 0.00933838, 0.523438, 0.214844, -0.11377, 0.202148, -1.46094, 0.621094, -0.570312, -0.554688, -0.0625, -0.400391, -0.10498, -0.9375, 0.118652, -0.714844, 0.507812, -0.3125, -0.341797, -0.400391, -0.925781, 0.902344, 0.0834961, 0.0732422 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_384] shape=[3072] showing 24/3072: 0.613281, 0.265625, 0.515625, 0.248047, -0.019043, 0.100586, -1.29688, 0.910156, -0.503906, -0.511719, -0.149414, -0.40625, -0.00231934, -0.886719, 0.0844727, -0.605469, 0.335938, -0.53125, -0.353516, -0.170898, -0.789062, 0.6875, -0.0593262, 0.287109 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_448] shape=[3072] showing 24/3072: 0.824219, 0.441406, 0.523438, 0.202148, 0.050293, 0.078125, -1.10938, 1.03906, -0.433594, -0.472656, -0.231445, -0.326172, 0.0549316, -0.75, 0.097168, -0.447266, 0.242188, -0.679688, -0.314453, -0.0311279, -0.660156, 0.490234, -0.176758, 0.410156 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_512] shape=[3072] showing 24/3072: -0.59375, -0.929688, -0.00970459, -0.134766, -0.171875, 0.789062, -0.597656, -0.890625, 0.101562, -0.431641, 0.108398, -0.263672, -0.507812, -0.15332, -0.289062, -0.519531, 0.761719, 0.589844, -0.164062, -0.742188, -0.40625, 0.820312, 0.558594, -0.628906 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_576] shape=[3072] showing 24/3072: -0.550781, -0.851562, 0.0898438, -0.0805664, -0.173828, 0.800781, -0.832031, -0.691406, -0.03125, -0.5, 0.167969, -0.359375, -0.527344, -0.269531, -0.275391, -0.617188, 0.847656, 0.535156, -0.18457, -0.71875, -0.570312, 0.917969, 0.523438, -0.585938 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_640] shape=[3072] showing 24/3072: -0.375, -0.683594, 0.236328, -0.00202942, -0.240234, 0.691406, -1.11719, -0.439453, -0.119629, -0.566406, 0.223633, -0.400391, -0.539062, -0.457031, -0.161133, -0.734375, 0.882812, 0.40625, -0.212891, -0.703125, -0.71875, 1.02344, 0.507812, -0.486328 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_704] shape=[3072] showing 24/3072: -0.078125, -0.498047, 0.386719, 0.0588379, -0.206055, 0.554688, -1.40625, -0.0534668, -0.337891, -0.609375, 0.245117, -0.490234, -0.421875, -0.585938, -0.0524902, -0.785156, 0.722656, 0.22168, -0.28125, -0.660156, -0.902344, 1.125, 0.466797, -0.306641 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_768] shape=[3072] showing 24/3072: 0.109375, -0.261719, 0.498047, 0.22168, -0.19043, 0.34375, -1.51562, 0.345703, -0.53125, -0.570312, 0.111816, -0.46875, -0.203125, -0.851562, 0.048584, -0.796875, 0.6875, -0.0742188, -0.285156, -0.589844, -0.992188, 1.03906, 0.259766, -0.0898438 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_832] shape=[3072] showing 24/3072: 0.388672, -0.00640869, 0.486328, 0.225586, -0.130859, 0.22168, -1.5, 0.664062, -0.585938, -0.554688, -0.0218506, -0.386719, -0.0639648, -0.9375, 0.0742188, -0.632812, 0.539062, -0.353516, -0.339844, -0.375, -0.992188, 0.910156, 0.0859375, 0.0751953 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_896] shape=[3072] showing 24/3072: 0.636719, 0.257812, 0.503906, 0.246094, -0.0698242, 0.128906, -1.28906, 0.90625, -0.515625, -0.539062, -0.172852, -0.357422, -0.00964355, -0.84375, 0.0610352, -0.597656, 0.347656, -0.542969, -0.320312, -0.188477, -0.820312, 0.691406, -0.0883789, 0.283203 ...
[VT][vision_model.encoder.layers.0.mlp.fc1[NLH]/item_960] shape=[3072] showing 24/3072: 0.6875, 0.480469, 0.498047, 0.257812, 0.0405273, 0.0698242, -1.04688, 1.04688, -0.384766, -0.451172, -0.216797, -0.369141, -0.00165558, -0.757812, 0.0966797, -0.488281, 0.257812, -0.675781, -0.324219, -0.0186768, -0.683594, 0.453125, -0.188477, 0.451172 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre] IN  shape=(1, 1024, 3072) layout=NLH  min=-0.169922 max=2.75 mean=0.134381 std=0.356206 sum1e6=129668
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_0] shape=[3072] showing 24/3072: -0.163086, -0.164062, 0.00354004, -0.0571289, -0.0598145, 0.601562, -0.165039, -0.166016, 0.0568848, -0.139648, 0.0688477, -0.111328, -0.155273, -0.0668945, -0.123047, -0.151367, 0.566406, 0.451172, -0.0761719, -0.169922, -0.137695, 0.6875, 0.394531, -0.166992 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_64] shape=[3072] showing 24/3072: -0.152344, -0.168945, 0.078125, -0.0178223, -0.0722656, 0.636719, -0.166016, -0.168945, 0.0101929, -0.15332, 0.123047, -0.131836, -0.157227, -0.0957031, -0.117188, -0.165039, 0.652344, 0.363281, -0.0927734, -0.169922, -0.162109, 0.789062, 0.404297, -0.163086 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_128] shape=[3072] showing 24/3072: -0.134766, -0.168945, 0.129883, 0.00205994, -0.0996094, 0.570312, -0.146484, -0.129883, -0.0722656, -0.162109, 0.145508, -0.145508, -0.15332, -0.136719, -0.0874023, -0.169922, 0.671875, 0.242188, -0.101074, -0.168945, -0.169922, 0.890625, 0.363281, -0.152344 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_192] shape=[3072] showing 24/3072: -0.0549316, -0.155273, 0.222656, 0.0795898, -0.097168, 0.417969, -0.114258, -0.0161133, -0.130859, -0.160156, 0.160156, -0.149414, -0.147461, -0.167969, -0.0358887, -0.169922, 0.59375, 0.119629, -0.0961914, -0.167969, -0.163086, 0.996094, 0.285156, -0.126953 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_256] shape=[3072] showing 24/3072: 0.0957031, -0.109375, 0.265625, 0.0834961, -0.097168, 0.227539, -0.0966797, 0.19043, -0.163086, -0.161133, 0.0800781, -0.137695, -0.0986328, -0.168945, -0.00186157, -0.169922, 0.443359, -0.0187988, -0.111328, -0.164062, -0.154297, 0.945312, 0.172852, -0.0927734 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_320] shape=[3072] showing 24/3072: 0.257812, 0.00469971, 0.365234, 0.125977, -0.0517578, 0.117188, -0.105469, 0.455078, -0.162109, -0.160156, -0.0296631, -0.137695, -0.0480957, -0.163086, 0.0649414, -0.169922, 0.351562, -0.117676, -0.125, -0.137695, -0.164062, 0.738281, 0.0444336, 0.0388184 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_384] shape=[3072] showing 24/3072: 0.447266, 0.160156, 0.359375, 0.148438, -0.00939941, 0.0544434, -0.125977, 0.746094, -0.155273, -0.15625, -0.065918, -0.138672, -0.00115967, -0.166016, 0.045166, -0.165039, 0.211914, -0.158203, -0.12793, -0.0737305, -0.169922, 0.519531, -0.0283203, 0.175781 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_448] shape=[3072] showing 24/3072: 0.65625, 0.296875, 0.365234, 0.117188, 0.026123, 0.0415039, -0.148438, 0.882812, -0.144531, -0.150391, -0.0947266, -0.121582, 0.0286865, -0.169922, 0.0522461, -0.146484, 0.144531, -0.168945, -0.118652, -0.0151978, -0.167969, 0.337891, -0.0761719, 0.269531 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_512] shape=[3072] showing 24/3072: -0.164062, -0.164062, -0.00482178, -0.0600586, -0.0742188, 0.621094, -0.164062, -0.166016, 0.0549316, -0.143555, 0.0588379, -0.104492, -0.155273, -0.0673828, -0.111816, -0.157227, 0.589844, 0.425781, -0.0712891, -0.169922, -0.138672, 0.652344, 0.398438, -0.166992 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_576] shape=[3072] showing 24/3072: -0.160156, -0.167969, 0.0480957, -0.0375977, -0.074707, 0.632812, -0.168945, -0.168945, -0.0152588, -0.154297, 0.0952148, -0.128906, -0.157227, -0.105957, -0.10791, -0.166016, 0.679688, 0.376953, -0.0786133, -0.169922, -0.162109, 0.753906, 0.365234, -0.163086 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_640] shape=[3072] showing 24/3072: -0.132812, -0.168945, 0.140625, -0.00101471, -0.097168, 0.523438, -0.147461, -0.145508, -0.0541992, -0.162109, 0.131836, -0.137695, -0.15918, -0.148438, -0.0703125, -0.169922, 0.714844, 0.267578, -0.0883789, -0.169922, -0.169922, 0.867188, 0.351562, -0.152344 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_704] shape=[3072] showing 24/3072: -0.0366211, -0.154297, 0.251953, 0.0307617, -0.0864258, 0.394531, -0.112305, -0.0256348, -0.124023, -0.165039, 0.146484, -0.15332, -0.141602, -0.163086, -0.0251465, -0.169922, 0.554688, 0.129883, -0.109375, -0.167969, -0.166016, 0.976562, 0.316406, -0.116211 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_768] shape=[3072] showing 24/3072: 0.0595703, -0.104004, 0.34375, 0.129883, -0.0810547, 0.217773, -0.0986328, 0.219727, -0.158203, -0.162109, 0.060791, -0.149414, -0.0854492, -0.167969, 0.0252686, -0.169922, 0.519531, -0.0349121, -0.110352, -0.164062, -0.15918, 0.882812, 0.15625, -0.041748 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_832] shape=[3072] showing 24/3072: 0.253906, -0.00318909, 0.333984, 0.132812, -0.0585938, 0.129883, -0.100586, 0.496094, -0.163086, -0.160156, -0.0107422, -0.134766, -0.0303955, -0.163086, 0.0393066, -0.166992, 0.380859, -0.12793, -0.124512, -0.132812, -0.15918, 0.746094, 0.0458984, 0.0397949 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_896] shape=[3072] showing 24/3072: 0.470703, 0.155273, 0.349609, 0.146484, -0.032959, 0.0712891, -0.12793, 0.742188, -0.15625, -0.15918, -0.074707, -0.128906, -0.00479126, -0.167969, 0.0319824, -0.164062, 0.220703, -0.15918, -0.120117, -0.0800781, -0.168945, 0.523438, -0.0410156, 0.172852 ...
[VT][vision_model.encoder.layers.0.mlp.fc2/pre[NLH]/item_960] shape=[3072] showing 24/3072: 0.519531, 0.328125, 0.34375, 0.155273, 0.020874, 0.0368652, -0.154297, 0.890625, -0.134766, -0.147461, -0.0898438, -0.131836, -0.000827789, -0.169922, 0.052002, -0.152344, 0.155273, -0.168945, -0.121094, -0.00921631, -0.168945, 0.306641, -0.0800781, 0.304688 ...
[VT][vision_model.encoder.layers.0.mlp.fc2] OUT shape=(1, 1024, 768) layout=NLH  min=-1.76562 max=2.17188 mean=-0.0506687 std=0.485733 sum1e6=-39847.5
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_0] shape=[768] showing 24/768: 0.107422, 0.404297, -0.0524902, 0.523438, -0.384766, 0.380859, -0.710938, 0.628906, 0.349609, 0.371094, 0.453125, -0.0932617, -0.621094, -0.546875, -0.474609, -0.103516, -0.585938, -0.0952148, 0.298828, -0.392578, 0.597656, -0.304688, 0.378906, -0.261719 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_64] shape=[768] showing 24/768: 0.242188, 0.408203, -0.122559, 0.427734, -0.259766, 0.478516, -0.613281, 0.632812, 0.265625, 0.390625, 0.373047, -0.0270996, -0.808594, -0.539062, -0.345703, -0.162109, -0.458984, -0.164062, 0.151367, -0.357422, 0.492188, -0.294922, 0.429688, -0.226562 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_128] shape=[768] showing 24/768: 0.349609, 0.480469, -0.208008, 0.347656, -0.107422, 0.605469, -0.439453, 0.554688, 0.0800781, 0.404297, 0.271484, 0.0356445, -0.941406, -0.494141, -0.162109, -0.125977, -0.285156, -0.201172, -0.0683594, -0.394531, 0.232422, -0.208984, 0.597656, -0.226562 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_192] shape=[768] showing 24/768: 0.410156, 0.613281, -0.25, 0.0800781, 0.0703125, 0.691406, -0.332031, 0.408203, -0.202148, 0.398438, 0.125977, 0.0942383, -1.0625, -0.433594, 0.0202637, -0.0108643, 0.0825195, -0.289062, -0.183594, -0.361328, -0.0568848, -0.0849609, 0.738281, -0.273438 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_256] shape=[768] showing 24/768: 0.5, 0.65625, -0.140625, -0.168945, 0.191406, 0.75, -0.263672, 0.158203, -0.457031, 0.365234, -0.0205078, 0.120605, -1.09375, -0.287109, 0.179688, -0.0617676, 0.5625, -0.386719, -0.300781, -0.234375, -0.341797, -0.0255127, 0.808594, -0.373047 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_320] shape=[768] showing 24/768: 0.527344, 0.570312, 0.0143433, -0.197266, 0.168945, 0.761719, -0.140625, -0.123535, -0.636719, 0.347656, -0.211914, 0.0668945, -0.957031, -0.160156, 0.277344, -0.168945, 0.914062, -0.492188, -0.294922, -0.140625, -0.582031, 0.0505371, 0.722656, -0.402344 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_384] shape=[768] showing 24/768: 0.519531, 0.408203, 0.168945, -0.165039, 0.143555, 0.722656, -0.109375, -0.439453, -0.625, 0.296875, -0.353516, -0.0055542, -0.804688, -0.0478516, 0.337891, -0.277344, 1.01562, -0.5625, -0.239258, -0.0123291, -0.769531, 0.0825195, 0.5625, -0.425781 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_448] shape=[768] showing 24/768: 0.46875, 0.273438, 0.255859, -0.133789, 0.131836, 0.671875, -0.100586, -0.652344, -0.585938, 0.24707, -0.4375, -0.0595703, -0.644531, 0.0698242, 0.308594, -0.414062, 1.03125, -0.621094, -0.202148, 0.0551758, -0.882812, 0.143555, 0.378906, -0.353516 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_512] shape=[768] showing 24/768: 0.126953, 0.392578, -0.0284424, 0.566406, -0.380859, 0.337891, -0.730469, 0.613281, 0.384766, 0.384766, 0.449219, -0.0917969, -0.648438, -0.546875, -0.427734, -0.149414, -0.617188, -0.09375, 0.287109, -0.40625, 0.589844, -0.310547, 0.369141, -0.275391 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_576] shape=[768] showing 24/768: 0.224609, 0.431641, -0.108887, 0.472656, -0.291016, 0.433594, -0.621094, 0.652344, 0.273438, 0.414062, 0.353516, 0.0038147, -0.792969, -0.490234, -0.337891, -0.164062, -0.519531, -0.119629, 0.147461, -0.40625, 0.423828, -0.279297, 0.431641, -0.255859 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_640] shape=[768] showing 24/768: 0.328125, 0.472656, -0.225586, 0.269531, -0.0756836, 0.589844, -0.417969, 0.597656, 0.100586, 0.419922, 0.245117, 0.0830078, -0.964844, -0.443359, -0.167969, -0.102539, -0.289062, -0.217773, -0.0786133, -0.349609, 0.223633, -0.216797, 0.53125, -0.197266 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_704] shape=[768] showing 24/768: 0.476562, 0.582031, -0.234375, 0.0341797, 0.09375, 0.726562, -0.275391, 0.394531, -0.154297, 0.375, 0.15625, 0.0927734, -1.08594, -0.416016, -0.0145264, -0.0668945, 0.0805664, -0.298828, -0.240234, -0.302734, -0.0498047, -0.120605, 0.722656, -0.228516 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_768] shape=[768] showing 24/768: 0.490234, 0.617188, -0.150391, -0.121582, 0.166992, 0.773438, -0.178711, 0.15625, -0.472656, 0.398438, -0.0541992, 0.0947266, -1.02344, -0.291016, 0.152344, -0.0305176, 0.554688, -0.382812, -0.355469, -0.255859, -0.375, -0.046875, 0.8125, -0.414062 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_832] shape=[768] showing 24/768: 0.558594, 0.570312, -0.0020752, -0.191406, 0.177734, 0.722656, -0.0869141, -0.12793, -0.609375, 0.365234, -0.224609, 0.0961914, -0.996094, -0.1875, 0.263672, -0.157227, 0.882812, -0.46875, -0.227539, -0.0791016, -0.636719, 0.0620117, 0.710938, -0.416016 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_896] shape=[768] showing 24/768: 0.539062, 0.4375, 0.171875, -0.169922, 0.182617, 0.6875, -0.0976562, -0.421875, -0.636719, 0.287109, -0.333984, 0.00799561, -0.828125, -0.0400391, 0.326172, -0.28125, 1.03906, -0.558594, -0.225586, 0.0146484, -0.78125, 0.0791016, 0.558594, -0.447266 ...
[VT][vision_model.encoder.layers.0.mlp.fc2[NLH]/item_960] shape=[768] showing 24/768: 0.466797, 0.271484, 0.275391, -0.11084, 0.0864258, 0.683594, -0.0976562, -0.628906, -0.601562, 0.255859, -0.445312, -0.0786133, -0.671875, 0.0776367, 0.28125, -0.400391, 1.03125, -0.59375, -0.205078, 0.0456543, -0.871094, 0.132812, 0.384766, -0.376953 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.5625 max=5.125 mean=-0.0511444 std=0.871675 sum1e6=-40221.6
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_0] shape=[768] showing 24/768: 1.07812, -0.0859375, 0.212891, 1.22656, 0.710938, 0.111328, -0.164062, -0.0742188, 0.65625, 1.54688, 0.714844, -0.796875, -1.125, -0.96875, -0.5, -0.734375, 2.125, -0.96875, -0.601562, 0.216797, 2.23438, 0.640625, 1.11719, 1.23438 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_64] shape=[768] showing 24/768: 0.820312, -0.208984, 0.267578, 0.921875, 0.664062, 0.243164, -0.271484, -0.148438, 0.730469, 0.949219, 0.287109, -0.416016, -1.14062, -0.789062, -0.464844, -0.890625, 1.75781, -0.953125, -0.621094, 0.0488281, 1.92188, 0.90625, 0.886719, 1.30469 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_128] shape=[768] showing 24/768: 0.5, -0.300781, 0.371094, 0.519531, 0.507812, 0.398438, -0.339844, -0.222656, 0.671875, 0.435547, -0.0761719, -0.154297, -1.20312, -0.617188, -0.347656, -0.984375, 1.34375, -0.890625, -0.765625, -0.213867, 1.45312, 1.04688, 0.824219, 1.29688 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_192] shape=[768] showing 24/768: 0.0234375, -0.3125, 0.566406, -0.177734, 0.605469, 0.609375, -0.507812, -0.400391, 0.480469, -0.210938, -0.429688, 0.154297, -1.13281, -0.40625, -0.21582, -0.902344, 1.17188, -0.78125, -0.964844, -0.363281, 0.949219, 1.375, 0.726562, 1.16406 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_256] shape=[768] showing 24/768: -0.34375, -0.351562, 0.882812, -0.707031, 0.621094, 0.835938, -0.78125, -0.734375, 0.238281, -0.726562, -0.652344, 0.488281, -1.1875, -0.126953, -0.0742188, -1.01562, 1.09375, -0.816406, -1.07812, -0.466797, 0.431641, 1.50781, 0.703125, 0.9375 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_320] shape=[768] showing 24/768: -0.816406, -0.4375, 1.28906, -1.07812, 0.457031, 0.792969, -1, -1, 0.0546875, -1.21875, -0.875, 0.671875, -0.96875, 0.214844, -0.0449219, -1.00781, 0.972656, -0.886719, -0.984375, -0.632812, -0.0664062, 1.50781, 0.664062, 0.769531 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_384] shape=[768] showing 24/768: -1.20312, -0.609375, 1.57812, -1.28906, 0.357422, 0.816406, -1.16406, -1.30469, 0.195312, -1.45312, -1.00781, 0.730469, -0.796875, 0.585938, -0.105469, -1.09375, 0.691406, -1.04688, -0.808594, -0.683594, -0.476562, 1.46094, 0.386719, 0.582031 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_448] shape=[768] showing 24/768: -1.59375, -0.722656, 1.75781, -1.50781, 0.132812, 0.8125, -1.28125, -1.625, 0.234375, -1.875, -1.1875, 0.878906, -0.53125, 1.00781, -0.261719, -1.10156, 0.285156, -1.125, -0.589844, -0.722656, -0.875, 1.48438, 0.119141, 0.462891 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_512] shape=[768] showing 24/768: 1.07812, -0.0800781, 0.298828, 1.29688, 0.664062, 0.0410156, -0.261719, -0.121094, 0.710938, 1.53906, 0.632812, -0.757812, -1.07812, -0.945312, -0.402344, -0.765625, 2.15625, -0.976562, -0.578125, 0.175781, 2.23438, 0.632812, 1.05469, 1.25 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_576] shape=[768] showing 24/768: 0.851562, -0.154297, 0.371094, 0.980469, 0.554688, 0.18457, -0.355469, -0.101562, 0.71875, 1.03125, 0.267578, -0.417969, -1.16406, -0.773438, -0.453125, -0.890625, 1.73438, -0.894531, -0.636719, 0.00585938, 1.95312, 0.835938, 0.875, 1.33594 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_640] shape=[768] showing 24/768: 0.511719, -0.269531, 0.34375, 0.416016, 0.574219, 0.392578, -0.294922, -0.117188, 0.648438, 0.388672, -0.0478516, -0.12793, -1.17188, -0.5625, -0.345703, -0.960938, 1.4375, -0.875, -0.824219, -0.202148, 1.53906, 1.04688, 0.746094, 1.35156 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_704] shape=[768] showing 24/768: 0.0703125, -0.347656, 0.5, -0.128906, 0.582031, 0.605469, -0.425781, -0.402344, 0.523438, -0.234375, -0.337891, 0.164062, -1.19531, -0.4375, -0.24707, -1.02344, 1.1875, -0.929688, -0.960938, -0.332031, 1.09375, 1.29688, 0.773438, 1.28906 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_768] shape=[768] showing 24/768: -0.439453, -0.320312, 0.914062, -0.628906, 0.601562, 0.730469, -0.695312, -0.625, 0.261719, -0.664062, -0.707031, 0.425781, -1.10938, -0.167969, -0.134766, -0.992188, 1.16406, -0.746094, -1.07812, -0.539062, 0.394531, 1.375, 0.773438, 0.914062 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_832] shape=[768] showing 24/768: -0.769531, -0.421875, 1.34375, -1.02344, 0.498047, 0.808594, -0.90625, -0.953125, 0.148438, -1.13281, -0.960938, 0.6875, -1.03125, 0.15625, -0.119141, -0.980469, 0.960938, -0.796875, -0.875, -0.566406, -0.148438, 1.51562, 0.597656, 0.75 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_896] shape=[768] showing 24/768: -1.14062, -0.601562, 1.60938, -1.32031, 0.324219, 0.875, -1.09375, -1.35938, 0.121094, -1.52344, -0.992188, 0.792969, -0.746094, 0.617188, -0.212891, -1.04688, 0.675781, -0.949219, -0.75, -0.695312, -0.566406, 1.39062, 0.382812, 0.490234 ...
[VT][vision_model.encoder.layers.1.layer_norm1/pre[NLH]/item_960] shape=[768] showing 24/768: -1.625, -0.710938, 1.80469, -1.45312, 0.0874023, 0.867188, -1.26562, -1.64062, 0.222656, -1.89844, -1.17188, 0.890625, -0.589844, 1.07031, -0.320312, -1.07031, 0.289062, -1.07031, -0.546875, -0.71875, -0.847656, 1.46875, 0.198242, 0.416016 ...
[VT][vision_model.encoder.layers.1.layer_norm1] OUT shape=(1, 1024, 768) layout=NLH  min=-3.875 max=4.40625 mean=-8.44865e-07 std=0.999998 sum1e6=-0.664429
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_0] shape=[768] showing 24/768: 0.792969, -0.245117, 0.0213623, 0.925781, 0.464844, -0.0688477, -0.314453, -0.234375, 0.416016, 1.21094, 0.46875, -0.878906, -1.17188, -1.03125, -0.613281, -0.820312, 1.72656, -1.03125, -0.703125, 0.0249023, 1.82031, 0.402344, 0.828125, 0.929688 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_64] shape=[768] showing 24/768: 0.652344, -0.357422, 0.110352, 0.753906, 0.5, 0.0864258, -0.419922, -0.298828, 0.566406, 0.78125, 0.129883, -0.5625, -1.27344, -0.929688, -0.609375, -1.03125, 1.57812, -1.08594, -0.761719, -0.104492, 1.73438, 0.738281, 0.71875, 1.13281 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_128] shape=[768] showing 24/768: 0.400391, -0.451172, 0.263672, 0.421875, 0.410156, 0.292969, -0.492188, -0.367188, 0.582031, 0.332031, -0.211914, -0.294922, -1.41406, -0.789062, -0.5, -1.17969, 1.29688, -1.07812, -0.945312, -0.359375, 1.41406, 0.984375, 0.746094, 1.25 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_192] shape=[768] showing 24/768: -0.0678711, -0.441406, 0.535156, -0.291016, 0.578125, 0.582031, -0.65625, -0.539062, 0.439453, -0.328125, -0.570312, 0.0771484, -1.35156, -0.542969, -0.333984, -1.09375, 1.20312, -0.960938, -1.16406, -0.496094, 0.957031, 1.42969, 0.710938, 1.19531 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_256] shape=[768] showing 24/768: -0.431641, -0.439453, 0.925781, -0.832031, 0.636719, 0.875, -0.914062, -0.863281, 0.212891, -0.855469, -0.773438, 0.490234, -1.36719, -0.191406, -0.132812, -1.17188, 1.16406, -0.953125, -1.24219, -0.566406, 0.427734, 1.61719, 0.726562, 0.988281 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_320] shape=[768] showing 24/768: -0.886719, -0.478516, 1.375, -1.16406, 0.484375, 0.84375, -1.08594, -1.08594, 0.0510254, -1.32031, -0.949219, 0.714844, -1.04688, 0.223633, -0.0561523, -1.09375, 1.03906, -0.960938, -1.0625, -0.6875, -0.0791016, 1.60938, 0.707031, 0.820312 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_384] shape=[768] showing 24/768: -1.1875, -0.589844, 1.61719, -1.27344, 0.386719, 0.851562, -1.14844, -1.28906, 0.222656, -1.44531, -0.992188, 0.761719, -0.777344, 0.617188, -0.0805664, -1.07812, 0.722656, -1.03125, -0.789062, -0.664062, -0.455078, 1.5, 0.416016, 0.613281 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_448] shape=[768] showing 24/768: -1.40625, -0.609375, 1.67188, -1.32812, 0.176758, 0.800781, -1.125, -1.4375, 0.269531, -1.67188, -1.03906, 0.863281, -0.433594, 0.980469, -0.185547, -0.957031, 0.316406, -0.980469, -0.486328, -0.609375, -0.75, 1.42188, 0.164062, 0.480469 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_512] shape=[768] showing 24/768: 0.792969, -0.239258, 0.0981445, 0.984375, 0.423828, -0.130859, -0.400391, -0.275391, 0.464844, 1.20312, 0.394531, -0.839844, -1.125, -1.00781, -0.527344, -0.847656, 1.75, -1.03906, -0.683594, -0.0114136, 1.82031, 0.394531, 0.769531, 0.945312 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_576] shape=[768] showing 24/768: 0.683594, -0.306641, 0.210938, 0.8125, 0.392578, 0.0272217, -0.503906, -0.253906, 0.554688, 0.863281, 0.108887, -0.566406, -1.30469, -0.917969, -0.601562, -1.03125, 1.55469, -1.03906, -0.78125, -0.148438, 1.77344, 0.667969, 0.707031, 1.16406 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_640] shape=[768] showing 24/768: 0.414062, -0.417969, 0.234375, 0.3125, 0.480469, 0.287109, -0.445312, -0.255859, 0.558594, 0.283203, -0.182617, -0.267578, -1.38281, -0.730469, -0.5, -1.15625, 1.39844, -1.0625, -1.00781, -0.345703, 1.50781, 0.984375, 0.664062, 1.30469 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_704] shape=[768] showing 24/768: -0.0167236, -0.480469, 0.458984, -0.237305, 0.550781, 0.574219, -0.566406, -0.539062, 0.484375, -0.353516, -0.46875, 0.0869141, -1.42188, -0.578125, -0.369141, -1.22656, 1.21875, -1.125, -1.15625, -0.462891, 1.11719, 1.34375, 0.761719, 1.33594 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_768] shape=[768] showing 24/768: -0.539062, -0.40625, 0.964844, -0.75, 0.617188, 0.761719, -0.824219, -0.746094, 0.239258, -0.789062, -0.835938, 0.421875, -1.28125, -0.238281, -0.201172, -1.15625, 1.24219, -0.878906, -1.25, -0.648438, 0.386719, 1.47656, 0.808594, 0.964844 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_832] shape=[768] showing 24/768: -0.839844, -0.464844, 1.4375, -1.11719, 0.527344, 0.863281, -0.988281, -1.03906, 0.149414, -1.23438, -1.04688, 0.730469, -1.125, 0.158203, -0.138672, -1.07031, 1.02344, -0.871094, -0.953125, -0.621094, -0.169922, 1.625, 0.632812, 0.796875 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_896] shape=[768] showing 24/768: -1.13281, -0.585938, 1.65625, -1.3125, 0.353516, 0.910156, -1.08594, -1.35156, 0.147461, -1.51562, -0.980469, 0.828125, -0.730469, 0.648438, -0.191406, -1.03906, 0.707031, -0.9375, -0.734375, -0.679688, -0.550781, 1.42969, 0.412109, 0.519531 ...
[VT][vision_model.encoder.layers.1.layer_norm1[NLH]/item_960] shape=[768] showing 24/768: -1.4375, -0.601562, 1.71094, -1.28125, 0.132812, 0.851562, -1.10938, -1.45312, 0.257812, -1.69531, -1.02344, 0.871094, -0.488281, 1.03906, -0.241211, -0.929688, 0.318359, -0.929688, -0.449219, -0.609375, -0.726562, 1.40625, 0.235352, 0.435547 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.875 max=4.40625 mean=-8.44865e-07 std=0.999998 sum1e6=-0.664429
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.792969, -0.245117, 0.0213623, 0.925781, 0.464844, -0.0688477, -0.314453, -0.234375, 0.416016, 1.21094, 0.46875, -0.878906, -1.17188, -1.03125, -0.613281, -0.820312, 1.72656, -1.03125, -0.703125, 0.0249023, 1.82031, 0.402344, 0.828125, 0.929688 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.652344, -0.357422, 0.110352, 0.753906, 0.5, 0.0864258, -0.419922, -0.298828, 0.566406, 0.78125, 0.129883, -0.5625, -1.27344, -0.929688, -0.609375, -1.03125, 1.57812, -1.08594, -0.761719, -0.104492, 1.73438, 0.738281, 0.71875, 1.13281 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.400391, -0.451172, 0.263672, 0.421875, 0.410156, 0.292969, -0.492188, -0.367188, 0.582031, 0.332031, -0.211914, -0.294922, -1.41406, -0.789062, -0.5, -1.17969, 1.29688, -1.07812, -0.945312, -0.359375, 1.41406, 0.984375, 0.746094, 1.25 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.0678711, -0.441406, 0.535156, -0.291016, 0.578125, 0.582031, -0.65625, -0.539062, 0.439453, -0.328125, -0.570312, 0.0771484, -1.35156, -0.542969, -0.333984, -1.09375, 1.20312, -0.960938, -1.16406, -0.496094, 0.957031, 1.42969, 0.710938, 1.19531 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.431641, -0.439453, 0.925781, -0.832031, 0.636719, 0.875, -0.914062, -0.863281, 0.212891, -0.855469, -0.773438, 0.490234, -1.36719, -0.191406, -0.132812, -1.17188, 1.16406, -0.953125, -1.24219, -0.566406, 0.427734, 1.61719, 0.726562, 0.988281 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.886719, -0.478516, 1.375, -1.16406, 0.484375, 0.84375, -1.08594, -1.08594, 0.0510254, -1.32031, -0.949219, 0.714844, -1.04688, 0.223633, -0.0561523, -1.09375, 1.03906, -0.960938, -1.0625, -0.6875, -0.0791016, 1.60938, 0.707031, 0.820312 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.1875, -0.589844, 1.61719, -1.27344, 0.386719, 0.851562, -1.14844, -1.28906, 0.222656, -1.44531, -0.992188, 0.761719, -0.777344, 0.617188, -0.0805664, -1.07812, 0.722656, -1.03125, -0.789062, -0.664062, -0.455078, 1.5, 0.416016, 0.613281 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.40625, -0.609375, 1.67188, -1.32812, 0.176758, 0.800781, -1.125, -1.4375, 0.269531, -1.67188, -1.03906, 0.863281, -0.433594, 0.980469, -0.185547, -0.957031, 0.316406, -0.980469, -0.486328, -0.609375, -0.75, 1.42188, 0.164062, 0.480469 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.792969, -0.239258, 0.0981445, 0.984375, 0.423828, -0.130859, -0.400391, -0.275391, 0.464844, 1.20312, 0.394531, -0.839844, -1.125, -1.00781, -0.527344, -0.847656, 1.75, -1.03906, -0.683594, -0.0114136, 1.82031, 0.394531, 0.769531, 0.945312 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.683594, -0.306641, 0.210938, 0.8125, 0.392578, 0.0272217, -0.503906, -0.253906, 0.554688, 0.863281, 0.108887, -0.566406, -1.30469, -0.917969, -0.601562, -1.03125, 1.55469, -1.03906, -0.78125, -0.148438, 1.77344, 0.667969, 0.707031, 1.16406 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.414062, -0.417969, 0.234375, 0.3125, 0.480469, 0.287109, -0.445312, -0.255859, 0.558594, 0.283203, -0.182617, -0.267578, -1.38281, -0.730469, -0.5, -1.15625, 1.39844, -1.0625, -1.00781, -0.345703, 1.50781, 0.984375, 0.664062, 1.30469 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.0167236, -0.480469, 0.458984, -0.237305, 0.550781, 0.574219, -0.566406, -0.539062, 0.484375, -0.353516, -0.46875, 0.0869141, -1.42188, -0.578125, -0.369141, -1.22656, 1.21875, -1.125, -1.15625, -0.462891, 1.11719, 1.34375, 0.761719, 1.33594 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.539062, -0.40625, 0.964844, -0.75, 0.617188, 0.761719, -0.824219, -0.746094, 0.239258, -0.789062, -0.835938, 0.421875, -1.28125, -0.238281, -0.201172, -1.15625, 1.24219, -0.878906, -1.25, -0.648438, 0.386719, 1.47656, 0.808594, 0.964844 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.839844, -0.464844, 1.4375, -1.11719, 0.527344, 0.863281, -0.988281, -1.03906, 0.149414, -1.23438, -1.04688, 0.730469, -1.125, 0.158203, -0.138672, -1.07031, 1.02344, -0.871094, -0.953125, -0.621094, -0.169922, 1.625, 0.632812, 0.796875 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.13281, -0.585938, 1.65625, -1.3125, 0.353516, 0.910156, -1.08594, -1.35156, 0.147461, -1.51562, -0.980469, 0.828125, -0.730469, 0.648438, -0.191406, -1.03906, 0.707031, -0.9375, -0.734375, -0.679688, -0.550781, 1.42969, 0.412109, 0.519531 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.4375, -0.601562, 1.71094, -1.28125, 0.132812, 0.851562, -1.10938, -1.45312, 0.257812, -1.69531, -1.02344, 0.871094, -0.488281, 1.03906, -0.241211, -0.929688, 0.318359, -0.929688, -0.449219, -0.609375, -0.726562, 1.40625, 0.235352, 0.435547 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.15625 max=3.71875 mean=-0.00541797 std=1.00639 sum1e6=-4260.86
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_0] shape=[768] showing 24/768: -1.20312, -0.808594, -0.0393066, 0.458984, -2.07812, -1.30469, -0.691406, -0.492188, -0.0446777, 0.0625, -0.855469, 0.0576172, 0.476562, -0.703125, -0.369141, 0.660156, 0.318359, -0.59375, 0.0101318, 2.125, 0.457031, -0.308594, 0.339844, 2.09375 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_64] shape=[768] showing 24/768: -1.375, -0.6875, -0.128906, 0.347656, -1.88281, -1.24219, -0.589844, -0.304688, -0.129883, 0.00216675, -0.738281, 0.103516, 0.394531, -0.808594, -0.236328, 0.652344, 0.198242, -0.8125, -0.157227, 1.98438, 0.341797, -0.263672, 0.289062, 1.9375 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_128] shape=[768] showing 24/768: -1.57031, -0.753906, -0.168945, 0.120117, -1.60156, -1.05469, -0.371094, 0.0476074, -0.322266, 0.140625, -0.683594, 0.102539, 0.273438, -0.800781, -0.00159454, 0.605469, 0.0150146, -0.886719, -0.427734, 1.63281, 0.111816, -0.365234, 0.291016, 1.72656 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_192] shape=[768] showing 24/768: -1.64844, -0.738281, -0.271484, -0.00153351, -1.10938, -0.96875, -0.119141, 0.640625, -0.546875, 0.18457, -0.496094, -0.00939941, 0.196289, -0.824219, 0.234375, 0.480469, -0.102051, -0.945312, -0.605469, 1.15625, -0.0737305, -0.435547, 0.511719, 1.28125 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_256] shape=[768] showing 24/768: -1.6875, -0.773438, -0.292969, -0.03125, -0.679688, -0.691406, 0.0222168, 1.07031, -0.800781, 0.300781, -0.332031, -0.0495605, 0.0317383, -0.785156, 0.664062, 0.478516, -0.0159912, -1.00781, -0.644531, 0.648438, -0.408203, -0.40625, 0.796875, 0.515625 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_320] shape=[768] showing 24/768: -1.57812, -0.808594, -0.390625, -0.00994873, -0.18457, -0.328125, -0.0649414, 1.28906, -0.789062, 0.361328, 0.117188, -0.097168, -0.0441895, -0.695312, 0.945312, 0.457031, -0.0947266, -1.09375, -0.683594, 0.189453, -0.416016, -0.455078, 0.921875, -0.170898 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_384] shape=[768] showing 24/768: -1.45312, -0.78125, -0.494141, 0.0620117, 0.251953, 0.0206299, -0.123047, 1.27344, -0.832031, 0.425781, 0.511719, -0.289062, -0.00152588, -0.597656, 1.125, 0.386719, -0.118652, -1.09375, -0.675781, -0.173828, -0.353516, -0.542969, 0.886719, -0.601562 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_448] shape=[768] showing 24/768: -1.11719, -0.664062, -0.550781, 0.0849609, 0.636719, 0.241211, -0.118652, 1.14844, -0.859375, 0.361328, 0.964844, -0.53125, -0.0258789, -0.554688, 1.23438, 0.242188, -0.181641, -1.00781, -0.753906, -0.466797, -0.318359, -0.570312, 0.757812, -0.84375 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_512] shape=[768] showing 24/768: -1.21875, -0.777344, -0.0476074, 0.503906, -2.01562, -1.375, -0.632812, -0.523438, -0.065918, 0.0129395, -0.800781, 0.109375, 0.474609, -0.777344, -0.335938, 0.703125, 0.357422, -0.640625, 0.043457, 2.14062, 0.464844, -0.263672, 0.425781, 2.09375 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_576] shape=[768] showing 24/768: -1.36719, -0.699219, -0.166016, 0.365234, -1.82812, -1.23438, -0.613281, -0.308594, -0.208008, 0.0184326, -0.75, 0.102051, 0.369141, -0.8125, -0.249023, 0.667969, 0.257812, -0.808594, -0.166016, 1.96094, 0.369141, -0.337891, 0.294922, 2.0625 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_640] shape=[768] showing 24/768: -1.5, -0.832031, -0.199219, 0.201172, -1.5625, -1.07812, -0.404297, 0.0517578, -0.466797, 0.0585938, -0.636719, 0.0981445, 0.333984, -0.84375, -0.0913086, 0.625, 0.10791, -0.863281, -0.402344, 1.65625, 0.196289, -0.337891, 0.330078, 1.80469 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_704] shape=[768] showing 24/768: -1.5625, -0.746094, -0.269531, 0.119629, -1.21875, -0.953125, -0.0473633, 0.488281, -0.730469, 0.180664, -0.503906, 0.00772095, 0.314453, -0.824219, 0.197266, 0.53125, -0.0194092, -0.855469, -0.617188, 1.27344, -0.0429688, -0.339844, 0.488281, 1.35156 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_768] shape=[768] showing 24/768: -1.54688, -0.78125, -0.255859, 0.0395508, -0.617188, -0.671875, 0.00473022, 1.01562, -0.78125, 0.300781, -0.227539, 0.0751953, 0.097168, -0.746094, 0.589844, 0.515625, -0.0668945, -0.957031, -0.804688, 0.734375, -0.261719, -0.328125, 0.785156, 0.542969 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_832] shape=[768] showing 24/768: -1.57031, -0.804688, -0.369141, 0.0378418, -0.185547, -0.357422, -0.0112915, 1.24219, -0.796875, 0.367188, 0.0664062, -0.0820312, -0.00723267, -0.671875, 1, 0.507812, -0.155273, -1.02344, -0.78125, 0.180664, -0.353516, -0.460938, 0.945312, -0.133789 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_896] shape=[768] showing 24/768: -1.4375, -0.769531, -0.478516, 0.0595703, 0.251953, -0.0169678, -0.0708008, 1.26562, -0.871094, 0.34375, 0.515625, -0.316406, 0.00427246, -0.546875, 1.16406, 0.427734, -0.135742, -1.03906, -0.769531, -0.255859, -0.388672, -0.578125, 0.847656, -0.570312 ...
[VT][vision_model.encoder.layers.1.self_attn.q_proj[NLH]/item_960] shape=[768] showing 24/768: -1.14844, -0.6875, -0.578125, 0.0800781, 0.628906, 0.320312, -0.154297, 1.25781, -0.839844, 0.398438, 0.941406, -0.40625, 0.0299072, -0.519531, 1.20312, 0.244141, -0.132812, -1.07031, -0.714844, -0.482422, -0.322266, -0.554688, 0.742188, -0.863281 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.875 max=4.40625 mean=-8.44865e-07 std=0.999998 sum1e6=-0.664429
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.792969, -0.245117, 0.0213623, 0.925781, 0.464844, -0.0688477, -0.314453, -0.234375, 0.416016, 1.21094, 0.46875, -0.878906, -1.17188, -1.03125, -0.613281, -0.820312, 1.72656, -1.03125, -0.703125, 0.0249023, 1.82031, 0.402344, 0.828125, 0.929688 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.652344, -0.357422, 0.110352, 0.753906, 0.5, 0.0864258, -0.419922, -0.298828, 0.566406, 0.78125, 0.129883, -0.5625, -1.27344, -0.929688, -0.609375, -1.03125, 1.57812, -1.08594, -0.761719, -0.104492, 1.73438, 0.738281, 0.71875, 1.13281 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.400391, -0.451172, 0.263672, 0.421875, 0.410156, 0.292969, -0.492188, -0.367188, 0.582031, 0.332031, -0.211914, -0.294922, -1.41406, -0.789062, -0.5, -1.17969, 1.29688, -1.07812, -0.945312, -0.359375, 1.41406, 0.984375, 0.746094, 1.25 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.0678711, -0.441406, 0.535156, -0.291016, 0.578125, 0.582031, -0.65625, -0.539062, 0.439453, -0.328125, -0.570312, 0.0771484, -1.35156, -0.542969, -0.333984, -1.09375, 1.20312, -0.960938, -1.16406, -0.496094, 0.957031, 1.42969, 0.710938, 1.19531 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.431641, -0.439453, 0.925781, -0.832031, 0.636719, 0.875, -0.914062, -0.863281, 0.212891, -0.855469, -0.773438, 0.490234, -1.36719, -0.191406, -0.132812, -1.17188, 1.16406, -0.953125, -1.24219, -0.566406, 0.427734, 1.61719, 0.726562, 0.988281 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.886719, -0.478516, 1.375, -1.16406, 0.484375, 0.84375, -1.08594, -1.08594, 0.0510254, -1.32031, -0.949219, 0.714844, -1.04688, 0.223633, -0.0561523, -1.09375, 1.03906, -0.960938, -1.0625, -0.6875, -0.0791016, 1.60938, 0.707031, 0.820312 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.1875, -0.589844, 1.61719, -1.27344, 0.386719, 0.851562, -1.14844, -1.28906, 0.222656, -1.44531, -0.992188, 0.761719, -0.777344, 0.617188, -0.0805664, -1.07812, 0.722656, -1.03125, -0.789062, -0.664062, -0.455078, 1.5, 0.416016, 0.613281 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.40625, -0.609375, 1.67188, -1.32812, 0.176758, 0.800781, -1.125, -1.4375, 0.269531, -1.67188, -1.03906, 0.863281, -0.433594, 0.980469, -0.185547, -0.957031, 0.316406, -0.980469, -0.486328, -0.609375, -0.75, 1.42188, 0.164062, 0.480469 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.792969, -0.239258, 0.0981445, 0.984375, 0.423828, -0.130859, -0.400391, -0.275391, 0.464844, 1.20312, 0.394531, -0.839844, -1.125, -1.00781, -0.527344, -0.847656, 1.75, -1.03906, -0.683594, -0.0114136, 1.82031, 0.394531, 0.769531, 0.945312 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.683594, -0.306641, 0.210938, 0.8125, 0.392578, 0.0272217, -0.503906, -0.253906, 0.554688, 0.863281, 0.108887, -0.566406, -1.30469, -0.917969, -0.601562, -1.03125, 1.55469, -1.03906, -0.78125, -0.148438, 1.77344, 0.667969, 0.707031, 1.16406 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.414062, -0.417969, 0.234375, 0.3125, 0.480469, 0.287109, -0.445312, -0.255859, 0.558594, 0.283203, -0.182617, -0.267578, -1.38281, -0.730469, -0.5, -1.15625, 1.39844, -1.0625, -1.00781, -0.345703, 1.50781, 0.984375, 0.664062, 1.30469 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.0167236, -0.480469, 0.458984, -0.237305, 0.550781, 0.574219, -0.566406, -0.539062, 0.484375, -0.353516, -0.46875, 0.0869141, -1.42188, -0.578125, -0.369141, -1.22656, 1.21875, -1.125, -1.15625, -0.462891, 1.11719, 1.34375, 0.761719, 1.33594 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.539062, -0.40625, 0.964844, -0.75, 0.617188, 0.761719, -0.824219, -0.746094, 0.239258, -0.789062, -0.835938, 0.421875, -1.28125, -0.238281, -0.201172, -1.15625, 1.24219, -0.878906, -1.25, -0.648438, 0.386719, 1.47656, 0.808594, 0.964844 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.839844, -0.464844, 1.4375, -1.11719, 0.527344, 0.863281, -0.988281, -1.03906, 0.149414, -1.23438, -1.04688, 0.730469, -1.125, 0.158203, -0.138672, -1.07031, 1.02344, -0.871094, -0.953125, -0.621094, -0.169922, 1.625, 0.632812, 0.796875 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.13281, -0.585938, 1.65625, -1.3125, 0.353516, 0.910156, -1.08594, -1.35156, 0.147461, -1.51562, -0.980469, 0.828125, -0.730469, 0.648438, -0.191406, -1.03906, 0.707031, -0.9375, -0.734375, -0.679688, -0.550781, 1.42969, 0.412109, 0.519531 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.4375, -0.601562, 1.71094, -1.28125, 0.132812, 0.851562, -1.10938, -1.45312, 0.257812, -1.69531, -1.02344, 0.871094, -0.488281, 1.03906, -0.241211, -0.929688, 0.318359, -0.929688, -0.449219, -0.609375, -0.726562, 1.40625, 0.235352, 0.435547 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-3.95312 max=3.53125 mean=0.00779488 std=0.980144 sum1e6=6130.14
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_0] shape=[768] showing 24/768: 0.777344, -2.28125, -0.675781, 0.96875, -1.03125, 0.445312, -0.255859, -0.746094, 1.78125, -0.310547, 1.13281, -0.699219, 1.38281, 0.53125, -1.46875, 0.65625, 0.765625, -0.710938, -0.337891, 0.851562, 2.03125, -1.60156, 1.95312, -1.71875 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_64] shape=[768] showing 24/768: 0.558594, -2.14062, -0.582031, 0.925781, -1.08594, 0.488281, 0.0233154, -0.613281, 1.8125, -0.361328, 0.953125, -0.333984, 0.984375, 0.625, -1.45312, 0.519531, 0.490234, -0.722656, -0.451172, 1.03906, 2.0625, -1.3125, 1.85938, -1.66406 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_128] shape=[768] showing 24/768: 0.1875, -1.82031, -0.283203, 0.863281, -1.19531, 0.574219, 0.316406, -0.507812, 1.66406, -0.367188, 0.695312, 0.12207, 0.585938, 0.554688, -1.375, 0.145508, 0.302734, -0.539062, -0.539062, 1.14844, 1.97656, -0.84375, 1.65625, -1.55469 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_192] shape=[768] showing 24/768: -0.25, -1.4375, 0.269531, 0.785156, -1.03125, 0.363281, 0.625, -0.5, 1.49219, -0.353516, 0.241211, 0.71875, 0.196289, 0.310547, -1.21875, -0.398438, 0.0137939, -0.235352, -0.470703, 1.125, 1.63281, -0.251953, 1.36719, -1.14844 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_256] shape=[768] showing 24/768: -0.695312, -0.824219, 0.738281, 0.554688, -0.597656, 0.167969, 0.917969, -0.496094, 1.21875, -0.255859, -0.241211, 1.08594, -0.257812, 0.183594, -0.894531, -1.07031, -0.0795898, 0.128906, -0.233398, 1.10156, 1.21875, 0.369141, 0.792969, -0.734375 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_320] shape=[768] showing 24/768: -1.25781, -0.253906, 1.09375, 0.207031, 0.0125732, -0.147461, 1.27344, -0.398438, 0.90625, -0.0639648, -0.65625, 1.36719, -0.632812, -0.0291748, -0.251953, -1.41406, -0.335938, 0.558594, 0.0888672, 0.992188, 0.675781, 1.32031, 0.105469, -0.300781 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_384] shape=[768] showing 24/768: -1.5625, 0.333984, 1.30469, -0.0446777, 0.546875, -0.335938, 1.375, -0.292969, 0.734375, 0.121094, -0.90625, 1.48438, -1.04688, 0.0668945, 0.279297, -1.58594, -0.421875, 0.785156, 0.310547, 0.71875, 0.296875, 2.03125, -0.386719, 0.0368652 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_448] shape=[768] showing 24/768: -1.74219, 0.691406, 1.26562, -0.225586, 0.976562, -0.519531, 1.42969, -0.128906, 0.4375, 0.361328, -1.01562, 1.4375, -1.39062, 0.140625, 0.683594, -1.63281, -0.365234, 0.78125, 0.443359, 0.466797, 0.0668945, 2.4375, -0.765625, 0.322266 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_512] shape=[768] showing 24/768: 0.757812, -2.32812, -0.730469, 0.960938, -1.03906, 0.498047, -0.239258, -0.742188, 1.75, -0.363281, 1.17188, -0.695312, 1.41406, 0.570312, -1.55469, 0.660156, 0.734375, -0.746094, -0.419922, 0.886719, 2.03125, -1.66406, 1.99219, -1.74219 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_576] shape=[768] showing 24/768: 0.492188, -2.14062, -0.613281, 0.910156, -1.14062, 0.462891, -0.0290527, -0.71875, 1.79688, -0.412109, 0.933594, -0.345703, 1.03125, 0.59375, -1.5, 0.5, 0.507812, -0.753906, -0.482422, 0.964844, 2.04688, -1.35938, 1.91406, -1.65625 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_640] shape=[768] showing 24/768: 0.111328, -1.86719, -0.306641, 0.8125, -1.10938, 0.382812, 0.322266, -0.490234, 1.71094, -0.375, 0.707031, 0.142578, 0.644531, 0.515625, -1.48438, 0.192383, 0.24707, -0.652344, -0.482422, 1.07031, 1.99219, -0.824219, 1.67188, -1.49219 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_704] shape=[768] showing 24/768: -0.349609, -1.47656, 0.160156, 0.671875, -1, 0.332031, 0.667969, -0.46875, 1.49219, -0.332031, 0.296875, 0.683594, 0.267578, 0.320312, -1.29688, -0.324219, 0.0593262, -0.359375, -0.480469, 1.16406, 1.67188, -0.233398, 1.36719, -1.16406 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_768] shape=[768] showing 24/768: -0.792969, -0.800781, 0.8125, 0.474609, -0.515625, 0.224609, 0.996094, -0.394531, 1.125, -0.285156, -0.217773, 1.19531, -0.168945, 0.180664, -0.890625, -0.945312, -0.120117, 0.138672, -0.419922, 1.17188, 1.15625, 0.511719, 0.757812, -0.664062 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_832] shape=[768] showing 24/768: -1.22656, -0.176758, 1.09375, 0.141602, 0.00361633, -0.0869141, 1.19531, -0.369141, 0.839844, -0.175781, -0.683594, 1.46094, -0.699219, -0.0195312, -0.283203, -1.42188, -0.365234, 0.464844, -0.0605469, 1.07031, 0.742188, 1.22656, 0.117676, -0.330078 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_896] shape=[768] showing 24/768: -1.46094, 0.322266, 1.28125, -0.0668945, 0.527344, -0.378906, 1.375, -0.238281, 0.667969, 0.143555, -0.863281, 1.52344, -1.14062, 0.0600586, 0.271484, -1.625, -0.378906, 0.75, 0.308594, 0.769531, 0.363281, 1.99219, -0.380859, -0.0336914 ...
[VT][vision_model.encoder.layers.1.self_attn.k_proj[NLH]/item_960] shape=[768] showing 24/768: -1.67188, 0.71875, 1.26562, -0.163086, 0.964844, -0.527344, 1.39844, -0.120117, 0.46875, 0.351562, -1.01562, 1.52344, -1.39062, 0.171875, 0.695312, -1.65625, -0.435547, 0.792969, 0.427734, 0.46875, -0.010376, 2.40625, -0.796875, 0.298828 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-3.875 max=4.40625 mean=-8.44865e-07 std=0.999998 sum1e6=-0.664429
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.792969, -0.245117, 0.0213623, 0.925781, 0.464844, -0.0688477, -0.314453, -0.234375, 0.416016, 1.21094, 0.46875, -0.878906, -1.17188, -1.03125, -0.613281, -0.820312, 1.72656, -1.03125, -0.703125, 0.0249023, 1.82031, 0.402344, 0.828125, 0.929688 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.652344, -0.357422, 0.110352, 0.753906, 0.5, 0.0864258, -0.419922, -0.298828, 0.566406, 0.78125, 0.129883, -0.5625, -1.27344, -0.929688, -0.609375, -1.03125, 1.57812, -1.08594, -0.761719, -0.104492, 1.73438, 0.738281, 0.71875, 1.13281 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.400391, -0.451172, 0.263672, 0.421875, 0.410156, 0.292969, -0.492188, -0.367188, 0.582031, 0.332031, -0.211914, -0.294922, -1.41406, -0.789062, -0.5, -1.17969, 1.29688, -1.07812, -0.945312, -0.359375, 1.41406, 0.984375, 0.746094, 1.25 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.0678711, -0.441406, 0.535156, -0.291016, 0.578125, 0.582031, -0.65625, -0.539062, 0.439453, -0.328125, -0.570312, 0.0771484, -1.35156, -0.542969, -0.333984, -1.09375, 1.20312, -0.960938, -1.16406, -0.496094, 0.957031, 1.42969, 0.710938, 1.19531 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.431641, -0.439453, 0.925781, -0.832031, 0.636719, 0.875, -0.914062, -0.863281, 0.212891, -0.855469, -0.773438, 0.490234, -1.36719, -0.191406, -0.132812, -1.17188, 1.16406, -0.953125, -1.24219, -0.566406, 0.427734, 1.61719, 0.726562, 0.988281 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.886719, -0.478516, 1.375, -1.16406, 0.484375, 0.84375, -1.08594, -1.08594, 0.0510254, -1.32031, -0.949219, 0.714844, -1.04688, 0.223633, -0.0561523, -1.09375, 1.03906, -0.960938, -1.0625, -0.6875, -0.0791016, 1.60938, 0.707031, 0.820312 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -1.1875, -0.589844, 1.61719, -1.27344, 0.386719, 0.851562, -1.14844, -1.28906, 0.222656, -1.44531, -0.992188, 0.761719, -0.777344, 0.617188, -0.0805664, -1.07812, 0.722656, -1.03125, -0.789062, -0.664062, -0.455078, 1.5, 0.416016, 0.613281 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.40625, -0.609375, 1.67188, -1.32812, 0.176758, 0.800781, -1.125, -1.4375, 0.269531, -1.67188, -1.03906, 0.863281, -0.433594, 0.980469, -0.185547, -0.957031, 0.316406, -0.980469, -0.486328, -0.609375, -0.75, 1.42188, 0.164062, 0.480469 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.792969, -0.239258, 0.0981445, 0.984375, 0.423828, -0.130859, -0.400391, -0.275391, 0.464844, 1.20312, 0.394531, -0.839844, -1.125, -1.00781, -0.527344, -0.847656, 1.75, -1.03906, -0.683594, -0.0114136, 1.82031, 0.394531, 0.769531, 0.945312 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.683594, -0.306641, 0.210938, 0.8125, 0.392578, 0.0272217, -0.503906, -0.253906, 0.554688, 0.863281, 0.108887, -0.566406, -1.30469, -0.917969, -0.601562, -1.03125, 1.55469, -1.03906, -0.78125, -0.148438, 1.77344, 0.667969, 0.707031, 1.16406 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.414062, -0.417969, 0.234375, 0.3125, 0.480469, 0.287109, -0.445312, -0.255859, 0.558594, 0.283203, -0.182617, -0.267578, -1.38281, -0.730469, -0.5, -1.15625, 1.39844, -1.0625, -1.00781, -0.345703, 1.50781, 0.984375, 0.664062, 1.30469 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.0167236, -0.480469, 0.458984, -0.237305, 0.550781, 0.574219, -0.566406, -0.539062, 0.484375, -0.353516, -0.46875, 0.0869141, -1.42188, -0.578125, -0.369141, -1.22656, 1.21875, -1.125, -1.15625, -0.462891, 1.11719, 1.34375, 0.761719, 1.33594 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.539062, -0.40625, 0.964844, -0.75, 0.617188, 0.761719, -0.824219, -0.746094, 0.239258, -0.789062, -0.835938, 0.421875, -1.28125, -0.238281, -0.201172, -1.15625, 1.24219, -0.878906, -1.25, -0.648438, 0.386719, 1.47656, 0.808594, 0.964844 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.839844, -0.464844, 1.4375, -1.11719, 0.527344, 0.863281, -0.988281, -1.03906, 0.149414, -1.23438, -1.04688, 0.730469, -1.125, 0.158203, -0.138672, -1.07031, 1.02344, -0.871094, -0.953125, -0.621094, -0.169922, 1.625, 0.632812, 0.796875 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -1.13281, -0.585938, 1.65625, -1.3125, 0.353516, 0.910156, -1.08594, -1.35156, 0.147461, -1.51562, -0.980469, 0.828125, -0.730469, 0.648438, -0.191406, -1.03906, 0.707031, -0.9375, -0.734375, -0.679688, -0.550781, 1.42969, 0.412109, 0.519531 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.4375, -0.601562, 1.71094, -1.28125, 0.132812, 0.851562, -1.10938, -1.45312, 0.257812, -1.69531, -1.02344, 0.871094, -0.488281, 1.03906, -0.241211, -0.929688, 0.318359, -0.929688, -0.449219, -0.609375, -0.726562, 1.40625, 0.235352, 0.435547 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.84375 max=4.09375 mean=0.0120992 std=0.986229 sum1e6=9515.18
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_0] shape=[768] showing 24/768: -0.652344, 0.8125, -0.0678711, -0.124023, -0.447266, -0.726562, 1.97656, 2.01562, -0.621094, 1.4375, -0.964844, 1.21094, -0.163086, -1.0625, -0.769531, 0.78125, -0.267578, -1.46875, 0.0213623, -0.00331116, 0.441406, -1.22656, -1.32812, 1.71875 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_64] shape=[768] showing 24/768: -1.125, 0.882812, 0.189453, -0.132812, -0.359375, -0.367188, 1.94531, 2.125, -0.496094, 1.34375, -1.0625, 1.26562, -0.402344, -0.949219, -0.839844, 0.742188, -0.197266, -1.32031, 0.180664, 0.0388184, 0.417969, -1.36719, -1.05469, 1.75781 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_128] shape=[768] showing 24/768: -1.60938, 0.96875, 0.4375, -0.135742, -0.273438, 0.0196533, 1.78125, 2.07812, -0.212891, 1.14844, -1.08594, 1.28906, -0.486328, -0.871094, -0.488281, 0.5625, -0.176758, -1.0625, 0.453125, 0.0683594, 0.421875, -1.53906, -0.664062, 1.83594 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_192] shape=[768] showing 24/768: -2.04688, 0.941406, 0.625, -0.0717773, -0.112793, 0.675781, 1.59375, 1.92188, 0.0756836, 0.929688, -0.816406, 1.15625, -0.542969, -0.574219, 0.107422, 0.558594, 0.0966797, -0.808594, 0.789062, 0.267578, 0.394531, -1.77344, -0.361328, 1.52344 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_256] shape=[768] showing 24/768: -2.28125, 0.851562, 0.498047, -0.0149536, -0.0996094, 1.22656, 1.17969, 1.53125, 0.170898, 0.742188, -0.535156, 0.957031, -0.660156, -0.394531, 0.617188, 0.582031, 0.359375, -0.494141, 1.16406, 0.376953, 0.271484, -2.125, -0.0114136, 1.14844 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_320] shape=[768] showing 24/768: -2.35938, 0.609375, 0.320312, -0.0668945, 0.126953, 1.65625, 0.765625, 1.0625, 0.152344, 0.378906, -0.388672, 0.667969, -0.605469, -0.320312, 1.0625, 0.515625, 0.470703, -0.105469, 1.14844, 0.470703, 0.228516, -2.23438, 0.232422, 0.777344 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_384] shape=[768] showing 24/768: -2.32812, 0.292969, 0.233398, -0.151367, 0.285156, 1.91406, 0.151367, 0.621094, 0.0101318, 0.0189209, -0.394531, 0.353516, -0.710938, -0.239258, 1.24219, 0.480469, 0.462891, 0.150391, 1.07812, 0.414062, 0.136719, -2.1875, 0.511719, 0.494141 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_448] shape=[768] showing 24/768: -2.09375, 0.0397949, 0.232422, -0.244141, 0.439453, 2.09375, -0.160156, 0.357422, 0.00518799, -0.205078, -0.458984, 0.0717773, -0.796875, -0.150391, 1.125, 0.523438, 0.460938, 0.472656, 0.898438, 0.335938, 0.227539, -1.98438, 0.722656, 0.328125 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_512] shape=[768] showing 24/768: -0.726562, 0.8125, -0.125977, -0.124512, -0.433594, -0.761719, 2, 2.04688, -0.558594, 1.46875, -0.976562, 1.19531, -0.160156, -1.00781, -0.832031, 0.726562, -0.277344, -1.47656, -0.00787354, -0.0301514, 0.414062, -1.25781, -1.33594, 1.74219 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_576] shape=[768] showing 24/768: -1.15625, 0.914062, 0.0966797, -0.131836, -0.351562, -0.378906, 1.94531, 2.15625, -0.443359, 1.34375, -1.07812, 1.30469, -0.355469, -0.957031, -0.796875, 0.695312, -0.232422, -1.30469, 0.154297, -0.0534668, 0.46875, -1.34375, -1.04688, 1.79688 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_640] shape=[768] showing 24/768: -1.57031, 1.00781, 0.472656, -0.150391, -0.330078, 0.132812, 1.82031, 2.0625, -0.277344, 1.25, -1.02344, 1.30469, -0.605469, -0.820312, -0.503906, 0.609375, -0.120117, -1.125, 0.423828, 0.0415039, 0.417969, -1.46875, -0.703125, 1.72656 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_704] shape=[768] showing 24/768: -1.98438, 1.02344, 0.621094, -0.0703125, -0.208008, 0.597656, 1.60938, 1.84375, -0.0456543, 0.945312, -0.890625, 1.19531, -0.675781, -0.632812, 0.0098877, 0.632812, 0.0439453, -0.863281, 0.699219, 0.158203, 0.304688, -1.82031, -0.390625, 1.53906 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_768] shape=[768] showing 24/768: -2.3125, 0.839844, 0.498047, -0.124023, -0.0454102, 1.23438, 1.17188, 1.48438, 0.0864258, 0.601562, -0.570312, 0.867188, -0.683594, -0.511719, 0.683594, 0.515625, 0.292969, -0.527344, 1.04688, 0.369141, 0.267578, -2.10938, -0.0830078, 1.05469 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_832] shape=[768] showing 24/768: -2.40625, 0.527344, 0.296875, -0.115723, 0.109375, 1.70312, 0.671875, 1.14844, 0.208008, 0.353516, -0.511719, 0.640625, -0.664062, -0.3125, 1.02344, 0.535156, 0.480469, -0.225586, 1.1875, 0.4375, 0.206055, -2.25, 0.337891, 0.757812 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_896] shape=[768] showing 24/768: -2.4375, 0.322266, 0.259766, -0.131836, 0.341797, 1.92188, 0.158203, 0.722656, 0.154297, 0.0869141, -0.523438, 0.322266, -0.660156, -0.269531, 1.16406, 0.574219, 0.523438, 0.168945, 1.09375, 0.431641, 0.229492, -2.14062, 0.554688, 0.503906 ...
[VT][vision_model.encoder.layers.1.self_attn.v_proj[NLH]/item_960] shape=[768] showing 24/768: -2.17188, 0.105957, 0.245117, -0.265625, 0.441406, 2.14062, -0.164062, 0.371094, 0.0422363, -0.203125, -0.472656, 0.0854492, -0.785156, -0.128906, 1.17188, 0.464844, 0.488281, 0.427734, 0.847656, 0.371094, 0.230469, -1.95312, 0.722656, 0.339844 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-2.03125 max=2.48438 mean=0.0121071 std=0.47261 sum1e6=9521.41
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.00842285, 0.300781, -0.0213623, 0.291016, 0.296875, 0.0664062, 0.8125, 0.550781, -0.117676, 0.0336914, -0.410156, 0.0629883, -0.431641, -0.0947266, -0.490234, 0.193359, -0.314453, 0.161133, 0.451172, 0.0600586, -0.373047, -0.484375, -0.114746, -0.261719 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_64] shape=[768] showing 24/768: -0.00205994, 0.213867, 0.00921631, 0.245117, 0.245117, 0.154297, 0.597656, 0.404297, -0.0834961, -0.045166, -0.273438, 0.0527344, -0.494141, -0.0390625, -0.435547, 0.0981445, -0.25, 0.12793, 0.355469, 0.0161133, -0.318359, -0.5, -0.0522461, -0.269531 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_128] shape=[768] showing 24/768: -0.0634766, 0.103027, 0.0668945, 0.144531, 0.160156, 0.324219, 0.302734, 0.21582, -0.0332031, -0.15332, -0.0844727, 0.0500488, -0.578125, 0.0488281, -0.316406, -0.0140381, -0.150391, 0.0761719, 0.232422, -0.0314941, -0.205078, -0.542969, 0.0184326, -0.25 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_192] shape=[768] showing 24/768: -0.124512, -0.0224609, 0.152344, 0.0446777, 0.0712891, 0.496094, -0.0302734, -0.0170898, -0.00439453, -0.296875, 0.118652, 0.0240479, -0.679688, 0.158203, -0.177734, -0.136719, -0.0515137, 0.0244141, 0.109375, -0.0825195, -0.0869141, -0.578125, 0.121582, -0.240234 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.209961, -0.0976562, 0.227539, -0.0267334, 0.000675201, 0.625, -0.245117, -0.162109, 0.00531006, -0.386719, 0.244141, 0.0146484, -0.75, 0.225586, -0.0524902, -0.210938, 0.0211182, -0.0220947, 0.0397949, -0.111328, 0.00439453, -0.621094, 0.195312, -0.205078 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.233398, -0.143555, 0.273438, -0.041748, -0.0578613, 0.648438, -0.359375, -0.239258, 0.00479126, -0.416016, 0.314453, 0.0383301, -0.800781, 0.236328, -0.0308838, -0.300781, 0.0617676, -0.0893555, -0.0422363, -0.147461, 0.0664062, -0.625, 0.21875, -0.15918 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -0.19043, -0.172852, 0.291016, -0.0422363, -0.0844727, 0.632812, -0.404297, -0.269531, 0.0145264, -0.425781, 0.345703, 0.0454102, -0.804688, 0.239258, -0.0427246, -0.339844, 0.0712891, -0.119141, -0.0986328, -0.169922, 0.0869141, -0.589844, 0.202148, -0.15625 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -0.0708008, -0.240234, 0.314453, -0.0280762, -0.113281, 0.582031, -0.511719, -0.359375, 0.0222168, -0.472656, 0.408203, 0.026123, -0.824219, 0.259766, -0.0805664, -0.419922, 0.0771484, -0.149414, -0.202148, -0.220703, 0.102051, -0.5, 0.201172, -0.196289 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_512] shape=[768] showing 24/768: -0.00741577, 0.302734, -0.0197754, 0.291016, 0.292969, 0.0712891, 0.808594, 0.546875, -0.124512, 0.0358887, -0.408203, 0.0703125, -0.441406, -0.0996094, -0.490234, 0.18457, -0.310547, 0.152344, 0.447266, 0.057373, -0.371094, -0.498047, -0.106445, -0.249023 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.00488281, 0.220703, 0.0038147, 0.241211, 0.255859, 0.158203, 0.621094, 0.419922, -0.078125, -0.043457, -0.285156, 0.0444336, -0.480469, -0.034668, -0.429688, 0.123535, -0.257812, 0.144531, 0.375, 0.0273438, -0.322266, -0.496094, -0.0644531, -0.28125 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_640] shape=[768] showing 24/768: -0.0522461, 0.129883, 0.0551758, 0.172852, 0.164062, 0.269531, 0.375, 0.269531, -0.043457, -0.111328, -0.126953, 0.0727539, -0.558594, 0.0130615, -0.361328, -0.00650024, -0.167969, 0.0625, 0.240234, -0.0285645, -0.226562, -0.535156, -0.0101318, -0.228516 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_704] shape=[768] showing 24/768: -0.144531, 0.015564, 0.132812, 0.0703125, 0.078125, 0.458984, 0.0544434, 0.0517578, -0.0144043, -0.243164, 0.0727539, 0.0581055, -0.664062, 0.113281, -0.214844, -0.124512, -0.0644531, 0.00921631, 0.12793, -0.0737305, -0.105957, -0.597656, 0.097168, -0.204102 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.240234, -0.0771484, 0.21875, -0.0103149, -0.0109253, 0.605469, -0.210938, -0.131836, -0.00610352, -0.347656, 0.230469, 0.0568848, -0.761719, 0.189453, -0.0888672, -0.240234, 0.0234375, -0.0588379, 0.0275879, -0.115723, 0.0114136, -0.648438, 0.185547, -0.15625 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.228516, -0.145508, 0.269531, -0.0351562, -0.0612793, 0.640625, -0.363281, -0.245117, 0.000444412, -0.410156, 0.318359, 0.0473633, -0.808594, 0.228516, -0.0510254, -0.322266, 0.0622559, -0.101074, -0.0563965, -0.154297, 0.0693359, -0.628906, 0.219727, -0.15332 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -0.148438, -0.203125, 0.298828, -0.0339355, -0.0966797, 0.613281, -0.460938, -0.320312, 0.0107422, -0.447266, 0.376953, 0.0395508, -0.828125, 0.24707, -0.0664062, -0.390625, 0.0761719, -0.137695, -0.146484, -0.194336, 0.0976562, -0.5625, 0.214844, -0.169922 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -0.0397949, -0.257812, 0.324219, -0.0175781, -0.125, 0.5625, -0.539062, -0.386719, 0.0166016, -0.478516, 0.423828, 0.0299072, -0.839844, 0.257812, -0.104004, -0.457031, 0.0786133, -0.171875, -0.239258, -0.239258, 0.110352, -0.482422, 0.204102, -0.196289 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-2 max=1.99219 mean=-0.00312211 std=0.474455 sum1e6=-2455.33
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_0] shape=[768] showing 24/768: 0.0673828, 0.365234, 0.265625, 0.0385742, 0.523438, -0.617188, -0.145508, -0.253906, 0.0654297, 0.558594, 0.455078, 0.333984, -0.10791, -0.507812, 0.369141, 0.181641, -0.208008, 0.78125, -0.0732422, 0.0932617, 0.144531, -0.0732422, -0.00215149, -0.208008 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_64] shape=[768] showing 24/768: 0.0251465, 0.359375, 0.231445, -0.0181885, 0.388672, -0.558594, -0.0291748, -0.253906, 0.134766, 0.542969, 0.46875, 0.414062, -0.100586, -0.371094, 0.255859, 0.148438, -0.208984, 0.828125, -0.0722656, 0.113281, 0.0737305, 0.0268555, 0.000197411, -0.148438 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_128] shape=[768] showing 24/768: -0.0344238, 0.359375, 0.197266, -0.0688477, 0.220703, -0.503906, 0.125977, -0.320312, 0.226562, 0.476562, 0.388672, 0.546875, -0.0551758, -0.189453, 0.074707, 0.118652, -0.195312, 0.828125, -0.0854492, 0.202148, -0.0159912, 0.175781, 0.0683594, -0.0344238 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_192] shape=[768] showing 24/768: -0.09375, 0.306641, 0.15625, -0.137695, -0.0356445, -0.373047, 0.318359, -0.359375, 0.369141, 0.388672, 0.300781, 0.625, 0.0356445, 0.0198975, -0.137695, 0.0795898, -0.149414, 0.769531, -0.0610352, 0.257812, -0.148438, 0.376953, 0.19043, 0.0952148 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_256] shape=[768] showing 24/768: -0.111328, 0.304688, 0.147461, -0.157227, -0.24707, -0.291016, 0.482422, -0.371094, 0.507812, 0.294922, 0.236328, 0.558594, 0.0756836, 0.15332, -0.333984, 0.125, -0.0649414, 0.628906, 0.015564, 0.292969, -0.242188, 0.496094, 0.308594, 0.172852 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_320] shape=[768] showing 24/768: -0.0585938, 0.335938, 0.107422, -0.12207, -0.435547, -0.259766, 0.566406, -0.328125, 0.632812, 0.251953, 0.181641, 0.408203, 0.0441895, 0.200195, -0.40625, 0.206055, 0.0361328, 0.410156, 0.125977, 0.226562, -0.333984, 0.546875, 0.375, 0.22168 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_384] shape=[768] showing 24/768: 0.0844727, 0.3125, 0.0854492, -0.0351562, -0.570312, -0.182617, 0.574219, -0.251953, 0.683594, 0.253906, 0.120605, 0.212891, -0.00299072, 0.243164, -0.390625, 0.271484, 0.113281, 0.0683594, 0.298828, 0.0561523, -0.369141, 0.498047, 0.396484, 0.253906 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_448] shape=[768] showing 24/768: 0.203125, 0.263672, 0.100098, 0.00389099, -0.71875, -0.168945, 0.515625, -0.192383, 0.71875, 0.253906, 0.0427246, 0.0800781, -0.0751953, 0.298828, -0.353516, 0.298828, 0.242188, -0.131836, 0.417969, -0.0869141, -0.460938, 0.515625, 0.363281, 0.328125 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_512] shape=[768] showing 24/768: 0.0554199, 0.380859, 0.257812, 0.045166, 0.523438, -0.625, -0.15625, -0.245117, 0.0529785, 0.570312, 0.46875, 0.326172, -0.130859, -0.486328, 0.371094, 0.186523, -0.208984, 0.78125, -0.0898438, 0.0908203, 0.142578, -0.0874023, -0.0035553, -0.214844 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_576] shape=[768] showing 24/768: 0.019043, 0.349609, 0.226562, 0.00165558, 0.408203, -0.578125, -0.041748, -0.265625, 0.11084, 0.550781, 0.447266, 0.416016, -0.108887, -0.367188, 0.271484, 0.154297, -0.227539, 0.796875, -0.0771484, 0.114746, 0.0795898, 0.0152588, 0.0351562, -0.150391 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_640] shape=[768] showing 24/768: -0.0429688, 0.345703, 0.208008, -0.0678711, 0.241211, -0.5, 0.106445, -0.294922, 0.208984, 0.46875, 0.416016, 0.519531, -0.0275879, -0.202148, 0.0893555, 0.126953, -0.188477, 0.796875, -0.0776367, 0.15332, 0.0055542, 0.174805, 0.0825195, -0.0490723 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_704] shape=[768] showing 24/768: -0.12793, 0.326172, 0.175781, -0.165039, 0.0122681, -0.359375, 0.332031, -0.351562, 0.347656, 0.398438, 0.347656, 0.582031, 0.0568848, -0.000530243, -0.147461, 0.0957031, -0.145508, 0.734375, -0.0703125, 0.25, -0.118652, 0.349609, 0.188477, 0.0834961 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_768] shape=[768] showing 24/768: -0.139648, 0.328125, 0.0742188, -0.191406, -0.220703, -0.300781, 0.449219, -0.384766, 0.539062, 0.271484, 0.275391, 0.523438, 0.103516, 0.105957, -0.310547, 0.12793, -0.0478516, 0.667969, -0.0148315, 0.306641, -0.22168, 0.486328, 0.351562, 0.140625 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_832] shape=[768] showing 24/768: -0.048584, 0.328125, 0.0820312, -0.122559, -0.425781, -0.259766, 0.53125, -0.320312, 0.648438, 0.261719, 0.188477, 0.398438, 0.0595703, 0.1875, -0.380859, 0.204102, 0.0351562, 0.447266, 0.126953, 0.246094, -0.337891, 0.558594, 0.376953, 0.203125 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_896] shape=[768] showing 24/768: 0.0810547, 0.308594, 0.0625, -0.0625, -0.589844, -0.18457, 0.539062, -0.230469, 0.699219, 0.263672, 0.129883, 0.216797, -0.00561523, 0.248047, -0.373047, 0.275391, 0.134766, 0.136719, 0.289062, 0.0424805, -0.376953, 0.539062, 0.390625, 0.263672 ...
[VT][vision_model.encoder.layers.1.self_attn.out_proj[NLH]/item_960] shape=[768] showing 24/768: 0.210938, 0.271484, 0.0742188, 0.00878906, -0.695312, -0.152344, 0.515625, -0.200195, 0.746094, 0.251953, 0.0240479, 0.111328, -0.0625, 0.289062, -0.341797, 0.310547, 0.236328, -0.108398, 0.410156, -0.090332, -0.453125, 0.519531, 0.386719, 0.365234 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.5 max=4.1875 mean=-0.0542652 std=0.987479 sum1e6=-42675.9
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_0] shape=[768] showing 24/768: 1.14844, 0.279297, 0.478516, 1.26562, 1.23438, -0.507812, -0.308594, -0.328125, 0.722656, 2.10938, 1.17188, -0.462891, -1.23438, -1.47656, -0.130859, -0.554688, 1.91406, -0.1875, -0.675781, 0.310547, 2.375, 0.566406, 1.11719, 1.02344 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_64] shape=[768] showing 24/768: 0.84375, 0.150391, 0.5, 0.902344, 1.05469, -0.316406, -0.300781, -0.402344, 0.867188, 1.49219, 0.757812, -0.00195312, -1.24219, -1.15625, -0.208984, -0.742188, 1.54688, -0.125, -0.695312, 0.162109, 1.99219, 0.933594, 0.886719, 1.15625 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_128] shape=[768] showing 24/768: 0.464844, 0.0585938, 0.570312, 0.451172, 0.726562, -0.105469, -0.213867, -0.542969, 0.898438, 0.914062, 0.3125, 0.392578, -1.25781, -0.804688, -0.273438, -0.867188, 1.14844, -0.0625, -0.851562, -0.0117188, 1.4375, 1.21875, 0.890625, 1.26562 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_192] shape=[768] showing 24/768: -0.0703125, -0.00585938, 0.722656, -0.316406, 0.570312, 0.236328, -0.189453, -0.757812, 0.851562, 0.177734, -0.128906, 0.78125, -1.09375, -0.386719, -0.353516, -0.824219, 1.02344, -0.0117188, -1.02344, -0.105469, 0.800781, 1.75, 0.917969, 1.25781 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_256] shape=[768] showing 24/768: -0.455078, -0.046875, 1.03125, -0.863281, 0.375, 0.546875, -0.298828, -1.10938, 0.746094, -0.431641, -0.416016, 1.04688, -1.10938, 0.0263672, -0.408203, -0.890625, 1.03125, -0.1875, -1.0625, -0.173828, 0.189453, 2, 1.01562, 1.10938 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_320] shape=[768] showing 24/768: -0.875, -0.101562, 1.39844, -1.20312, 0.0214844, 0.53125, -0.433594, -1.32812, 0.6875, -0.96875, -0.695312, 1.07812, -0.925781, 0.414062, -0.451172, -0.800781, 1.00781, -0.476562, -0.859375, -0.40625, -0.400391, 2.0625, 1.03906, 0.992188 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_384] shape=[768] showing 24/768: -1.11719, -0.296875, 1.66406, -1.32812, -0.212891, 0.632812, -0.589844, -1.55469, 0.878906, -1.20312, -0.886719, 0.945312, -0.800781, 0.828125, -0.496094, -0.820312, 0.804688, -0.976562, -0.507812, -0.628906, -0.84375, 1.96094, 0.78125, 0.835938 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_448] shape=[768] showing 24/768: -1.39062, -0.458984, 1.85938, -1.50781, -0.585938, 0.644531, -0.765625, -1.82031, 0.953125, -1.625, -1.14844, 0.960938, -0.605469, 1.30469, -0.617188, -0.804688, 0.527344, -1.25781, -0.171875, -0.808594, -1.33594, 2, 0.482422, 0.789062 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_512] shape=[768] showing 24/768: 1.13281, 0.300781, 0.554688, 1.34375, 1.1875, -0.585938, -0.417969, -0.367188, 0.765625, 2.10938, 1.10156, -0.431641, -1.21094, -1.42969, -0.03125, -0.578125, 1.94531, -0.195312, -0.667969, 0.265625, 2.375, 0.546875, 1.05469, 1.03125 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_576] shape=[768] showing 24/768: 0.871094, 0.195312, 0.597656, 0.980469, 0.960938, -0.394531, -0.396484, -0.367188, 0.828125, 1.57812, 0.714844, -0.00195312, -1.27344, -1.14062, -0.181641, -0.734375, 1.50781, -0.0976562, -0.714844, 0.120605, 2.03125, 0.851562, 0.910156, 1.1875 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_640] shape=[768] showing 24/768: 0.46875, 0.0761719, 0.550781, 0.347656, 0.816406, -0.107422, -0.188477, -0.412109, 0.859375, 0.859375, 0.367188, 0.390625, -1.20312, -0.765625, -0.255859, -0.835938, 1.25, -0.078125, -0.902344, -0.0488281, 1.54688, 1.21875, 0.828125, 1.30469 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_704] shape=[768] showing 24/768: -0.0576172, -0.0214844, 0.675781, -0.292969, 0.59375, 0.246094, -0.09375, -0.753906, 0.871094, 0.164062, 0.00976562, 0.746094, -1.14062, -0.4375, -0.394531, -0.929688, 1.03906, -0.195312, -1.03125, -0.0820312, 0.976562, 1.64844, 0.960938, 1.375 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_768] shape=[768] showing 24/768: -0.578125, 0.0078125, 0.988281, -0.820312, 0.380859, 0.429688, -0.246094, -1.00781, 0.800781, -0.392578, -0.431641, 0.949219, -1.00781, -0.0620117, -0.445312, -0.863281, 1.11719, -0.078125, -1.09375, -0.232422, 0.172852, 1.85938, 1.125, 1.05469 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_832] shape=[768] showing 24/768: -0.816406, -0.09375, 1.42188, -1.14844, 0.0722656, 0.546875, -0.375, -1.27344, 0.796875, -0.871094, -0.773438, 1.08594, -0.972656, 0.34375, -0.5, -0.777344, 0.996094, -0.349609, -0.75, -0.320312, -0.486328, 2.07812, 0.976562, 0.953125 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_896] shape=[768] showing 24/768: -1.0625, -0.292969, 1.67188, -1.38281, -0.265625, 0.691406, -0.554688, -1.59375, 0.820312, -1.25781, -0.863281, 1.00781, -0.75, 0.867188, -0.585938, -0.773438, 0.8125, -0.8125, -0.460938, -0.652344, -0.945312, 1.92969, 0.773438, 0.753906 ...
[VT][vision_model.encoder.layers.1.layer_norm2/pre[NLH]/item_960] shape=[768] showing 24/768: -1.41406, -0.439453, 1.875, -1.44531, -0.609375, 0.714844, -0.75, -1.84375, 0.96875, -1.64844, -1.14844, 1, -0.652344, 1.35938, -0.664062, -0.757812, 0.523438, -1.17969, -0.136719, -0.808594, -1.29688, 1.98438, 0.585938, 0.78125 ...
[VT][vision_model.encoder.layers.1.layer_norm2] OUT shape=(1, 1024, 768) layout=NLH  min=-4.21875 max=4.34375 mean=2.95353e-06 std=0.999997 sum1e6=2.32275
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_0] shape=[768] showing 24/768: 0.808594, 0.0932617, 0.257812, 0.90625, 0.878906, -0.554688, -0.390625, -0.40625, 0.458984, 1.60156, 0.828125, -0.519531, -1.15625, -1.35156, -0.244141, -0.59375, 1.4375, -0.291016, -0.691406, 0.119141, 1.82031, 0.330078, 0.78125, 0.707031 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_64] shape=[768] showing 24/768: 0.636719, 0.0153198, 0.328125, 0.691406, 0.828125, -0.402344, -0.388672, -0.480469, 0.65625, 1.21875, 0.558594, -0.121094, -1.23438, -1.15625, -0.306641, -0.785156, 1.26562, -0.231445, -0.742188, 0.0258789, 1.66406, 0.71875, 0.675781, 0.917969 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_128] shape=[768] showing 24/768: 0.345703, -0.0444336, 0.447266, 0.332031, 0.597656, -0.202148, -0.306641, -0.621094, 0.761719, 0.777344, 0.199219, 0.275391, -1.3125, -0.875, -0.363281, -0.933594, 1, -0.161133, -0.917969, -0.112305, 1.28125, 1.07031, 0.753906, 1.11719 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_192] shape=[768] showing 24/768: -0.140625, -0.0766602, 0.644531, -0.382812, 0.492188, 0.162109, -0.257812, -0.820312, 0.769531, 0.104492, -0.198242, 0.699219, -1.14844, -0.453125, -0.419922, -0.886719, 0.941406, -0.0825195, -1.07812, -0.174805, 0.71875, 1.65625, 0.835938, 1.17188 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_256] shape=[768] showing 24/768: -0.484375, -0.0839844, 0.972656, -0.886719, 0.330078, 0.498047, -0.332031, -1.125, 0.695312, -0.460938, -0.445312, 0.988281, -1.125, -0.0122681, -0.439453, -0.910156, 0.972656, -0.22168, -1.07812, -0.208984, 0.147461, 1.92188, 0.957031, 1.04688 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_320] shape=[768] showing 24/768: -0.839844, -0.102051, 1.32812, -1.15625, 0.015625, 0.503906, -0.419922, -1.27344, 0.652344, -0.929688, -0.667969, 1.02344, -0.890625, 0.390625, -0.435547, -0.769531, 0.957031, -0.460938, -0.824219, -0.392578, -0.386719, 1.96875, 0.988281, 0.941406 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_384] shape=[768] showing 24/768: -0.996094, -0.249023, 1.53906, -1.1875, -0.171875, 0.597656, -0.515625, -1.39844, 0.824219, -1.07812, -0.785156, 0.882812, -0.707031, 0.777344, -0.429688, -0.726562, 0.753906, -0.867188, -0.441406, -0.550781, -0.746094, 1.80469, 0.734375, 0.785156 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_448] shape=[768] showing 24/768: -1.125, -0.339844, 1.61719, -1.22656, -0.445312, 0.59375, -0.597656, -1.48438, 0.851562, -1.32031, -0.921875, 0.859375, -0.462891, 1.14844, -0.472656, -0.628906, 0.492188, -1.01562, -0.0966797, -0.632812, -1.07812, 1.73438, 0.455078, 0.714844 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_512] shape=[768] showing 24/768: 0.792969, 0.110352, 0.318359, 0.964844, 0.839844, -0.617188, -0.478516, -0.4375, 0.492188, 1.59375, 0.769531, -0.490234, -1.13281, -1.3125, -0.162109, -0.609375, 1.46094, -0.296875, -0.683594, 0.081543, 1.8125, 0.3125, 0.730469, 0.710938 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_576] shape=[768] showing 24/768: 0.660156, 0.0537109, 0.414062, 0.757812, 0.742188, -0.476562, -0.478516, -0.451172, 0.621094, 1.29688, 0.519531, -0.123535, -1.26562, -1.14844, -0.285156, -0.78125, 1.23438, -0.208984, -0.761719, -0.0133667, 1.70312, 0.644531, 0.695312, 0.945312 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_640] shape=[768] showing 24/768: 0.349609, -0.0279541, 0.429688, 0.233398, 0.683594, -0.205078, -0.283203, -0.498047, 0.726562, 0.726562, 0.251953, 0.275391, -1.25781, -0.839844, -0.347656, -0.90625, 1.10156, -0.176758, -0.96875, -0.148438, 1.39062, 1.07031, 0.695312, 1.15625 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_704] shape=[768] showing 24/768: -0.12793, -0.0922852, 0.597656, -0.361328, 0.515625, 0.171875, -0.164062, -0.816406, 0.789062, 0.0908203, -0.0615234, 0.667969, -1.20312, -0.503906, -0.460938, -0.992188, 0.957031, -0.263672, -1.09375, -0.152344, 0.894531, 1.5625, 0.878906, 1.28906 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_768] shape=[768] showing 24/768: -0.605469, -0.0303955, 0.933594, -0.84375, 0.335938, 0.384766, -0.279297, -1.03125, 0.75, -0.423828, -0.462891, 0.894531, -1.03125, -0.0991211, -0.474609, -0.886719, 1.0625, -0.114746, -1.10938, -0.265625, 0.131836, 1.78906, 1.07031, 0.996094 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_832] shape=[768] showing 24/768: -0.789062, -0.0957031, 1.35938, -1.10938, 0.0634766, 0.519531, -0.365234, -1.22656, 0.757812, -0.839844, -0.746094, 1.03906, -0.9375, 0.324219, -0.484375, -0.75, 0.949219, -0.341797, -0.726562, -0.3125, -0.472656, 1.98438, 0.929688, 0.910156 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_896] shape=[768] showing 24/768: -0.949219, -0.246094, 1.54688, -1.24219, -0.22168, 0.652344, -0.486328, -1.4375, 0.769531, -1.125, -0.765625, 0.941406, -0.664062, 0.8125, -0.515625, -0.683594, 0.765625, -0.722656, -0.400391, -0.574219, -0.84375, 1.78906, 0.730469, 0.710938 ...
[VT][vision_model.encoder.layers.1.layer_norm2[NLH]/item_960] shape=[768] showing 24/768: -1.14844, -0.324219, 1.625, -1.17188, -0.466797, 0.648438, -0.585938, -1.50781, 0.863281, -1.34375, -0.921875, 0.890625, -0.503906, 1.19531, -0.515625, -0.59375, 0.488281, -0.949219, -0.0688477, -0.636719, -1.04688, 1.71875, 0.539062, 0.707031 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.21875 max=4.34375 mean=2.95353e-06 std=0.999997 sum1e6=2.32275
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_0] shape=[768] showing 24/768: 0.808594, 0.0932617, 0.257812, 0.90625, 0.878906, -0.554688, -0.390625, -0.40625, 0.458984, 1.60156, 0.828125, -0.519531, -1.15625, -1.35156, -0.244141, -0.59375, 1.4375, -0.291016, -0.691406, 0.119141, 1.82031, 0.330078, 0.78125, 0.707031 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_64] shape=[768] showing 24/768: 0.636719, 0.0153198, 0.328125, 0.691406, 0.828125, -0.402344, -0.388672, -0.480469, 0.65625, 1.21875, 0.558594, -0.121094, -1.23438, -1.15625, -0.306641, -0.785156, 1.26562, -0.231445, -0.742188, 0.0258789, 1.66406, 0.71875, 0.675781, 0.917969 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_128] shape=[768] showing 24/768: 0.345703, -0.0444336, 0.447266, 0.332031, 0.597656, -0.202148, -0.306641, -0.621094, 0.761719, 0.777344, 0.199219, 0.275391, -1.3125, -0.875, -0.363281, -0.933594, 1, -0.161133, -0.917969, -0.112305, 1.28125, 1.07031, 0.753906, 1.11719 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_192] shape=[768] showing 24/768: -0.140625, -0.0766602, 0.644531, -0.382812, 0.492188, 0.162109, -0.257812, -0.820312, 0.769531, 0.104492, -0.198242, 0.699219, -1.14844, -0.453125, -0.419922, -0.886719, 0.941406, -0.0825195, -1.07812, -0.174805, 0.71875, 1.65625, 0.835938, 1.17188 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_256] shape=[768] showing 24/768: -0.484375, -0.0839844, 0.972656, -0.886719, 0.330078, 0.498047, -0.332031, -1.125, 0.695312, -0.460938, -0.445312, 0.988281, -1.125, -0.0122681, -0.439453, -0.910156, 0.972656, -0.22168, -1.07812, -0.208984, 0.147461, 1.92188, 0.957031, 1.04688 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_320] shape=[768] showing 24/768: -0.839844, -0.102051, 1.32812, -1.15625, 0.015625, 0.503906, -0.419922, -1.27344, 0.652344, -0.929688, -0.667969, 1.02344, -0.890625, 0.390625, -0.435547, -0.769531, 0.957031, -0.460938, -0.824219, -0.392578, -0.386719, 1.96875, 0.988281, 0.941406 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_384] shape=[768] showing 24/768: -0.996094, -0.249023, 1.53906, -1.1875, -0.171875, 0.597656, -0.515625, -1.39844, 0.824219, -1.07812, -0.785156, 0.882812, -0.707031, 0.777344, -0.429688, -0.726562, 0.753906, -0.867188, -0.441406, -0.550781, -0.746094, 1.80469, 0.734375, 0.785156 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_448] shape=[768] showing 24/768: -1.125, -0.339844, 1.61719, -1.22656, -0.445312, 0.59375, -0.597656, -1.48438, 0.851562, -1.32031, -0.921875, 0.859375, -0.462891, 1.14844, -0.472656, -0.628906, 0.492188, -1.01562, -0.0966797, -0.632812, -1.07812, 1.73438, 0.455078, 0.714844 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_512] shape=[768] showing 24/768: 0.792969, 0.110352, 0.318359, 0.964844, 0.839844, -0.617188, -0.478516, -0.4375, 0.492188, 1.59375, 0.769531, -0.490234, -1.13281, -1.3125, -0.162109, -0.609375, 1.46094, -0.296875, -0.683594, 0.081543, 1.8125, 0.3125, 0.730469, 0.710938 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_576] shape=[768] showing 24/768: 0.660156, 0.0537109, 0.414062, 0.757812, 0.742188, -0.476562, -0.478516, -0.451172, 0.621094, 1.29688, 0.519531, -0.123535, -1.26562, -1.14844, -0.285156, -0.78125, 1.23438, -0.208984, -0.761719, -0.0133667, 1.70312, 0.644531, 0.695312, 0.945312 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_640] shape=[768] showing 24/768: 0.349609, -0.0279541, 0.429688, 0.233398, 0.683594, -0.205078, -0.283203, -0.498047, 0.726562, 0.726562, 0.251953, 0.275391, -1.25781, -0.839844, -0.347656, -0.90625, 1.10156, -0.176758, -0.96875, -0.148438, 1.39062, 1.07031, 0.695312, 1.15625 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_704] shape=[768] showing 24/768: -0.12793, -0.0922852, 0.597656, -0.361328, 0.515625, 0.171875, -0.164062, -0.816406, 0.789062, 0.0908203, -0.0615234, 0.667969, -1.20312, -0.503906, -0.460938, -0.992188, 0.957031, -0.263672, -1.09375, -0.152344, 0.894531, 1.5625, 0.878906, 1.28906 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_768] shape=[768] showing 24/768: -0.605469, -0.0303955, 0.933594, -0.84375, 0.335938, 0.384766, -0.279297, -1.03125, 0.75, -0.423828, -0.462891, 0.894531, -1.03125, -0.0991211, -0.474609, -0.886719, 1.0625, -0.114746, -1.10938, -0.265625, 0.131836, 1.78906, 1.07031, 0.996094 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_832] shape=[768] showing 24/768: -0.789062, -0.0957031, 1.35938, -1.10938, 0.0634766, 0.519531, -0.365234, -1.22656, 0.757812, -0.839844, -0.746094, 1.03906, -0.9375, 0.324219, -0.484375, -0.75, 0.949219, -0.341797, -0.726562, -0.3125, -0.472656, 1.98438, 0.929688, 0.910156 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_896] shape=[768] showing 24/768: -0.949219, -0.246094, 1.54688, -1.24219, -0.22168, 0.652344, -0.486328, -1.4375, 0.769531, -1.125, -0.765625, 0.941406, -0.664062, 0.8125, -0.515625, -0.683594, 0.765625, -0.722656, -0.400391, -0.574219, -0.84375, 1.78906, 0.730469, 0.710938 ...
[VT][vision_model.encoder.layers.1.mlp.fc1/pre[NLH]/item_960] shape=[768] showing 24/768: -1.14844, -0.324219, 1.625, -1.17188, -0.466797, 0.648438, -0.585938, -1.50781, 0.863281, -1.34375, -0.921875, 0.890625, -0.503906, 1.19531, -0.515625, -0.59375, 0.488281, -0.949219, -0.0688477, -0.636719, -1.04688, 1.71875, 0.539062, 0.707031 ...
[VT][vision_model.encoder.layers.1.mlp.fc1] OUT shape=(1, 1024, 3072) layout=NLH  min=-2.70312 max=2.70312 mean=0.00917345 std=0.630725 sum1e6=7870.92
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_0] shape=[3072] showing 24/3072: -0.396484, 0.488281, -0.257812, 1, 0.380859, -0.582031, -1.04688, -0.314453, -1.54688, -0.0256348, -0.34375, -1.14062, -0.0339355, -0.738281, 1.09375, 0.738281, 1.625, 0.121094, 0.84375, -0.332031, 0.753906, -0.408203, -0.150391, 0.041748 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_64] shape=[3072] showing 24/3072: -0.369141, 0.375, -0.257812, 1.10156, 0.292969, -0.683594, -0.992188, -0.480469, -1.50781, -0.15625, -0.339844, -1.02344, -0.110352, -0.625, 1.03906, 0.675781, 1.53906, 0.231445, 1.0625, -0.332031, 0.835938, -0.400391, -0.318359, 0.0107422 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_128] shape=[3072] showing 24/3072: -0.402344, 0.231445, -0.269531, 1.19531, 0.0600586, -0.832031, -0.855469, -0.734375, -1.40625, -0.239258, -0.457031, -0.800781, -0.199219, -0.535156, 0.988281, 0.523438, 1.3125, 0.353516, 1.27344, -0.294922, 0.90625, -0.408203, -0.503906, -0.0319824 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_192] shape=[3072] showing 24/3072: -0.412109, 0.0864258, -0.236328, 1.30469, -0.251953, -0.917969, -0.671875, -0.882812, -1.16406, -0.227539, -0.574219, -0.388672, -0.300781, -0.443359, 0.828125, 0.357422, 0.914062, 0.478516, 1.41406, -0.291016, 0.925781, -0.240234, -0.699219, 0.0220947 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_256] shape=[3072] showing 24/3072: -0.279297, -0.0157471, -0.180664, 1.33594, -0.582031, -1.09375, -0.511719, -0.890625, -0.855469, -0.3125, -0.535156, 0.0395508, -0.367188, -0.425781, 0.617188, 0.0952148, 0.398438, 0.527344, 1.45312, -0.227539, 0.730469, -0.150391, -0.855469, 0.0109863 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_320] shape=[3072] showing 24/3072: -0.149414, -0.019043, 0.00196838, 1.35938, -0.753906, -1.14844, -0.355469, -0.757812, -0.390625, -0.392578, -0.365234, 0.398438, -0.40625, -0.390625, 0.443359, -0.279297, -0.0878906, 0.482422, 1.50781, -0.12793, 0.408203, -0.0529785, -0.824219, -0.103516 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_384] shape=[3072] showing 24/3072: 0.0466309, -0.0308838, 0.144531, 1.14062, -0.722656, -1.24219, -0.188477, -0.640625, -0.0678711, -0.496094, -0.130859, 0.738281, -0.423828, -0.384766, 0.332031, -0.5625, -0.5, 0.292969, 1.38281, -0.0390625, 0.125, 0.0515137, -0.65625, -0.255859 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_448] shape=[3072] showing 24/3072: 0.183594, -0.0395508, 0.28125, 0.96875, -0.601562, -1.16406, -0.0239258, -0.519531, 0.257812, -0.59375, 0.0869141, 0.988281, -0.46875, -0.223633, 0.229492, -0.707031, -0.773438, 0.169922, 1.25781, -0.0240479, -0.0708008, 0.0566406, -0.482422, -0.396484 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_512] shape=[3072] showing 24/3072: -0.369141, 0.472656, -0.257812, 0.984375, 0.355469, -0.566406, -1.04688, -0.316406, -1.5625, -0.0629883, -0.328125, -1.1875, -0.0578613, -0.726562, 1.07812, 0.738281, 1.61719, 0.135742, 0.835938, -0.388672, 0.769531, -0.388672, -0.165039, 0.0603027 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_576] shape=[3072] showing 24/3072: -0.367188, 0.375, -0.248047, 1.03125, 0.257812, -0.710938, -0.992188, -0.447266, -1.51562, -0.161133, -0.361328, -1.04688, -0.0820312, -0.691406, 1.10938, 0.640625, 1.53125, 0.211914, 1.01562, -0.306641, 0.871094, -0.433594, -0.298828, 0.0134277 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_640] shape=[3072] showing 24/3072: -0.369141, 0.224609, -0.246094, 1.17969, 0.0703125, -0.824219, -0.820312, -0.691406, -1.40625, -0.213867, -0.492188, -0.785156, -0.151367, -0.601562, 1.02344, 0.535156, 1.29688, 0.361328, 1.23438, -0.289062, 0.941406, -0.386719, -0.498047, -0.00595093 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_704] shape=[3072] showing 24/3072: -0.394531, 0.0717773, -0.242188, 1.28906, -0.224609, -0.957031, -0.703125, -0.941406, -1.13281, -0.206055, -0.5, -0.423828, -0.283203, -0.449219, 0.828125, 0.339844, 0.910156, 0.464844, 1.38281, -0.251953, 0.914062, -0.337891, -0.730469, -0.00104523 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_768] shape=[3072] showing 24/3072: -0.333984, -0.0164795, -0.116699, 1.40625, -0.570312, -1.07812, -0.453125, -0.828125, -0.820312, -0.25, -0.458984, -0.0300293, -0.345703, -0.367188, 0.617188, 0.060791, 0.408203, 0.558594, 1.41406, -0.205078, 0.734375, -0.111328, -0.820312, 0.0742188 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_832] shape=[3072] showing 24/3072: -0.167969, -0.0527344, -0.000189781, 1.33594, -0.691406, -1.1875, -0.298828, -0.746094, -0.490234, -0.373047, -0.345703, 0.410156, -0.431641, -0.357422, 0.482422, -0.227539, -0.101074, 0.443359, 1.4375, -0.142578, 0.439453, -0.0200195, -0.800781, -0.0380859 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_896] shape=[3072] showing 24/3072: 0.0354004, -0.0830078, 0.158203, 1.21094, -0.71875, -1.21094, -0.186523, -0.652344, -0.0932617, -0.498047, -0.125977, 0.726562, -0.433594, -0.306641, 0.361328, -0.507812, -0.535156, 0.298828, 1.42188, -0.0756836, 0.115723, 0.00184631, -0.617188, -0.244141 ...
[VT][vision_model.encoder.layers.1.mlp.fc1[NLH]/item_960] shape=[3072] showing 24/3072: 0.164062, -0.0766602, 0.283203, 0.984375, -0.636719, -1.11719, -0.0291748, -0.523438, 0.25, -0.621094, 0.060791, 0.949219, -0.470703, -0.209961, 0.237305, -0.710938, -0.792969, 0.185547, 1.22656, -0.00473022, -0.0480957, 0.0524902, -0.453125, -0.390625 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre] IN  shape=(1, 1024, 3072) layout=NLH  min=-0.169922 max=2.6875 mean=0.13901 std=0.358787 sum1e6=137797
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_0] shape=[3072] showing 24/3072: -0.136719, 0.335938, -0.102539, 0.839844, 0.24707, -0.163086, -0.154297, -0.118652, -0.0942383, -0.0125732, -0.125977, -0.145508, -0.0164795, -0.169922, 0.945312, 0.566406, 1.53906, 0.0664062, 0.675781, -0.123047, 0.582031, -0.139648, -0.0664062, 0.0216064 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_64] shape=[3072] showing 24/3072: -0.131836, 0.242188, -0.102539, 0.953125, 0.180664, -0.168945, -0.15918, -0.151367, -0.0996094, -0.0683594, -0.124512, -0.157227, -0.050293, -0.166016, 0.882812, 0.507812, 1.44531, 0.136719, 0.910156, -0.123047, 0.667969, -0.137695, -0.119629, 0.00543213 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_128] shape=[3072] showing 24/3072: -0.138672, 0.136719, -0.105957, 1.05469, 0.0314941, -0.168945, -0.167969, -0.169922, -0.112305, -0.097168, -0.148438, -0.169922, -0.0839844, -0.158203, 0.828125, 0.365234, 1.1875, 0.225586, 1.14062, -0.113281, 0.742188, -0.139648, -0.155273, -0.015564 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_192] shape=[3072] showing 24/3072: -0.140625, 0.0461426, -0.0961914, 1.17969, -0.101074, -0.165039, -0.168945, -0.166992, -0.142578, -0.0932617, -0.162109, -0.135742, -0.114746, -0.145508, 0.660156, 0.228516, 0.75, 0.328125, 1.30469, -0.112305, 0.761719, -0.097168, -0.168945, 0.0112305 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_256] shape=[3072] showing 24/3072: -0.108887, -0.00778198, -0.0771484, 1.21094, -0.163086, -0.150391, -0.15625, -0.166016, -0.167969, -0.117676, -0.158203, 0.0203857, -0.130859, -0.142578, 0.451172, 0.0512695, 0.261719, 0.369141, 1.34375, -0.0932617, 0.558594, -0.0664062, -0.167969, 0.0055542 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_320] shape=[3072] showing 24/3072: -0.065918, -0.00939941, 0.000984192, 1.24219, -0.169922, -0.144531, -0.12793, -0.169922, -0.135742, -0.136719, -0.130859, 0.261719, -0.138672, -0.135742, 0.296875, -0.108887, -0.0407715, 0.330078, 1.40625, -0.057373, 0.269531, -0.0253906, -0.168945, -0.0476074 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_384] shape=[3072] showing 24/3072: 0.0241699, -0.0150757, 0.0805664, 0.996094, -0.169922, -0.132812, -0.0800781, -0.166992, -0.0319824, -0.15332, -0.0585938, 0.566406, -0.142578, -0.134766, 0.208984, -0.161133, -0.154297, 0.180664, 1.26562, -0.0189209, 0.0688477, 0.0268555, -0.167969, -0.102051 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_448] shape=[3072] showing 24/3072: 0.10498, -0.019165, 0.171875, 0.808594, -0.165039, -0.142578, -0.0117188, -0.157227, 0.155273, -0.164062, 0.0463867, 0.828125, -0.149414, -0.0917969, 0.135742, -0.169922, -0.169922, 0.0961914, 1.125, -0.0117798, -0.0334473, 0.029541, -0.152344, -0.136719 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_512] shape=[3072] showing 24/3072: -0.131836, 0.322266, -0.102539, 0.824219, 0.227539, -0.162109, -0.154297, -0.119141, -0.0922852, -0.0299072, -0.12207, -0.139648, -0.0275879, -0.169922, 0.925781, 0.566406, 1.53125, 0.0751953, 0.667969, -0.135742, 0.597656, -0.135742, -0.0717773, 0.0314941 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_576] shape=[3072] showing 24/3072: -0.130859, 0.242188, -0.0996094, 0.875, 0.155273, -0.169922, -0.15918, -0.146484, -0.0986328, -0.0703125, -0.129883, -0.154297, -0.0383301, -0.168945, 0.960938, 0.472656, 1.4375, 0.123535, 0.859375, -0.116211, 0.703125, -0.144531, -0.114258, 0.0067749 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_640] shape=[3072] showing 24/3072: -0.131836, 0.131836, -0.0991211, 1.03906, 0.0371094, -0.168945, -0.168945, -0.168945, -0.112305, -0.0888672, -0.15332, -0.169922, -0.0664062, -0.165039, 0.867188, 0.376953, 1.17188, 0.231445, 1.10156, -0.111816, 0.777344, -0.134766, -0.154297, -0.00296021 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_704] shape=[3072] showing 24/3072: -0.136719, 0.0378418, -0.0981445, 1.16406, -0.0922852, -0.162109, -0.169922, -0.163086, -0.145508, -0.0864258, -0.154297, -0.142578, -0.109863, -0.146484, 0.660156, 0.214844, 0.746094, 0.316406, 1.26562, -0.101074, 0.75, -0.124023, -0.169922, -0.000522614 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_768] shape=[3072] showing 24/3072: -0.123535, -0.00811768, -0.0529785, 1.29688, -0.162109, -0.151367, -0.147461, -0.168945, -0.168945, -0.100098, -0.148438, -0.0146484, -0.125977, -0.130859, 0.451172, 0.0319824, 0.269531, 0.398438, 1.30469, -0.0859375, 0.5625, -0.0507812, -0.168945, 0.0393066 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_832] shape=[3072] showing 24/3072: -0.0727539, -0.0252686, -9.48906e-05, 1.21094, -0.168945, -0.139648, -0.114258, -0.169922, -0.15332, -0.131836, -0.125977, 0.269531, -0.143555, -0.128906, 0.330078, -0.0932617, -0.0463867, 0.296875, 1.32812, -0.0629883, 0.294922, -0.00982666, -0.169922, -0.0184326 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_896] shape=[3072] showing 24/3072: 0.0181885, -0.0388184, 0.0888672, 1.07031, -0.169922, -0.136719, -0.0795898, -0.167969, -0.0432129, -0.154297, -0.0566406, 0.558594, -0.144531, -0.116211, 0.231445, -0.155273, -0.158203, 0.18457, 1.3125, -0.0356445, 0.0629883, 0.000923157, -0.166016, -0.0986328 ...
[VT][vision_model.encoder.layers.1.mlp.fc2/pre[NLH]/item_960] shape=[3072] showing 24/3072: 0.0927734, -0.0358887, 0.172852, 0.824219, -0.166992, -0.147461, -0.0142212, -0.157227, 0.149414, -0.166016, 0.0319824, 0.785156, -0.150391, -0.0874023, 0.140625, -0.169922, -0.169922, 0.106445, 1.09375, -0.00234985, -0.0230713, 0.0273438, -0.147461, -0.135742 ...
[VT][vision_model.encoder.layers.1.mlp.fc2] OUT shape=(1, 1024, 768) layout=NLH  min=-2.34375 max=1.82812 mean=-0.0746649 std=0.483509 sum1e6=-58718.9
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_0] shape=[768] showing 24/768: 0.09375, -0.204102, 0.0996094, 0.423828, -0.123535, -0.820312, 0.0673828, -0.0223389, 0.347656, 0.10498, -0.341797, 0.0240479, -0.789062, -0.136719, 0.226562, 0.6875, -0.486328, 0.207031, 0.191406, 0.213867, -0.245117, -0.160156, 0.402344, 0.101074 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_64] shape=[768] showing 24/768: 0.125977, -0.292969, -0.0578613, 0.478516, -0.213867, -0.886719, -0.0162354, -0.0917969, 0.292969, 0.351562, -0.219727, -0.0159912, -0.761719, -0.0717773, 0.294922, 0.824219, -0.683594, 0.203125, 0.112793, 0.158203, -0.0246582, -0.141602, 0.314453, 0.174805 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_128] shape=[768] showing 24/768: 0.183594, -0.414062, -0.249023, 0.523438, -0.431641, -0.890625, -0.0368652, -0.0942383, 0.341797, 0.628906, 0.0109253, -0.132812, -0.691406, 0.102539, 0.357422, 0.933594, -0.9375, 0.172852, -0.0192871, 0.180664, 0.25, -0.0874023, 0.132812, 0.298828 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_192] shape=[768] showing 24/768: 0.209961, -0.488281, -0.445312, 0.535156, -0.617188, -0.652344, 0.106445, -0.0269775, 0.353516, 0.878906, 0.269531, -0.207031, -0.597656, 0.249023, 0.328125, 0.925781, -1.13281, 0.0966797, -0.237305, 0.263672, 0.515625, -0.0512695, -0.137695, 0.314453 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_256] shape=[768] showing 24/768: 0.106445, -0.53125, -0.609375, 0.400391, -0.660156, -0.292969, 0.369141, -0.00576782, 0.339844, 0.957031, 0.535156, -0.367188, -0.558594, 0.324219, 0.267578, 0.839844, -1.10156, -0.0251465, -0.330078, 0.404297, 0.625, -0.0241699, -0.314453, 0.263672 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_320] shape=[768] showing 24/768: -0.0250244, -0.59375, -0.628906, 0.195312, -0.640625, -0.0917969, 0.519531, -0.000965118, 0.207031, 0.855469, 0.71875, -0.542969, -0.449219, 0.287109, 0.265625, 0.808594, -0.980469, -0.18457, -0.273438, 0.484375, 0.703125, -0.114746, -0.449219, 0.103027 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_384] shape=[768] showing 24/768: -0.136719, -0.498047, -0.695312, -0.0654297, -0.628906, 0.00927734, 0.644531, 0.0375977, -0.00622559, 0.6875, 0.867188, -0.625, -0.365234, 0.242188, 0.318359, 0.808594, -0.84375, -0.259766, -0.219727, 0.488281, 0.828125, -0.189453, -0.464844, -0.0805664 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_448] shape=[768] showing 24/768: -0.201172, -0.382812, -0.742188, -0.208984, -0.707031, 0.0507812, 0.675781, 0.116699, -0.269531, 0.554688, 1.00781, -0.679688, -0.308594, 0.257812, 0.361328, 0.785156, -0.695312, -0.291016, -0.208984, 0.435547, 0.898438, -0.259766, -0.386719, -0.318359 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_512] shape=[768] showing 24/768: 0.100098, -0.220703, 0.101074, 0.408203, -0.138672, -0.832031, 0.0532227, -0.017334, 0.333984, 0.111328, -0.355469, 0.0302734, -0.808594, -0.133789, 0.191406, 0.679688, -0.474609, 0.237305, 0.208984, 0.1875, -0.259766, -0.155273, 0.416016, 0.0786133 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_576] shape=[768] showing 24/768: 0.137695, -0.314453, -0.0668945, 0.478516, -0.239258, -0.871094, -0.0395508, -0.107422, 0.308594, 0.318359, -0.207031, -0.0615234, -0.761719, -0.0576172, 0.302734, 0.808594, -0.683594, 0.240234, 0.0766602, 0.162109, -0.0371094, -0.163086, 0.289062, 0.176758 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_640] shape=[768] showing 24/768: 0.144531, -0.402344, -0.228516, 0.566406, -0.402344, -0.847656, -0.0218506, -0.111328, 0.300781, 0.59375, 0.0055542, -0.128906, -0.640625, 0.0727539, 0.351562, 0.90625, -0.945312, 0.217773, -0.0673828, 0.175781, 0.228516, -0.133789, 0.0878906, 0.259766 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_704] shape=[768] showing 24/768: 0.162109, -0.46875, -0.441406, 0.558594, -0.625, -0.65625, 0.0961914, -0.0581055, 0.300781, 0.878906, 0.244141, -0.236328, -0.574219, 0.213867, 0.320312, 0.902344, -1.11719, 0.119141, -0.237305, 0.28125, 0.507812, -0.0947266, -0.136719, 0.298828 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_768] shape=[768] showing 24/768: 0.12207, -0.546875, -0.566406, 0.423828, -0.664062, -0.392578, 0.322266, 0.00482178, 0.330078, 0.914062, 0.445312, -0.394531, -0.527344, 0.341797, 0.257812, 0.863281, -1.14844, -0.000170708, -0.277344, 0.425781, 0.640625, -0.0766602, -0.332031, 0.253906 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_832] shape=[768] showing 24/768: -0.00314331, -0.542969, -0.648438, 0.208984, -0.609375, -0.11377, 0.558594, 0.0397949, 0.155273, 0.90625, 0.738281, -0.519531, -0.447266, 0.304688, 0.261719, 0.792969, -0.980469, -0.166016, -0.267578, 0.523438, 0.730469, -0.0913086, -0.457031, 0.0864258 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_896] shape=[768] showing 24/768: -0.0961914, -0.474609, -0.710938, -0.0883789, -0.628906, 0.0289307, 0.65625, 0.0786133, -0.0310059, 0.730469, 0.871094, -0.648438, -0.361328, 0.296875, 0.294922, 0.773438, -0.808594, -0.279297, -0.213867, 0.511719, 0.789062, -0.150391, -0.421875, -0.167969 ...
[VT][vision_model.encoder.layers.1.mlp.fc2[NLH]/item_960] shape=[768] showing 24/768: -0.222656, -0.431641, -0.753906, -0.238281, -0.722656, 0.0245361, 0.644531, 0.108887, -0.21875, 0.558594, 1.00781, -0.746094, -0.308594, 0.243164, 0.341797, 0.796875, -0.691406, -0.3125, -0.176758, 0.453125, 0.867188, -0.227539, -0.371094, -0.326172 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-5.3125 max=4.34375 mean=-0.128931 std=1.09908 sum1e6=-101395
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_0] shape=[768] showing 24/768: 1.24219, 0.0751953, 0.578125, 1.6875, 1.10938, -1.32812, -0.241211, -0.349609, 1.07031, 2.21875, 0.828125, -0.439453, -2.03125, -1.60938, 0.0957031, 0.132812, 1.42969, 0.0195312, -0.484375, 0.523438, 2.125, 0.40625, 1.51562, 1.125 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_64] shape=[768] showing 24/768: 0.96875, -0.142578, 0.441406, 1.38281, 0.839844, -1.20312, -0.316406, -0.494141, 1.15625, 1.84375, 0.539062, -0.0179443, -2, -1.22656, 0.0859375, 0.0820312, 0.863281, 0.078125, -0.582031, 0.320312, 1.96875, 0.792969, 1.20312, 1.32812 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_128] shape=[768] showing 24/768: 0.648438, -0.355469, 0.320312, 0.976562, 0.294922, -0.996094, -0.25, -0.636719, 1.24219, 1.54688, 0.324219, 0.259766, -1.95312, -0.703125, 0.0839844, 0.0664062, 0.210938, 0.110352, -0.871094, 0.168945, 1.6875, 1.13281, 1.02344, 1.5625 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_192] shape=[768] showing 24/768: 0.139648, -0.494141, 0.277344, 0.21875, -0.046875, -0.416016, -0.0830078, -0.785156, 1.20312, 1.05469, 0.140625, 0.574219, -1.6875, -0.137695, -0.0253906, 0.101562, -0.109375, 0.0849609, -1.25781, 0.158203, 1.3125, 1.69531, 0.78125, 1.57031 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_256] shape=[768] showing 24/768: -0.347656, -0.578125, 0.421875, -0.462891, -0.285156, 0.253906, 0.0703125, -1.11719, 1.08594, 0.523438, 0.119141, 0.679688, -1.67188, 0.351562, -0.140625, -0.0507812, -0.0703125, -0.212891, -1.39062, 0.230469, 0.8125, 1.97656, 0.703125, 1.375 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_320] shape=[768] showing 24/768: -0.898438, -0.695312, 0.769531, -1.00781, -0.617188, 0.439453, 0.0859375, -1.32812, 0.894531, -0.113281, 0.0234375, 0.535156, -1.375, 0.703125, -0.185547, 0.0078125, 0.0273438, -0.660156, -1.13281, 0.078125, 0.302734, 1.94531, 0.589844, 1.09375 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_384] shape=[768] showing 24/768: -1.25, -0.796875, 0.96875, -1.39062, -0.84375, 0.640625, 0.0546875, -1.51562, 0.871094, -0.515625, -0.0195312, 0.320312, -1.16406, 1.07031, -0.177734, -0.0117188, -0.0390625, -1.23438, -0.726562, -0.140625, -0.015625, 1.77344, 0.316406, 0.753906 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_448] shape=[768] showing 24/768: -1.59375, -0.84375, 1.11719, -1.71875, -1.29688, 0.695312, -0.0898438, -1.70312, 0.683594, -1.07031, -0.140625, 0.28125, -0.914062, 1.5625, -0.255859, -0.0195312, -0.167969, -1.54688, -0.380859, -0.373047, -0.4375, 1.74219, 0.0957031, 0.470703 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_512] shape=[768] showing 24/768: 1.23438, 0.0800781, 0.65625, 1.75, 1.04688, -1.42188, -0.365234, -0.384766, 1.10156, 2.21875, 0.746094, -0.402344, -2.01562, -1.5625, 0.160156, 0.101562, 1.46875, 0.0419922, -0.458984, 0.453125, 2.10938, 0.390625, 1.46875, 1.10938 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_576] shape=[768] showing 24/768: 1.00781, -0.119141, 0.53125, 1.46094, 0.722656, -1.26562, -0.435547, -0.474609, 1.14062, 1.89844, 0.507812, -0.0634766, -2.03125, -1.19531, 0.121094, 0.0742188, 0.824219, 0.142578, -0.636719, 0.283203, 1.99219, 0.6875, 1.20312, 1.36719 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_640] shape=[768] showing 24/768: 0.613281, -0.326172, 0.322266, 0.914062, 0.414062, -0.953125, -0.209961, -0.523438, 1.15625, 1.45312, 0.373047, 0.261719, -1.84375, -0.691406, 0.0957031, 0.0703125, 0.304688, 0.139648, -0.96875, 0.126953, 1.77344, 1.08594, 0.914062, 1.5625 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_704] shape=[768] showing 24/768: 0.104492, -0.490234, 0.234375, 0.265625, -0.03125, -0.410156, 0.00244141, -0.8125, 1.17188, 1.04688, 0.253906, 0.507812, -1.71875, -0.223633, -0.0742188, -0.0273438, -0.078125, -0.0761719, -1.26562, 0.199219, 1.48438, 1.55469, 0.824219, 1.67188 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_768] shape=[768] showing 24/768: -0.457031, -0.539062, 0.421875, -0.396484, -0.283203, 0.0371094, 0.0761719, -1, 1.13281, 0.523438, 0.0136719, 0.554688, -1.53125, 0.279297, -0.1875, 0, -0.03125, -0.078125, -1.375, 0.193359, 0.8125, 1.78125, 0.792969, 1.3125 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_832] shape=[768] showing 24/768: -0.820312, -0.636719, 0.773438, -0.9375, -0.539062, 0.433594, 0.183594, -1.23438, 0.953125, 0.0351562, -0.0351562, 0.566406, -1.42188, 0.648438, -0.238281, 0.015625, 0.015625, -0.515625, -1.01562, 0.203125, 0.244141, 1.98438, 0.519531, 1.03906 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_896] shape=[768] showing 24/768: -1.15625, -0.765625, 0.960938, -1.46875, -0.894531, 0.71875, 0.101562, -1.51562, 0.789062, -0.527344, 0.0078125, 0.359375, -1.10938, 1.16406, -0.291016, 0, 0.00390625, -1.09375, -0.675781, -0.140625, -0.15625, 1.78125, 0.351562, 0.585938 ...
[VT][vision_model.encoder.layers.2.layer_norm1/pre[NLH]/item_960] shape=[768] showing 24/768: -1.64062, -0.871094, 1.125, -1.6875, -1.32812, 0.738281, -0.105469, -1.73438, 0.75, -1.09375, -0.140625, 0.253906, -0.960938, 1.60156, -0.322266, 0.0390625, -0.167969, -1.49219, -0.3125, -0.355469, -0.429688, 1.75781, 0.214844, 0.455078 ...
[VT][vision_model.encoder.layers.2.layer_norm1] OUT shape=(1, 1024, 768) layout=NLH  min=-4.34375 max=4.09375 mean=-1.58635e-06 std=1 sum1e6=-1.24756
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_0] shape=[768] showing 24/768: 0.882812, -0.00521851, 0.378906, 1.22656, 0.78125, -1.07812, -0.246094, -0.328125, 0.753906, 1.625, 0.570312, -0.398438, -1.60938, -1.28906, 0.010437, 0.0388184, 1.02344, -0.0476074, -0.431641, 0.335938, 1.55469, 0.24707, 1.09375, 0.796875 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_64] shape=[768] showing 24/768: 0.753906, -0.161133, 0.318359, 1.09375, 0.644531, -1.03125, -0.302734, -0.449219, 0.90625, 1.46875, 0.398438, -0.0583496, -1.6875, -1.05469, 0.0268555, 0.0236816, 0.664062, 0.0205078, -0.523438, 0.219727, 1.57031, 0.609375, 0.945312, 1.04688 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_128] shape=[768] showing 24/768: 0.535156, -0.337891, 0.25, 0.820312, 0.228516, -0.894531, -0.246094, -0.582031, 1.05469, 1.32031, 0.253906, 0.197266, -1.72656, -0.640625, 0.0444336, 0.0290527, 0.155273, 0.0673828, -0.785156, 0.118164, 1.4375, 0.957031, 0.863281, 1.32812 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_192] shape=[768] showing 24/768: 0.112793, -0.453125, 0.235352, 0.183594, -0.0539551, -0.382812, -0.0859375, -0.714844, 1.0625, 0.929688, 0.113281, 0.5, -1.51562, -0.134766, -0.034668, 0.0786133, -0.109863, 0.0639648, -1.13281, 0.128906, 1.15625, 1.5, 0.683594, 1.39062 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_256] shape=[768] showing 24/768: -0.298828, -0.503906, 0.384766, -0.402344, -0.243164, 0.236328, 0.0727539, -0.984375, 0.976562, 0.474609, 0.116211, 0.613281, -1.47656, 0.322266, -0.114746, -0.0351562, -0.0524902, -0.179688, -1.22656, 0.214844, 0.734375, 1.76562, 0.636719, 1.23438 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_320] shape=[768] showing 24/768: -0.742188, -0.566406, 0.707031, -0.839844, -0.498047, 0.419922, 0.111816, -1.11719, 0.8125, -0.0610352, 0.0576172, 0.503906, -1.15625, 0.648438, -0.124023, 0.0441895, 0.0610352, -0.535156, -0.945312, 0.10498, 0.300781, 1.72656, 0.550781, 0.988281 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.597656, 0.871094, -1.09375, -0.636719, 0.597656, 0.11084, -1.19531, 0.792969, -0.365234, 0.0490723, 0.332031, -0.90625, 0.957031, -0.0830078, 0.0556641, 0.0327148, -0.964844, -0.539062, -0.0517578, 0.0522461, 1.54688, 0.328125, 0.695312 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_448] shape=[768] showing 24/768: -1.14844, -0.566406, 0.964844, -1.25, -0.921875, 0.632812, 0.0218506, -1.23438, 0.625, -0.742188, -0.0177002, 0.310547, -0.621094, 1.3125, -0.10791, 0.0766602, -0.0390625, -1.11719, -0.205078, -0.199219, -0.249023, 1.45312, 0.166992, 0.458984 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_512] shape=[768] showing 24/768: 0.875, -0.0019989, 0.435547, 1.26562, 0.734375, -1.14062, -0.339844, -0.355469, 0.773438, 1.625, 0.503906, -0.369141, -1.59375, -1.25, 0.0588379, 0.0143433, 1.05469, -0.0308838, -0.412109, 0.28125, 1.53906, 0.234375, 1.05469, 0.78125 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_576] shape=[768] showing 24/768: 0.785156, -0.143555, 0.392578, 1.15625, 0.550781, -1.08594, -0.402344, -0.435547, 0.894531, 1.51562, 0.373047, -0.097168, -1.71875, -1.03125, 0.0544434, 0.0158691, 0.632812, 0.0722656, -0.570312, 0.1875, 1.59375, 0.519531, 0.945312, 1.07812 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_640] shape=[768] showing 24/768: 0.507812, -0.3125, 0.253906, 0.769531, 0.333984, -0.859375, -0.211914, -0.486328, 0.980469, 1.24219, 0.296875, 0.200195, -1.64062, -0.632812, 0.0551758, 0.032959, 0.237305, 0.0932617, -0.875, 0.0825195, 1.52344, 0.921875, 0.769531, 1.33594 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_704] shape=[768] showing 24/768: 0.0820312, -0.449219, 0.198242, 0.225586, -0.0390625, -0.376953, -0.0090332, -0.738281, 1.03125, 0.921875, 0.21582, 0.441406, -1.54688, -0.210938, -0.0776367, -0.0356445, -0.0810547, -0.0791016, -1.14062, 0.166992, 1.3125, 1.375, 0.722656, 1.48438 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_768] shape=[768] showing 24/768: -0.398438, -0.470703, 0.384766, -0.34375, -0.243164, 0.041748, 0.0766602, -0.882812, 1.01562, 0.474609, 0.020874, 0.503906, -1.35156, 0.257812, -0.158203, 0.00866699, -0.019165, -0.060791, -1.21875, 0.180664, 0.730469, 1.59375, 0.714844, 1.17969 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_832] shape=[768] showing 24/768: -0.675781, -0.515625, 0.707031, -0.777344, -0.431641, 0.414062, 0.196289, -1.03906, 0.863281, 0.0668945, 0.00561523, 0.527344, -1.20312, 0.601562, -0.170898, 0.0498047, 0.0498047, -0.412109, -0.847656, 0.212891, 0.248047, 1.75781, 0.488281, 0.941406 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_896] shape=[768] showing 24/768: -0.902344, -0.574219, 0.867188, -1.16406, -0.683594, 0.664062, 0.149414, -1.20312, 0.722656, -0.375, 0.0712891, 0.365234, -0.863281, 1.03906, -0.177734, 0.0649414, 0.0683594, -0.847656, -0.5, -0.0524902, -0.0654297, 1.55469, 0.359375, 0.554688 ...
[VT][vision_model.encoder.layers.2.layer_norm1[NLH]/item_960] shape=[768] showing 24/768: -1.1875, -0.589844, 0.96875, -1.22656, -0.945312, 0.664062, 0.00817871, -1.25781, 0.675781, -0.761719, -0.0192871, 0.289062, -0.660156, 1.33594, -0.161133, 0.121094, -0.0405273, -1.07031, -0.15332, -0.186523, -0.244141, 1.46094, 0.257812, 0.445312 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.34375 max=4.09375 mean=-1.58635e-06 std=1 sum1e6=-1.24756
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.882812, -0.00521851, 0.378906, 1.22656, 0.78125, -1.07812, -0.246094, -0.328125, 0.753906, 1.625, 0.570312, -0.398438, -1.60938, -1.28906, 0.010437, 0.0388184, 1.02344, -0.0476074, -0.431641, 0.335938, 1.55469, 0.24707, 1.09375, 0.796875 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.753906, -0.161133, 0.318359, 1.09375, 0.644531, -1.03125, -0.302734, -0.449219, 0.90625, 1.46875, 0.398438, -0.0583496, -1.6875, -1.05469, 0.0268555, 0.0236816, 0.664062, 0.0205078, -0.523438, 0.219727, 1.57031, 0.609375, 0.945312, 1.04688 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.535156, -0.337891, 0.25, 0.820312, 0.228516, -0.894531, -0.246094, -0.582031, 1.05469, 1.32031, 0.253906, 0.197266, -1.72656, -0.640625, 0.0444336, 0.0290527, 0.155273, 0.0673828, -0.785156, 0.118164, 1.4375, 0.957031, 0.863281, 1.32812 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_192] shape=[768] showing 24/768: 0.112793, -0.453125, 0.235352, 0.183594, -0.0539551, -0.382812, -0.0859375, -0.714844, 1.0625, 0.929688, 0.113281, 0.5, -1.51562, -0.134766, -0.034668, 0.0786133, -0.109863, 0.0639648, -1.13281, 0.128906, 1.15625, 1.5, 0.683594, 1.39062 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.298828, -0.503906, 0.384766, -0.402344, -0.243164, 0.236328, 0.0727539, -0.984375, 0.976562, 0.474609, 0.116211, 0.613281, -1.47656, 0.322266, -0.114746, -0.0351562, -0.0524902, -0.179688, -1.22656, 0.214844, 0.734375, 1.76562, 0.636719, 1.23438 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.742188, -0.566406, 0.707031, -0.839844, -0.498047, 0.419922, 0.111816, -1.11719, 0.8125, -0.0610352, 0.0576172, 0.503906, -1.15625, 0.648438, -0.124023, 0.0441895, 0.0610352, -0.535156, -0.945312, 0.10498, 0.300781, 1.72656, 0.550781, 0.988281 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.597656, 0.871094, -1.09375, -0.636719, 0.597656, 0.11084, -1.19531, 0.792969, -0.365234, 0.0490723, 0.332031, -0.90625, 0.957031, -0.0830078, 0.0556641, 0.0327148, -0.964844, -0.539062, -0.0517578, 0.0522461, 1.54688, 0.328125, 0.695312 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.14844, -0.566406, 0.964844, -1.25, -0.921875, 0.632812, 0.0218506, -1.23438, 0.625, -0.742188, -0.0177002, 0.310547, -0.621094, 1.3125, -0.10791, 0.0766602, -0.0390625, -1.11719, -0.205078, -0.199219, -0.249023, 1.45312, 0.166992, 0.458984 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.875, -0.0019989, 0.435547, 1.26562, 0.734375, -1.14062, -0.339844, -0.355469, 0.773438, 1.625, 0.503906, -0.369141, -1.59375, -1.25, 0.0588379, 0.0143433, 1.05469, -0.0308838, -0.412109, 0.28125, 1.53906, 0.234375, 1.05469, 0.78125 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.785156, -0.143555, 0.392578, 1.15625, 0.550781, -1.08594, -0.402344, -0.435547, 0.894531, 1.51562, 0.373047, -0.097168, -1.71875, -1.03125, 0.0544434, 0.0158691, 0.632812, 0.0722656, -0.570312, 0.1875, 1.59375, 0.519531, 0.945312, 1.07812 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.507812, -0.3125, 0.253906, 0.769531, 0.333984, -0.859375, -0.211914, -0.486328, 0.980469, 1.24219, 0.296875, 0.200195, -1.64062, -0.632812, 0.0551758, 0.032959, 0.237305, 0.0932617, -0.875, 0.0825195, 1.52344, 0.921875, 0.769531, 1.33594 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_704] shape=[768] showing 24/768: 0.0820312, -0.449219, 0.198242, 0.225586, -0.0390625, -0.376953, -0.0090332, -0.738281, 1.03125, 0.921875, 0.21582, 0.441406, -1.54688, -0.210938, -0.0776367, -0.0356445, -0.0810547, -0.0791016, -1.14062, 0.166992, 1.3125, 1.375, 0.722656, 1.48438 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.398438, -0.470703, 0.384766, -0.34375, -0.243164, 0.041748, 0.0766602, -0.882812, 1.01562, 0.474609, 0.020874, 0.503906, -1.35156, 0.257812, -0.158203, 0.00866699, -0.019165, -0.060791, -1.21875, 0.180664, 0.730469, 1.59375, 0.714844, 1.17969 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.675781, -0.515625, 0.707031, -0.777344, -0.431641, 0.414062, 0.196289, -1.03906, 0.863281, 0.0668945, 0.00561523, 0.527344, -1.20312, 0.601562, -0.170898, 0.0498047, 0.0498047, -0.412109, -0.847656, 0.212891, 0.248047, 1.75781, 0.488281, 0.941406 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -0.902344, -0.574219, 0.867188, -1.16406, -0.683594, 0.664062, 0.149414, -1.20312, 0.722656, -0.375, 0.0712891, 0.365234, -0.863281, 1.03906, -0.177734, 0.0649414, 0.0683594, -0.847656, -0.5, -0.0524902, -0.0654297, 1.55469, 0.359375, 0.554688 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.1875, -0.589844, 0.96875, -1.22656, -0.945312, 0.664062, 0.00817871, -1.25781, 0.675781, -0.761719, -0.0192871, 0.289062, -0.660156, 1.33594, -0.161133, 0.121094, -0.0405273, -1.07031, -0.15332, -0.186523, -0.244141, 1.46094, 0.257812, 0.445312 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.25 max=3.8125 mean=-0.00161284 std=1.0016 sum1e6=-1268.39
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_0] shape=[768] showing 24/768: 0.466797, -1.63281, 1.17188, -0.753906, 0.472656, -0.679688, 0.0290527, -0.416016, -0.75, 0.425781, 1.07031, -3.1875, -0.539062, -0.289062, -1.35156, -1.00781, -1.53125, 0.234375, 2.25, -0.296875, 0.163086, -1, 1.11719, -0.800781 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_64] shape=[768] showing 24/768: 0.46875, -1.44531, 1.59375, -0.441406, 0.4375, -0.621094, 0.117188, -0.574219, -0.53125, 0.460938, 0.714844, -2.9375, -0.208008, -0.220703, -1.63281, -0.738281, -1.4375, 0.589844, 2.40625, -0.185547, 0.271484, -0.847656, 0.832031, -0.984375 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_128] shape=[768] showing 24/768: 0.441406, -1.17969, 1.99219, -0.0131226, 0.441406, -0.464844, 0.142578, -0.789062, -0.269531, 0.306641, 0.332031, -2.46875, 0.269531, -0.0791016, -1.89062, -0.332031, -1.28125, 1.07812, 2.40625, 0.145508, 0.318359, -0.636719, 0.298828, -1.21094 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_192] shape=[768] showing 24/768: 0.265625, -0.824219, 2.39062, 0.294922, 0.546875, -0.449219, 0.292969, -0.914062, -0.034668, 0.178711, -0.429688, -1.55469, 0.613281, -0.0209961, -1.96875, 0.326172, -1.3125, 1.32812, 2.09375, 0.539062, 0.292969, -0.455078, -0.3125, -1.25781 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_256] shape=[768] showing 24/768: 0.013855, -0.636719, 2.60938, 0.652344, 0.859375, -0.337891, 0.425781, -0.894531, 0.214844, 0.261719, -1.14844, -0.644531, 0.953125, -0.00939941, -1.85156, 0.90625, -1.41406, 1.34375, 1.48438, 0.894531, 0.341797, -0.240234, -0.835938, -1.08594 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_320] shape=[768] showing 24/768: -0.206055, -0.310547, 2.73438, 0.996094, 1.21094, -0.365234, 0.4375, -0.597656, 0.640625, 0.570312, -1.46094, 0.102539, 1.19531, 0.0319824, -1.48438, 1.26562, -1.21094, 1.13281, 1.09375, 1.16406, 0.257812, -0.148438, -1.27344, -0.859375 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_384] shape=[768] showing 24/768: -0.337891, 0.0110474, 2.6875, 1.15625, 1.39844, -0.453125, 0.384766, -0.398438, 0.800781, 1, -1.58594, 0.617188, 1.40625, 0.15918, -1.13281, 1.34375, -0.945312, 0.964844, 0.890625, 1.25781, 0.104004, 0.0761719, -1.73438, -0.636719 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_448] shape=[768] showing 24/768: -0.345703, 0.365234, 2.4375, 1.33594, 1.35156, -0.455078, 0.292969, -0.213867, 1.04688, 1.27344, -1.5, 0.949219, 1.57031, 0.310547, -0.886719, 1.39062, -0.597656, 0.695312, 0.675781, 1.17188, 0.0308838, 0.199219, -2.14062, -0.330078 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_512] shape=[768] showing 24/768: 0.453125, -1.64844, 1.09375, -0.671875, 0.412109, -0.675781, 0.000297546, -0.429688, -0.78125, 0.335938, 1.05469, -3.21875, -0.539062, -0.224609, -1.35156, -0.964844, -1.53906, 0.310547, 2.25, -0.34375, 0.271484, -1.02344, 1.13281, -0.769531 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_576] shape=[768] showing 24/768: 0.515625, -1.40625, 1.51562, -0.451172, 0.451172, -0.636719, 0.0407715, -0.558594, -0.546875, 0.386719, 0.820312, -3, -0.212891, -0.162109, -1.6875, -0.691406, -1.46875, 0.667969, 2.5, -0.196289, 0.245117, -0.835938, 0.761719, -1.01562 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_640] shape=[768] showing 24/768: 0.390625, -1.1875, 2.01562, -0.166992, 0.511719, -0.550781, 0.105957, -0.730469, -0.376953, 0.3125, 0.341797, -2.35938, 0.166992, -0.106934, -1.95312, -0.28125, -1.33594, 1.0625, 2.35938, 0.160156, 0.243164, -0.703125, 0.267578, -1.28125 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_704] shape=[768] showing 24/768: 0.169922, -0.945312, 2.32812, 0.300781, 0.566406, -0.396484, 0.219727, -0.960938, -0.213867, 0.265625, -0.484375, -1.55469, 0.578125, -0.0581055, -1.99219, 0.28125, -1.22656, 1.34375, 1.98438, 0.574219, 0.333984, -0.451172, -0.291016, -1.26562 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_768] shape=[768] showing 24/768: 0.0203857, -0.644531, 2.625, 0.652344, 0.886719, -0.390625, 0.388672, -0.800781, 0.15918, 0.226562, -1.0625, -0.578125, 0.867188, -0.00610352, -1.75781, 0.890625, -1.21094, 1.35938, 1.58594, 1, 0.246094, -0.337891, -0.8125, -1.13281 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_832] shape=[768] showing 24/768: -0.140625, -0.314453, 2.78125, 0.96875, 1.24219, -0.375, 0.486328, -0.550781, 0.554688, 0.474609, -1.46094, 0.0708008, 1.10156, 0.147461, -1.49219, 1.25781, -1.24219, 1.13281, 1.19531, 1.17188, 0.261719, -0.189453, -1.26562, -0.863281 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_896] shape=[768] showing 24/768: -0.239258, 0.0864258, 2.71875, 1.11719, 1.40625, -0.425781, 0.478516, -0.345703, 0.886719, 0.894531, -1.625, 0.640625, 1.375, 0.257812, -1.10938, 1.41406, -0.929688, 0.964844, 0.902344, 1.1875, 0.131836, -0.0541992, -1.71875, -0.578125 ...
[VT][vision_model.encoder.layers.2.self_attn.q_proj[NLH]/item_960] shape=[768] showing 24/768: -0.283203, 0.369141, 2.5, 1.30469, 1.35156, -0.472656, 0.292969, -0.210938, 1.03906, 1.28125, -1.52344, 0.960938, 1.59375, 0.417969, -0.917969, 1.32031, -0.582031, 0.734375, 0.757812, 1.21094, 0.0454102, 0.183594, -2.125, -0.410156 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.34375 max=4.09375 mean=-1.58635e-06 std=1 sum1e6=-1.24756
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.882812, -0.00521851, 0.378906, 1.22656, 0.78125, -1.07812, -0.246094, -0.328125, 0.753906, 1.625, 0.570312, -0.398438, -1.60938, -1.28906, 0.010437, 0.0388184, 1.02344, -0.0476074, -0.431641, 0.335938, 1.55469, 0.24707, 1.09375, 0.796875 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.753906, -0.161133, 0.318359, 1.09375, 0.644531, -1.03125, -0.302734, -0.449219, 0.90625, 1.46875, 0.398438, -0.0583496, -1.6875, -1.05469, 0.0268555, 0.0236816, 0.664062, 0.0205078, -0.523438, 0.219727, 1.57031, 0.609375, 0.945312, 1.04688 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.535156, -0.337891, 0.25, 0.820312, 0.228516, -0.894531, -0.246094, -0.582031, 1.05469, 1.32031, 0.253906, 0.197266, -1.72656, -0.640625, 0.0444336, 0.0290527, 0.155273, 0.0673828, -0.785156, 0.118164, 1.4375, 0.957031, 0.863281, 1.32812 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_192] shape=[768] showing 24/768: 0.112793, -0.453125, 0.235352, 0.183594, -0.0539551, -0.382812, -0.0859375, -0.714844, 1.0625, 0.929688, 0.113281, 0.5, -1.51562, -0.134766, -0.034668, 0.0786133, -0.109863, 0.0639648, -1.13281, 0.128906, 1.15625, 1.5, 0.683594, 1.39062 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.298828, -0.503906, 0.384766, -0.402344, -0.243164, 0.236328, 0.0727539, -0.984375, 0.976562, 0.474609, 0.116211, 0.613281, -1.47656, 0.322266, -0.114746, -0.0351562, -0.0524902, -0.179688, -1.22656, 0.214844, 0.734375, 1.76562, 0.636719, 1.23438 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.742188, -0.566406, 0.707031, -0.839844, -0.498047, 0.419922, 0.111816, -1.11719, 0.8125, -0.0610352, 0.0576172, 0.503906, -1.15625, 0.648438, -0.124023, 0.0441895, 0.0610352, -0.535156, -0.945312, 0.10498, 0.300781, 1.72656, 0.550781, 0.988281 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.597656, 0.871094, -1.09375, -0.636719, 0.597656, 0.11084, -1.19531, 0.792969, -0.365234, 0.0490723, 0.332031, -0.90625, 0.957031, -0.0830078, 0.0556641, 0.0327148, -0.964844, -0.539062, -0.0517578, 0.0522461, 1.54688, 0.328125, 0.695312 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.14844, -0.566406, 0.964844, -1.25, -0.921875, 0.632812, 0.0218506, -1.23438, 0.625, -0.742188, -0.0177002, 0.310547, -0.621094, 1.3125, -0.10791, 0.0766602, -0.0390625, -1.11719, -0.205078, -0.199219, -0.249023, 1.45312, 0.166992, 0.458984 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.875, -0.0019989, 0.435547, 1.26562, 0.734375, -1.14062, -0.339844, -0.355469, 0.773438, 1.625, 0.503906, -0.369141, -1.59375, -1.25, 0.0588379, 0.0143433, 1.05469, -0.0308838, -0.412109, 0.28125, 1.53906, 0.234375, 1.05469, 0.78125 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.785156, -0.143555, 0.392578, 1.15625, 0.550781, -1.08594, -0.402344, -0.435547, 0.894531, 1.51562, 0.373047, -0.097168, -1.71875, -1.03125, 0.0544434, 0.0158691, 0.632812, 0.0722656, -0.570312, 0.1875, 1.59375, 0.519531, 0.945312, 1.07812 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.507812, -0.3125, 0.253906, 0.769531, 0.333984, -0.859375, -0.211914, -0.486328, 0.980469, 1.24219, 0.296875, 0.200195, -1.64062, -0.632812, 0.0551758, 0.032959, 0.237305, 0.0932617, -0.875, 0.0825195, 1.52344, 0.921875, 0.769531, 1.33594 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_704] shape=[768] showing 24/768: 0.0820312, -0.449219, 0.198242, 0.225586, -0.0390625, -0.376953, -0.0090332, -0.738281, 1.03125, 0.921875, 0.21582, 0.441406, -1.54688, -0.210938, -0.0776367, -0.0356445, -0.0810547, -0.0791016, -1.14062, 0.166992, 1.3125, 1.375, 0.722656, 1.48438 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.398438, -0.470703, 0.384766, -0.34375, -0.243164, 0.041748, 0.0766602, -0.882812, 1.01562, 0.474609, 0.020874, 0.503906, -1.35156, 0.257812, -0.158203, 0.00866699, -0.019165, -0.060791, -1.21875, 0.180664, 0.730469, 1.59375, 0.714844, 1.17969 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.675781, -0.515625, 0.707031, -0.777344, -0.431641, 0.414062, 0.196289, -1.03906, 0.863281, 0.0668945, 0.00561523, 0.527344, -1.20312, 0.601562, -0.170898, 0.0498047, 0.0498047, -0.412109, -0.847656, 0.212891, 0.248047, 1.75781, 0.488281, 0.941406 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -0.902344, -0.574219, 0.867188, -1.16406, -0.683594, 0.664062, 0.149414, -1.20312, 0.722656, -0.375, 0.0712891, 0.365234, -0.863281, 1.03906, -0.177734, 0.0649414, 0.0683594, -0.847656, -0.5, -0.0524902, -0.0654297, 1.55469, 0.359375, 0.554688 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.1875, -0.589844, 0.96875, -1.22656, -0.945312, 0.664062, 0.00817871, -1.25781, 0.675781, -0.761719, -0.0192871, 0.289062, -0.660156, 1.33594, -0.161133, 0.121094, -0.0405273, -1.07031, -0.15332, -0.186523, -0.244141, 1.46094, 0.257812, 0.445312 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-4.25 max=4.03125 mean=-0.00852745 std=1.00201 sum1e6=-6706.26
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_0] shape=[768] showing 24/768: -0.141602, 0.929688, 1.03125, 0.941406, -1.35938, 0.110352, 0.523438, 1.92969, 0.367188, 0.318359, 1.63281, 1.45312, -0.527344, 0.447266, -1.03906, -0.761719, -0.503906, -2.75, -1.36719, 0.230469, 1.66406, 0.148438, 0.59375, 0.839844 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_64] shape=[768] showing 24/768: 0.0820312, 1.16406, 0.855469, 0.96875, -1.34375, 0.141602, 0.414062, 1.97656, 0.363281, -0.15918, 1.54688, 1.5, -0.416016, 0.447266, -0.824219, -0.625, -0.808594, -2.76562, -1.83594, 0.104492, 1.75781, -0.147461, 0.494141, 0.953125 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_128] shape=[768] showing 24/768: 0.400391, 1.53125, 0.605469, 0.925781, -1.16406, 0.188477, 0.263672, 1.94531, 0.298828, -0.75, 1.53906, 1.4375, -0.330078, 0.398438, -0.597656, -0.400391, -1.125, -2.6875, -2.40625, -0.122559, 1.77344, -0.566406, 0.28125, 1.09375 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_192] shape=[768] showing 24/768: 0.59375, 1.89844, 0.333984, 0.832031, -0.777344, 0.244141, -0.00952148, 1.82812, 0.367188, -1.55469, 1.44531, 1.25, -0.25, 0.0483398, -0.59375, -0.133789, -1.5625, -2.39062, -2.9375, -0.205078, 1.67969, -0.925781, -0.0220947, 1.09375 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_256] shape=[768] showing 24/768: 0.847656, 2.1875, 0.0537109, 0.664062, -0.34375, 0.241211, -0.412109, 1.78906, 0.535156, -2.14062, 1.32812, 0.980469, -0.196289, -0.111816, -0.730469, 0.257812, -1.86719, -1.72656, -2.96875, -0.115723, 1.63281, -1.14062, -0.414062, 1.10156 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_320] shape=[768] showing 24/768: 1.09375, 2.34375, -0.0795898, 0.496094, -0.0395508, 0.417969, -0.792969, 1.55469, 0.613281, -2.48438, 1.38281, 0.75, -0.237305, -0.143555, -0.648438, 0.6875, -1.82031, -1.04688, -2.73438, 0.0166016, 1.44531, -1.02344, -1.00781, 0.921875 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_384] shape=[768] showing 24/768: 1.49219, 2.15625, -0.115234, 0.158203, 0.0483398, 0.628906, -1.17969, 1.1875, 0.625, -2.60938, 1.50781, 0.466797, -0.130859, -0.228516, -0.369141, 1.125, -1.45312, -0.351562, -2.45312, 0.129883, 1.35938, -0.78125, -1.46094, 0.785156 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_448] shape=[768] showing 24/768: 1.59375, 1.92188, -0.0722656, -0.0888672, 0.165039, 0.816406, -1.39844, 0.769531, 0.558594, -2.46875, 1.45312, 0.251953, -0.0388184, -0.306641, 0.000172615, 1.41406, -1.10938, 0.201172, -2.09375, 0.203125, 1.17188, -0.671875, -1.86719, 0.753906 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_512] shape=[768] showing 24/768: -0.132812, 0.929688, 1.02344, 1, -1.4375, 0.0844727, 0.470703, 1.92969, 0.308594, 0.259766, 1.625, 1.39844, -0.486328, 0.466797, -0.972656, -0.699219, -0.589844, -2.75, -1.36719, 0.230469, 1.625, 0.151367, 0.601562, 0.851562 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_576] shape=[768] showing 24/768: 0.117676, 1.17188, 0.78125, 0.960938, -1.38281, 0.129883, 0.427734, 2, 0.341797, -0.202148, 1.60156, 1.42969, -0.40625, 0.523438, -0.753906, -0.605469, -0.757812, -2.79688, -1.86719, 0.09375, 1.8125, -0.114258, 0.507812, 0.992188 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_640] shape=[768] showing 24/768: 0.349609, 1.54688, 0.574219, 0.851562, -1.14062, 0.136719, 0.300781, 1.96875, 0.386719, -0.808594, 1.47656, 1.42188, -0.289062, 0.466797, -0.625, -0.445312, -1.17188, -2.6875, -2.51562, -0.0407715, 1.75781, -0.648438, 0.351562, 1.07812 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_704] shape=[768] showing 24/768: 0.652344, 1.90625, 0.396484, 0.863281, -0.777344, 0.223633, 0.000178337, 1.92188, 0.380859, -1.52344, 1.40625, 1.17969, -0.240234, 0.18457, -0.671875, -0.114746, -1.60156, -2.375, -2.96875, -0.165039, 1.69531, -1.09375, 0.0654297, 1.01562 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_768] shape=[768] showing 24/768: 0.917969, 2.1875, 0.0241699, 0.734375, -0.316406, 0.361328, -0.429688, 1.79688, 0.390625, -2.17188, 1.28906, 0.988281, -0.195312, -0.0149536, -0.773438, 0.292969, -1.9375, -1.80469, -2.96875, -0.0727539, 1.45312, -1.20312, -0.492188, 1.01562 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_832] shape=[768] showing 24/768: 1.14062, 2.26562, -0.12793, 0.546875, -0.0449219, 0.482422, -0.910156, 1.55469, 0.523438, -2.54688, 1.32812, 0.738281, -0.119141, -0.214844, -0.652344, 0.730469, -1.80469, -1.125, -2.82812, 0.09375, 1.4375, -1.02344, -1.07031, 0.890625 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_896] shape=[768] showing 24/768: 1.42188, 2.21875, -0.102051, 0.202148, 0.1875, 0.613281, -1.27344, 1.21094, 0.625, -2.6875, 1.46094, 0.482422, -0.0664062, -0.261719, -0.310547, 1.25, -1.53125, -0.408203, -2.45312, 0.128906, 1.32031, -0.777344, -1.53125, 0.832031 ...
[VT][vision_model.encoder.layers.2.self_attn.k_proj[NLH]/item_960] shape=[768] showing 24/768: 1.64062, 1.92188, -0.0917969, -0.0786133, 0.176758, 0.8125, -1.45312, 0.769531, 0.550781, -2.45312, 1.49219, 0.296875, -0.032959, -0.239258, 0.0218506, 1.42969, -1.19531, 0.140625, -2.0625, 0.157227, 1.15625, -0.613281, -1.8125, 0.722656 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre] IN  shape=(1, 1024, 768) layout=NLH  min=-4.34375 max=4.09375 mean=-1.58635e-06 std=1 sum1e6=-1.24756
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_0] shape=[768] showing 24/768: 0.882812, -0.00521851, 0.378906, 1.22656, 0.78125, -1.07812, -0.246094, -0.328125, 0.753906, 1.625, 0.570312, -0.398438, -1.60938, -1.28906, 0.010437, 0.0388184, 1.02344, -0.0476074, -0.431641, 0.335938, 1.55469, 0.24707, 1.09375, 0.796875 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_64] shape=[768] showing 24/768: 0.753906, -0.161133, 0.318359, 1.09375, 0.644531, -1.03125, -0.302734, -0.449219, 0.90625, 1.46875, 0.398438, -0.0583496, -1.6875, -1.05469, 0.0268555, 0.0236816, 0.664062, 0.0205078, -0.523438, 0.219727, 1.57031, 0.609375, 0.945312, 1.04688 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_128] shape=[768] showing 24/768: 0.535156, -0.337891, 0.25, 0.820312, 0.228516, -0.894531, -0.246094, -0.582031, 1.05469, 1.32031, 0.253906, 0.197266, -1.72656, -0.640625, 0.0444336, 0.0290527, 0.155273, 0.0673828, -0.785156, 0.118164, 1.4375, 0.957031, 0.863281, 1.32812 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_192] shape=[768] showing 24/768: 0.112793, -0.453125, 0.235352, 0.183594, -0.0539551, -0.382812, -0.0859375, -0.714844, 1.0625, 0.929688, 0.113281, 0.5, -1.51562, -0.134766, -0.034668, 0.0786133, -0.109863, 0.0639648, -1.13281, 0.128906, 1.15625, 1.5, 0.683594, 1.39062 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_256] shape=[768] showing 24/768: -0.298828, -0.503906, 0.384766, -0.402344, -0.243164, 0.236328, 0.0727539, -0.984375, 0.976562, 0.474609, 0.116211, 0.613281, -1.47656, 0.322266, -0.114746, -0.0351562, -0.0524902, -0.179688, -1.22656, 0.214844, 0.734375, 1.76562, 0.636719, 1.23438 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_320] shape=[768] showing 24/768: -0.742188, -0.566406, 0.707031, -0.839844, -0.498047, 0.419922, 0.111816, -1.11719, 0.8125, -0.0610352, 0.0576172, 0.503906, -1.15625, 0.648438, -0.124023, 0.0441895, 0.0610352, -0.535156, -0.945312, 0.10498, 0.300781, 1.72656, 0.550781, 0.988281 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_384] shape=[768] showing 24/768: -0.976562, -0.597656, 0.871094, -1.09375, -0.636719, 0.597656, 0.11084, -1.19531, 0.792969, -0.365234, 0.0490723, 0.332031, -0.90625, 0.957031, -0.0830078, 0.0556641, 0.0327148, -0.964844, -0.539062, -0.0517578, 0.0522461, 1.54688, 0.328125, 0.695312 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_448] shape=[768] showing 24/768: -1.14844, -0.566406, 0.964844, -1.25, -0.921875, 0.632812, 0.0218506, -1.23438, 0.625, -0.742188, -0.0177002, 0.310547, -0.621094, 1.3125, -0.10791, 0.0766602, -0.0390625, -1.11719, -0.205078, -0.199219, -0.249023, 1.45312, 0.166992, 0.458984 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_512] shape=[768] showing 24/768: 0.875, -0.0019989, 0.435547, 1.26562, 0.734375, -1.14062, -0.339844, -0.355469, 0.773438, 1.625, 0.503906, -0.369141, -1.59375, -1.25, 0.0588379, 0.0143433, 1.05469, -0.0308838, -0.412109, 0.28125, 1.53906, 0.234375, 1.05469, 0.78125 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_576] shape=[768] showing 24/768: 0.785156, -0.143555, 0.392578, 1.15625, 0.550781, -1.08594, -0.402344, -0.435547, 0.894531, 1.51562, 0.373047, -0.097168, -1.71875, -1.03125, 0.0544434, 0.0158691, 0.632812, 0.0722656, -0.570312, 0.1875, 1.59375, 0.519531, 0.945312, 1.07812 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_640] shape=[768] showing 24/768: 0.507812, -0.3125, 0.253906, 0.769531, 0.333984, -0.859375, -0.211914, -0.486328, 0.980469, 1.24219, 0.296875, 0.200195, -1.64062, -0.632812, 0.0551758, 0.032959, 0.237305, 0.0932617, -0.875, 0.0825195, 1.52344, 0.921875, 0.769531, 1.33594 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_704] shape=[768] showing 24/768: 0.0820312, -0.449219, 0.198242, 0.225586, -0.0390625, -0.376953, -0.0090332, -0.738281, 1.03125, 0.921875, 0.21582, 0.441406, -1.54688, -0.210938, -0.0776367, -0.0356445, -0.0810547, -0.0791016, -1.14062, 0.166992, 1.3125, 1.375, 0.722656, 1.48438 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_768] shape=[768] showing 24/768: -0.398438, -0.470703, 0.384766, -0.34375, -0.243164, 0.041748, 0.0766602, -0.882812, 1.01562, 0.474609, 0.020874, 0.503906, -1.35156, 0.257812, -0.158203, 0.00866699, -0.019165, -0.060791, -1.21875, 0.180664, 0.730469, 1.59375, 0.714844, 1.17969 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_832] shape=[768] showing 24/768: -0.675781, -0.515625, 0.707031, -0.777344, -0.431641, 0.414062, 0.196289, -1.03906, 0.863281, 0.0668945, 0.00561523, 0.527344, -1.20312, 0.601562, -0.170898, 0.0498047, 0.0498047, -0.412109, -0.847656, 0.212891, 0.248047, 1.75781, 0.488281, 0.941406 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_896] shape=[768] showing 24/768: -0.902344, -0.574219, 0.867188, -1.16406, -0.683594, 0.664062, 0.149414, -1.20312, 0.722656, -0.375, 0.0712891, 0.365234, -0.863281, 1.03906, -0.177734, 0.0649414, 0.0683594, -0.847656, -0.5, -0.0524902, -0.0654297, 1.55469, 0.359375, 0.554688 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj/pre[NLH]/item_960] shape=[768] showing 24/768: -1.1875, -0.589844, 0.96875, -1.22656, -0.945312, 0.664062, 0.00817871, -1.25781, 0.675781, -0.761719, -0.0192871, 0.289062, -0.660156, 1.33594, -0.161133, 0.121094, -0.0405273, -1.07031, -0.15332, -0.186523, -0.244141, 1.46094, 0.257812, 0.445312 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj] OUT shape=(1, 1024, 768) layout=NLH  min=-3.96875 max=4.46875 mean=-0.0146551 std=1.02733 sum1e6=-11525.2
[VT][vision_model.encoder.layers.2.self_attn.v_proj[NLH]/item_0] shape=[768] showing 24/768: -0.988281, 0.466797, 1.45312, 0.988281, -0.380859, 0.132812, -0.921875, 1.41406, -2.28125, 0.601562, 0.154297, 1.44531, 1.38281, 1.39844, -0.296875, -1.02344, -0.832031, -1.01562, 0.192383, 2.34375, -0.257812, 0.566406, 0.267578, 0.248047 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj[NLH]/item_64] shape=[768] showing 24/768: -0.804688, 0.492188, 1.5, 1.30469, -0.613281, 0.699219, -0.746094, 1.1875, -1.96094, 0.398438, 0.125977, 1.58594, 1.30469, 1.45312, -0.337891, -1.24219, -1.02344, -0.816406, -0.0252686, 2.40625, -0.566406, 0.679688, 0.380859, -0.0432129 ...
[VT][vision_model.encoder.layers.2.self_attn.v_proj[NLH]/item_128] shape=[768] showing 24/768: -0.417969, 0.472656, 1.42188, 1.76562, -0.917969, 1.42188, -0.5625, 0.777344, -1.55469, -0.00164032, 0.150391, 1.58594, 1.15625, 1.32031, -0.410156, -1.49219, -1.32031, -0.449219, -0.21582, 2.4375, -0.9375, 0.6875, 0.640625, -0.271484 ...