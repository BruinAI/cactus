{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25da9734-d549-4a49-b908-fafb32ca33ec",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866781ab-7d09-4a2c-aab3-3e1cf418709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from cactus_bindings import bindings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from enum import Enum\n",
    "import time\n",
    "from typing import List, Dict, Callable, Optional, get_args, get_origin, Union\n",
    "import inspect\n",
    "from docstring_parser import parse\n",
    "from dataclasses import dataclass, field\n",
    "from functools import wraps\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856c248-156f-4949-85d4-942dcfbf3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(text1:str, text2:str, verbose:bool=False)->float:\n",
    "    t1 = time.time()\n",
    "    v1 = np.asarray(clm.embed(text1))\n",
    "    t2 = time.time()\n",
    "    v2 = np.asarray(clm.embed(text2))\n",
    "    t3 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Embeddings complete in {t2-t1:.2f}sec | {t3-t2:.2f}sec')\n",
    "    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    "\n",
    "def keywords(kw: list = None):\n",
    "    \"A decorator to attach a list of keywords to a function.\"\n",
    "    def decorator(func):\n",
    "        setattr(func, '_keywords', kw or [])\n",
    "        \n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return func(*args, **kwargs)\n",
    "        \n",
    "        return func\n",
    "    \n",
    "    return decorator\n",
    "\n",
    "class TransformationType(str, Enum):\n",
    "    NAME_DESCRIPTION = \"name-description\"\n",
    "    NAME_DESCRIPTION_ARGS = \"name-description-args\"\n",
    "    NAME_DESCRIPTION_ARGS_DESCRIPTIONS = \"name-description-args-descriptions\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ToolArgument:\n",
    "    name:str\n",
    "    description:str\n",
    "    _type:str\n",
    "    required:bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Tool:\n",
    "    name:str\n",
    "    description:str\n",
    "    func:Callable\n",
    "    args:Optional[List[ToolArgument]]=field(default_factory=list)\n",
    "    keywords:Optional[List[str]]=field(default_factory=list)\n",
    "\n",
    "    def to_openai_format(self)->Dict:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        arg.name: {\n",
    "                            \"type\": arg._type,\n",
    "                            \"description\": arg.description\n",
    "                        }\n",
    "                        for arg in self.args\n",
    "                    },\n",
    "                    \"required\": [arg.name for arg in self.args if arg.required]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def to_string(\n",
    "        self,\n",
    "        transformation_type:TransformationType=TransformationType.NAME_DESCRIPTION_ARGS_DESCRIPTIONS\n",
    "    )->str:\n",
    "        match transformation_type.value:\n",
    "            case 'name-description':\n",
    "                return f\"Function {self.name} with description: `{self.description}`\" \n",
    "            case 'name-description-args':\n",
    "                return f\"\"\"Function {self.name} with description: `{self.description}` and arguments {', '.join([f\"`{arg.name}`\" for arg in self.args])}\"\"\"\n",
    "            case 'name-description-args-descriptions':\n",
    "                return f\"\"\"Function {self.name} with description: `{self.description}` and arguments {', '.join([f\"`{arg.name}` ({arg.description})\" for arg in self.args])}\"\"\"\n",
    "            case _:\n",
    "                raise Exception('unknown case!')\n",
    "\n",
    "\n",
    "class Tools:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tools:List[Tool],\n",
    "    )->None:\n",
    "        self.tools=tools\n",
    "\n",
    "    def retrieve_relevant(\n",
    "        self, \n",
    "        user_query:str,\n",
    "        return_format:str='openai',\n",
    "        top_n:int=1\n",
    "    )->List[Tool | Dict]:\n",
    "        assert return_format in ('openai', 'dict'), 'Unsupported return format!'\n",
    "        \n",
    "        tool_cos_sims = [calculate_cosine_similarity(tool.to_string(), user_query) for tool in self.tools]\n",
    "        sorted_tools = sorted(zip(self.tools, tool_cos_sims), key=lambda x: x[1], reverse=True)\n",
    "        retrieved_tools = [x[0] for x in sorted_tools[:top_n]]\n",
    "        \n",
    "        match return_format:\n",
    "            case 'openai':\n",
    "                return [t.to_openai_format() for t in retrieved_tools]\n",
    "            case 'dict':\n",
    "                return retrieved_tools\n",
    "\n",
    "class CactusModel:\n",
    "    WEIGHTS_PATH=\"/Users/noahcylich/Documents/Desert/cactus-fc/weights/\"\n",
    "\n",
    "    def __init__(self, slug:str, context_size:int=2048)->None:\n",
    "        self.model_path=self.WEIGHTS_PATH+slug\n",
    "        self.context_size=context_size\n",
    "        self.initialize_model()\n",
    "\n",
    "    def initialize_model(self)->None:\n",
    "        self.model=bindings.cactus_init(\n",
    "            model_path=self.model_path,\n",
    "            context_size=self.context_size\n",
    "        )\n",
    "\n",
    "    def complete(self, messages:List[Dict], max_tokens:int=1024, tools:List=[])->Dict:\n",
    "        try:\n",
    "            response_json = bindings.cactus_complete(\n",
    "                model=self.model,\n",
    "                messages_json=json.dumps(messages),\n",
    "                response_buffer_size=4096,\n",
    "                options_json=json.dumps({\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"temperature\": 0.7\n",
    "                }),\n",
    "                tools_json=json.dumps(tools),\n",
    "                callback=None\n",
    "            )\n",
    "            response=json.loads(response_json)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def embed(self, text:str)->List:\n",
    "        try:\n",
    "            return bindings.cactus_embed(\n",
    "                model=self.model,\n",
    "                text=text\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "class CactusChatModel(CactusModel):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        slug:str, \n",
    "        context_size:int=2048, \n",
    "        prompt:str='You are a helpful assistant.'\n",
    "    )->None:\n",
    "        super().__init__(slug, context_size)\n",
    "        self.system_prompt = prompt \n",
    "        self.reset_history()\n",
    "\n",
    "    def reset_history(self)->None:\n",
    "        \"\"\"Resets the conversation to just the initial system prompt.\"\"\"\n",
    "        self.message_history_raw = [{'role': 'system', 'content': self.system_prompt}]\n",
    "\n",
    "    def send_message(\n",
    "        self, \n",
    "        message:str, \n",
    "        tools:Optional[Tools]=Tools([]),\n",
    "        filter_tools:bool=True,\n",
    "        top_n_tools:int=1,\n",
    "        auto_call_tool=True\n",
    "    )->Dict:\n",
    "        if filter_tools:\n",
    "            self.tools=tools.retrieve_relevant(message, return_format='openai', top_n=top_n_tools)\n",
    "            print(f\"Filtered tools down to {[t.get('function').get('name') for t in self.tools]} for {message}\")\n",
    "        else:\n",
    "            self.tools=[tool.to_openai_format() for tool in tools.tools]\n",
    "            \n",
    "        self.message_history_raw.append({'role': 'user', 'content': message})\n",
    "        response_json = self.complete(messages=self.message_history, tools=self.tools)\n",
    "\n",
    "        if response_json:\n",
    "            self.message_history_raw.append(response_json)\n",
    "    \n",
    "            if auto_call_tool and response_json.get('function_calls'):\n",
    "                \n",
    "                function_calls = response_json.get('function_calls', [])\n",
    "                for call in function_calls:\n",
    "                    tool_name = call.get('name') or call.get('function')\n",
    "                    tool_args = call.get('arguments')\n",
    "    \n",
    "                    tool = [t for t in tools.tools if t.name == tool_name]\n",
    "                    if tool:\n",
    "                        try:\n",
    "                            tool_output = tool[0].func(**tool_args)\n",
    "                        except Exception as e:\n",
    "                            tool_output = 'error calling tool'\n",
    "                        self.message_history_raw.append({'role': 'tool_response', 'content': tool_output})\n",
    "                    else:\n",
    "                        self.message_history_raw.append({'role': 'tool_response', 'content': f\"Error: Tool '{tool_name}' not found.\"})\n",
    "                \n",
    "                response_json = self.complete(self.message_history, max_tokens=1024)\n",
    "                self.message_history_raw.append(response_json)\n",
    "            \n",
    "            return response_json\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    @property\n",
    "    def message_history(self)->List:\n",
    "        return [\n",
    "            x if x.get('role') in ['user', 'system', 'tool_response'] else \\\n",
    "                {**{'role': 'assistant', 'content': x['response'] if not x.get('function_calls') else [{\"type\": \"tool_call\", \"function\": x} for x in x.get('function_calls')]}} \\\n",
    "                for x in self.message_history_raw\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def messages_df(self)->pd.DataFrame:\n",
    "        df = pd.DataFrame(self.message_history_raw)\n",
    "        df['content'] = df.content.combine_first(df.response)\n",
    "        df['role'].fillna('assistant', inplace=True)\n",
    "        return df[[col for col in df if col != 'response']]\n",
    "\n",
    "def _map_type(py_type) -> str:\n",
    "    \"\"\"Maps Python types to JSON schema string types.\"\"\"\n",
    "    if py_type == str:\n",
    "        return \"string\"\n",
    "    if py_type == int:\n",
    "        return \"integer\"\n",
    "    if py_type == float:\n",
    "        return \"number\"\n",
    "    if py_type == bool:\n",
    "        return \"boolean\"\n",
    "    return \"string\" # Default\n",
    "\n",
    "def build_tool_from_func(func: Callable) -> Tool:\n",
    "    \"Generates a Tool object by inspecting a Python function.\"\n",
    "    \n",
    "    sig = inspect.signature(func) # get signature (names, types, defaults)\n",
    "    docstring = parse(inspect.getdoc(func))\n",
    "    param_docs = {param.arg_name: param.description for param in docstring.params}\n",
    "    \n",
    "    tool_args = []\n",
    "    for name, param in sig.parameters.items():        \n",
    "        is_required = (param.default == inspect.Parameter.empty)\n",
    "        real_type = param.annotation\n",
    "        if get_origin(real_type) in [Union, Optional]:\n",
    "            args = get_args(real_type) # first type argument that isn't None\n",
    "            real_type = next(t for t in args if t is not type(None))\n",
    "        \n",
    "        tool_args.append(\n",
    "            ToolArgument(\n",
    "                name=name,\n",
    "                description=param_docs.get(name, \"\"),\n",
    "                _type=_map_type(real_type),\n",
    "                required=is_required\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return Tool(\n",
    "        name=func.__name__,\n",
    "        description=docstring.short_description or \"\",\n",
    "        func=func,\n",
    "        args=tool_args,\n",
    "        keywords=getattr(func, '_keywords', [])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e5e35-0fdc-4cbd-8cea-083a8881c3d4",
   "metadata": {},
   "source": [
    "#### Tool definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685583ce-5f2d-40ce-9d94-a4e5de01d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# Using Optional[type] which is equivalent to type | None\n",
    "# for broader Python compatibility.\n",
    "\n",
    "def create_note(text: str):\n",
    "    \"\"\"\n",
    "    Creates a new note with the given text. Call this tool if asked to be reminded or to take a note.\n",
    "\n",
    "    Args:\n",
    "        text: The text of the note, usually a direct quote from the user\n",
    "    \"\"\"\n",
    "    return f\"Note created with text: {text}\"\n",
    "\n",
    "\n",
    "def set_alarm(time_hours: int, time_minutes: int):\n",
    "    \"\"\"\n",
    "    Sets an alarm for a specific time.\n",
    "\n",
    "    Args:\n",
    "        time_hours: The hour component of the alarm time (24 hour time)\n",
    "        time_minutes: The minute component of the alarm time (0-59)\n",
    "    \"\"\"\n",
    "    return f\"Alarm set successfully!\"\n",
    "\n",
    "\n",
    "def set_timer_absolute(day_offset: Optional[str], time_hours: int, time_minutes: int):\n",
    "    \"\"\"\n",
    "    Sets a timer to go off at an absolute day and time.\n",
    "\n",
    "    Args:\n",
    "        day_offset: The offset of the day to remind the user at e.g. 'tomorrow', 'today', 'thursday' (will be the next thursday), '3' (will be in 3 days)\n",
    "        time_hours: The hour component of the desired end time (24 hour time)\n",
    "        time_minutes: The minute component of the desired end time (0-59)\n",
    "    \"\"\"\n",
    "    return f\"Absolute timer set for {day_offset} at {time_hours}:{time_minutes}\"\n",
    "\n",
    "\n",
    "def set_timer(time_hours: Optional[int], time_minutes: Optional[int], time_seconds: Optional[int]):\n",
    "    \"\"\"\n",
    "    Sets a timer for a relative duration (hours, minutes, seconds).\n",
    "\n",
    "    Args:\n",
    "        time_hours: The number of hours on the timer\n",
    "        time_minutes: The number of minutes on the timer\n",
    "        time_seconds: The number of seconds on the timer\n",
    "    \"\"\"\n",
    "    return f\"Timer set for {time_hours}h {time_minutes}m {time_seconds}s\"\n",
    "\n",
    "\n",
    "def reminder_absolute(day_offset: Optional[str], absolute_time_hour: int, absolute_time_minute: int, date_month_day: Optional[str], date_year: Optional[int], message: str):\n",
    "    \"\"\"\n",
    "    Creates a reminder for a specific absolute date and time.\n",
    "\n",
    "    Args:\n",
    "        day_offset: The offset of the day to remind the user at e.g. 'tomorrow', 'today', 'thursday' (will be the next thursday), '3' (will be in 3 days)\n",
    "        absolute_time_hour: The absolute time to remind the user at as a 24 hour hour part e.g. '17'\n",
    "        absolute_time_minute: The absolute time to remind the user at as a minute part e.g. '30', or '00' for the top of the hour\n",
    "        date_month_day: The date to remind the user at if specified by the user as a date part (month-day) e.g. '12-31'\n",
    "        date_year: The year to remind the user at if specified by the user as a year part e.g. '2022'\n",
    "        message: The message to remind the user e.g. 'Buy more milk'\n",
    "    \"\"\"\n",
    "    return f\"Absolute reminder set for '{message}' on {date_month_day}-{date_year} or {day_offset} at {absolute_time_hour}:{absolute_time_minute}\"\n",
    "\n",
    "\n",
    "def create_reminder_relative(relative_time: int, time_unit: str, message: str):\n",
    "    \"\"\"\n",
    "    When the user requires a reminder at a relative time e.g. 'in 5 minutes' use the create_reminder_relative tool.\n",
    "\n",
    "    Args:\n",
    "        relative_time: The relative time to remind the user at as n 'time_unit's in the future\n",
    "        time_unit: The unit of time for the relative time. Must be one of: [\"seconds\", \"minutes\", \"hours\", \"days\", \"weeks\", \"months\", \"years\"]\n",
    "        message: The message to remind the user e.g. 'Buy more milk'\n",
    "    \"\"\"\n",
    "    return f\"Relative reminder set for '{message}' in {relative_time} {time_unit}\"\n",
    "\n",
    "tools = Tools([build_tool_from_func(f) for f in [\n",
    "    create_note,\n",
    "    set_alarm,\n",
    "    set_timer_absolute,\n",
    "    set_timer,\n",
    "    reminder_absolute,\n",
    "    create_reminder_relative\n",
    "]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cf0e4-cc94-4f11-bb06-5573951517fd",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36d6d9-02e4-4179-9347-0015dd72a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = [\n",
    "    {\n",
    "        \"query\": \"send Henry a message about our upcoming framework release.\", \n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"what is the weather in London?\", \n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Wake me up at 5 am tomorrow please.\", \n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Write down that i need to go buy groceries for the house tomorrow\", \n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Hey how are you!\", \n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Text mom I'll be home late.\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can you message Alex about the 3pm call?\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tell Henry I've finished the draft for the medium article.\", # Personalized from your context\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Will I need an umbrella tomorrow in New York?\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How cold is it in Paris right now?\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Get me the forecast for San Francisco this weekend.\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"query\": \"Set an alarm for 7:30 PM.\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I need an alarm for 6:15 tomorrow morning.\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Remind me to buy milk and eggs.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Make a note: pick up dry cleaning on Tuesday.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Save this thought: on-device inference is key for privacy.\", # Personalized from your context\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"That's great, thanks!\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the capital of France?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who won the game last night?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Make a note of the weather in Berlin.\", # Ambiguous query to test boundaries\n",
    "        \"correct_tool\": \"create_note\" \n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I need an alarm for 8:45 in the morning.\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Set an alarm for 11:30 PM tonight.\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Alarm for 6am.\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can you wake me up at 7:15 am?\",\n",
    "        \"correct_tool\": \"set_alarm\"\n",
    "    },\n",
    "\n",
    "    # --- weather_lookup ---\n",
    "    {\n",
    "        \"query\": \"What's the weather like in Boston?\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I'm going to Paris tomorrow, what's the forecast?\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tell me the temperature in Dubai.\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Weather forecast for Seattle for the next 3 days.\",\n",
    "        \"correct_tool\": \"weather_lookup\"\n",
    "    },\n",
    "\n",
    "    # --- write_text_message ---\n",
    "    {\n",
    "        \"query\": \"Send a message to Alice asking 'What time is dinner?'\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Text Bob: 'I'm running about 15 minutes late.'\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Please message my manager that I've pushed the new code.\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Text 'On my way!' to Sarah.\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can you text my brother 'Happy birthday!'?\",\n",
    "        \"correct_tool\": \"write_text_message\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Note to self: buy milk.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Remember this: the new inference engine for the react-native app is a priority.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I need to make a note about the meeting... just write down 'Follow up with marketing'.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Jot this down: need to research more apps for the Cactus library.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Create a new note titled 'Gift Ideas' with 'book for mom' in it.\",\n",
    "        \"correct_tool\": \"create_note\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Thanks, that's perfect.\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How do I set an alarm?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who was the first person on the moon?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How old is the Eiffel Tower?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the alarm for?\",\n",
    "        \"correct_tool\": None\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tell me a joke.\",\n",
    "        \"correct_tool\": None\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f383d-e7f6-4e1a-8130-bac7831879a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered tools down to ['create_note', 'reminder_absolute', 'set_timer'] for Who was the first person on the moon?\n"
     ]
    }
   ],
   "source": [
    "model_slugs=[\n",
    "    'Qwen3-0.6B_tool_calling_lora',\n",
    "    # 'qwen3-0.6b',\n",
    "    # 'lfm2-1.2B-Tool',\n",
    "    # 'lfm2-1.2B',\n",
    "    # 'lfm2-350m',\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_slug in model_slugs:\n",
    "    \n",
    "    clm = CactusChatModel(\n",
    "        slug=model_slug,\n",
    "        prompt=\"You are a helpful assistant. You have access to a list of tools. You are communicating via one-shot interactions. If using a tool/function, just call it without asking follow-up questions.\"\n",
    "    )\n",
    "    \n",
    "    for filter_tools in [True, False]:\n",
    "        for sample in eval_data:\n",
    "            query = sample['query']\n",
    "            correct_tool = sample['correct_tool']\n",
    "        \n",
    "            clm.reset_history()\n",
    "        \n",
    "            clm.send_message(\n",
    "                message=query,\n",
    "                tools=tools,\n",
    "                filter_tools=filter_tools,\n",
    "                top_n_tools=3\n",
    "            )\n",
    "            try:\n",
    "                function_calls = [m for m in clm.message_history_raw if m.get('function_calls')]\n",
    "                if function_calls:\n",
    "                    tools_called = [fc.get('name') for fc in function_calls[-1].get('function_calls', {})]\n",
    "                else:\n",
    "                    tools_called = []\n",
    "            \n",
    "                correct_tool_called = (correct_tool is None and tools_called == []) or (correct_tool in tools_called)\n",
    "            \n",
    "                results.append({\n",
    "                    \"query\": query,\n",
    "                    \"model\": model_slug,\n",
    "                    \"filter_tools\": filter_tools,\n",
    "                    \"correct_tool\": correct_tool,\n",
    "                    \"tools_called\": tools_called,\n",
    "                    \"correct_tool_called\": correct_tool_called,\n",
    "                    \"message_history\": clm.message_history_raw\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda9308-d581-4eb2-845d-259c60c03da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032700d-5f42-4520-b0e7-19d7f37490b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.correct_tool == 'weather_lookup']\n",
    "df[df.correct_tool == 'write_text_message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0184d8-5cf3-4001-b982-05d189ed0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(['filter_tools', 'correct_tool']).correct_tool_called.mean()).reset_index().pivot(\n",
    "    columns='correct_tool',\n",
    "    index='filter_tools',\n",
    "    values='correct_tool_called'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16792ebc-69ee-4911-881d-76ca62cde990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['filter_tools']).correct_tool_called.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c58e86-5139-4150-ba3a-f73145604096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['filter_tools', 'model', ]).correct_tool_called.mean().reset_index().pivot(\n",
    "    columns='model',\n",
    "    index='filter_tools',\n",
    "    values='correct_tool_called'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114d13e-5cff-48e4-a816-55af216b13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = df[\n",
    "    (df.model == model_slugs[1]) &\n",
    "    (df.correct_tool_called == False)\n",
    "].message_history.apply(lambda x: x[1].get('response', '') if len(x) > 1 else None)\n",
    "\n",
    "for resp in response_df.dropna().tolist():\n",
    "    print(\"----\")\n",
    "    print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
